{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glacier grids from SGI or GLAMOS:\n",
    "\n",
    "Creates monthly grid files for the MBM to make PMB predictions over the whole glacier grid. The files come from the SGI grid and use OGGM topography. Computing takes a long time because of the conversion to monthly format.\n",
    "## Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../')) # Add root of repo to import MBM\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import massbalancemachine as mbm\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import geopandas as gpd\n",
    "\n",
    "# scripts\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "from scripts.plots import *\n",
    "from scripts.geodata import *\n",
    "from scripts.xgb_helpers import *\n",
    "from scripts.config_CH import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)\n",
    "free_up_cuda()  # in case no memory\n",
    "\n",
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "\n",
    "# Climate columns\n",
    "vois_climate = [\n",
    "    't2m', 'tp', 'slhf', 'sshf', 'ssrd', 'fal', 'str', 'u10', 'v10'\n",
    "]\n",
    "# Topographical columns\n",
    "voi_topographical = [\n",
    "    \"aspect\",\n",
    "    \"slope\",\n",
    "    \"hugonnet_dhdt\",\n",
    "    \"consensus_ice_thickness\",\n",
    "    \"millan_v\",\n",
    "    \"topo\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glaciers_glamos_dem = os.listdir(\n",
    "    os.path.join(cfg.dataPath, path_GLAMOS_topo, 'lv95/'))\n",
    "\n",
    "# Glacier outlines:\n",
    "glacier_outline_sgi = gpd.read_file(\n",
    "    os.path.join(cfg.dataPath, path_SGI_topo, 'inventory_sgi2016_r2020',\n",
    "                 'SGI_2016_glaciers_copy.shp'))  # Load the shapefile\n",
    "glacier_outline_rgi = gpd.read_file(cfg.dataPath + path_rgi_outlines)\n",
    "\n",
    "# Sort glaciers by area\n",
    "gl_area = get_gl_area(cfg)\n",
    "gl_area['clariden'] = gl_area['claridenL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodetic_mb = get_geodetic_MB(cfg)\n",
    "\n",
    "# get years per glacier\n",
    "years_start_per_gl = geodetic_mb.groupby(\n",
    "    'glacier_name')['Astart'].unique().apply(list).to_dict()\n",
    "years_end_per_gl = geodetic_mb.groupby('glacier_name')['Aend'].unique().apply(\n",
    "    list).to_dict()\n",
    "\n",
    "periods_per_glacier, geoMB_per_glacier = build_periods_per_glacier(geodetic_mb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 1: SGI (2015) grids (for option 2 see below - GLAMOS grids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine SGI data:\n",
    "### Glacier masks over SGI aspect:\n",
    "This is to check that there is a good overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glacier outlines:\n",
    "glacier_outline_sgi = gpd.read_file(\n",
    "    os.path.join(cfg.dataPath, path_SGI_topo, 'inventory_sgi2016_r2020',\n",
    "                 'SGI_2016_glaciers.shp'))  # Load the shapefile\n",
    "\n",
    "# Clear output folder\n",
    "emptyfolder('figures/SGI_mask/')\n",
    "\n",
    "for glacier_name in tqdm(years_start_per_gl.keys(),\n",
    "                         desc=\"Processing glaciers\"):\n",
    "\n",
    "    # Handle 'clariden' separately due to special ID format\n",
    "    sgi_id, rgi_id, rgi_shp = get_rgi_sgi_ids(cfg, glacier_name)\n",
    "\n",
    "    # Skip if no SGI ID\n",
    "    if not sgi_id:\n",
    "        print(f'No SGI ID found for {glacier_name}')\n",
    "        continue\n",
    "\n",
    "    # Get glacier mask from SGI shapefile\n",
    "    gdf_mask_gl = glacier_outline_sgi[glacier_outline_sgi['sgi-id'] == sgi_id]\n",
    "\n",
    "    # Skip if no glacier mask found\n",
    "    if gdf_mask_gl.empty:\n",
    "        print(f'No glacier mask found for {glacier_name}')\n",
    "        continue\n",
    "\n",
    "    # Locate aspect grid file\n",
    "    aspect_gl = next((f for f in os.listdir(\n",
    "        os.path.join(cfg.dataPath, path_SGI_topo, 'aspect')) if sgi_id in f),\n",
    "                     None)\n",
    "\n",
    "    # Skip if no aspect file found\n",
    "    if not aspect_gl:\n",
    "        print(f'No aspect file found for {glacier_name}')\n",
    "        continue\n",
    "\n",
    "    # Load grid file\n",
    "    metadata_aspect, grid_data_aspect = load_grid_file(\n",
    "        os.path.join(os.path.join(cfg.dataPath, path_SGI_topo, 'aspect'),\n",
    "                     aspect_gl))\n",
    "\n",
    "    # Convert to xarray\n",
    "    aspect = convert_to_xarray_geodata(grid_data_aspect, metadata_aspect)\n",
    "\n",
    "    # Transform to WGS84 coordinates\n",
    "    aspect_wgs84 = transform_xarray_coords_lv95_to_wgs84(aspect)\n",
    "\n",
    "    # Plot the data\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    aspect_wgs84.plot(ax=ax)\n",
    "    gdf_mask_gl.plot(ax=ax, alpha=0.5)\n",
    "\n",
    "    # Save the figure\n",
    "    output_path = os.path.join('figures', 'SGI_mask', f\"{glacier_name}.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare one example grid of SGI to OGGM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glacier name\n",
    "glacier_name = 'rhone'\n",
    "\n",
    "# Get SGI ID and RGI shapefile ID safely\n",
    "try:\n",
    "    sgi_id, rgi_id, rgi_shp = get_rgi_sgi_ids(cfg, glacier_name)\n",
    "except KeyError:\n",
    "    print(f\"Error: {glacier_name} not found in rgi_df\")\n",
    "    sgi_id, rgi_id, rgi_shp = '', '', ''\n",
    "\n",
    "if not sgi_id or not rgi_id or not rgi_shp:\n",
    "    print(f\"Warning: Missing data for {glacier_name}. Skipping...\")\n",
    "else:\n",
    "    # Load SGI masked dataset\n",
    "    ds = xr_SGI_masked_topo(glacier_outline_sgi, sgi_id, cfg)\n",
    "    if ds is None:\n",
    "        print(\n",
    "            f\"Warning: Failed to load SGI dataset for {glacier_name}. Skipping...\"\n",
    "        )\n",
    "    else:\n",
    "        # Load OGGM dataset\n",
    "        oggm_path = os.path.join(cfg.dataPath, path_OGGM, 'xr_grids',\n",
    "                                 f'{rgi_id}.zarr')\n",
    "\n",
    "        try:\n",
    "            ds_oggm = xr.open_dataset(oggm_path)\n",
    "        except FileNotFoundError:\n",
    "            print(\n",
    "                f\"Error: OGGM dataset not found for {glacier_name}. Skipping...\"\n",
    "            )\n",
    "            ds_oggm = None\n",
    "\n",
    "        # Calculate SGI resolution\n",
    "        dx_sgi, dy_sgi = get_res_from_degrees(ds)\n",
    "        print(f\"Cell size of SGI: {dx_sgi:.2f} x {dy_sgi:.2f} meters\")\n",
    "\n",
    "        if ds_oggm is not None:\n",
    "            # Calculate OGGM resolution\n",
    "            dx_oggm = abs(ds_oggm.x[1] - ds_oggm.x[0])\n",
    "            dy_oggm = abs(ds_oggm.y[1] - ds_oggm.y[0])\n",
    "            print(f\"Cell size of OGGM: {dx_oggm:.2f} x {dy_oggm:.2f} meters\")\n",
    "\n",
    "            # Plot the data\n",
    "            fig, axs = plt.subplots(2, 4, figsize=(15, 8))\n",
    "\n",
    "            # SGI Data\n",
    "            ds.masked_aspect.plot(ax=axs[0, 0],\n",
    "                                  cmap='twilight_shifted',\n",
    "                                  add_colorbar=False)\n",
    "            ds.masked_slope.plot(ax=axs[0, 1],\n",
    "                                 cmap='cividis',\n",
    "                                 add_colorbar=False)\n",
    "            ds.masked_elev.plot(ax=axs[0, 2],\n",
    "                                cmap='terrain',\n",
    "                                add_colorbar=False)\n",
    "            ds.glacier_mask.plot(ax=axs[0, 3],\n",
    "                                 cmap='binary',\n",
    "                                 add_colorbar=False)\n",
    "\n",
    "            axs[0, 0].set_title(\"Aspect SGI\")\n",
    "            axs[0, 1].set_title(\"Slope SGI\")\n",
    "            axs[0, 2].set_title(\"DEM SGI\")\n",
    "            axs[0, 3].set_title(\"Glacier mask SGI\")\n",
    "\n",
    "            # OGGM Data\n",
    "            if all(var in ds_oggm\n",
    "                   for var in ['aspect', 'slope', 'topo', 'glacier_mask']):\n",
    "                ds_oggm.aspect.plot(ax=axs[1, 0],\n",
    "                                    cmap='twilight_shifted',\n",
    "                                    add_colorbar=False)\n",
    "                ds_oggm.slope.plot(ax=axs[1, 1],\n",
    "                                   cmap='cividis',\n",
    "                                   add_colorbar=False)\n",
    "                ds_oggm.topo.plot(ax=axs[1, 2],\n",
    "                                  cmap='terrain',\n",
    "                                  add_colorbar=False)\n",
    "                ds_oggm.glacier_mask.plot(ax=axs[1, 3],\n",
    "                                          cmap='binary',\n",
    "                                          add_colorbar=False)\n",
    "\n",
    "                axs[1, 0].set_title(\"Aspect OGGM\")\n",
    "                axs[1, 1].set_title(\"Slope OGGM\")\n",
    "                axs[1, 2].set_title(\"DEM OGGM\")\n",
    "                axs[1, 3].set_title(\"Glacier mask OGGM\")\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Warning: Some OGGM variables are missing in {oggm_path}\")\n",
    "\n",
    "            # Set axis labels\n",
    "            for ax in axs.flatten():\n",
    "                ax.set_xlabel(\"x\")\n",
    "                ax.set_ylabel(\"y\")\n",
    "                ax.legend().remove()\n",
    "\n",
    "            # Optimize layout\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample SGI grid:\n",
    "# Coarson to 30 m resolution\n",
    "ds_resampled = coarsenDS(ds)\n",
    "\n",
    "# Calculate resolution\n",
    "dx_m, dy_m = get_res_from_degrees(ds_resampled)\n",
    "print(f\"Cell size of resampled grid: {dx_m:.2f} x {dy_m:.2f} meters\")\n",
    "\n",
    "# Plot resampled grid\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 6))\n",
    "ds_resampled.masked_aspect.plot(ax=axs[0], cmap='twilight_shifted')\n",
    "ds_resampled.masked_slope.plot(ax=axs[1], cmap='cividis', add_colorbar=False)\n",
    "ds_resampled.masked_elev.plot(ax=axs[2], cmap='terrain', add_colorbar=False)\n",
    "ds_resampled.glacier_mask.plot(ax=axs[3], cmap='binary', add_colorbar=False)\n",
    "\n",
    "axs[0].set_title(\"Aspect\")\n",
    "axs[1].set_title(\"Slope\")\n",
    "axs[2].set_title(\"DEM\")\n",
    "axs[3].set_title(\"Glacier mask\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly masked grids - dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the masked topographical arrays per glacier:\n",
    "glacier_list = sorted(years_start_per_gl.keys())\n",
    "RUN = False\n",
    "if RUN:\n",
    "    create_sgi_topo_masks(cfg,\n",
    "                          glacier_list,\n",
    "                          type='glacier_name',\n",
    "                          path_save=os.path.join(cfg.dataPath, path_SGI_topo,\n",
    "                                                 'xr_masked_grids/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN = False\n",
    "path_xr_grids = os.path.join(cfg.dataPath, path_SGI_topo, 'xr_masked_grids/')\n",
    "if RUN:\n",
    "    emptyfolder(cfg.dataPath + path_glacier_grid_sgi)\n",
    "    for glacier_name in tqdm(years_start_per_gl.keys(),\n",
    "                             desc=\"Processing glaciers\"):\n",
    "        folder_path = os.path.join(cfg.dataPath, path_glacier_grid_sgi, glacier_name)\n",
    "        os.makedirs(folder_path, exist_ok=True)  # Ensure folder exists\n",
    "\n",
    "        # Get existing processed years\n",
    "        existing_files = [\n",
    "            f for f in os.listdir(folder_path)\n",
    "            if re.search(r'_grid_(\\d{4})\\.parquet$', f)\n",
    "        ]\n",
    "        existing_years = {\n",
    "            int(re.search(r'_grid_(\\d{4})\\.parquet$', f).group(1))\n",
    "            for f in existing_files\n",
    "        }\n",
    "\n",
    "        # Get the longest period dynamically for the current glacier\n",
    "        if glacier_name in years_start_per_gl and glacier_name in years_end_per_gl:\n",
    "            geodetic_period = (years_start_per_gl[glacier_name][0],\n",
    "                               years_end_per_gl[glacier_name][-1])\n",
    "            print('Geodetic period:', int(geodetic_period[0]), '-',\n",
    "                  int(geodetic_period[1]))\n",
    "        else:\n",
    "            print(f\"Skipping {glacier_name}: missing start/end years\")\n",
    "            continue\n",
    "\n",
    "        # Get available .zarr files for this glacier\n",
    "        nc_files = [f for f in os.listdir(path_xr_grids) if glacier_name in f]\n",
    "        nc_files.sort()\n",
    "        print(f\"\\nProcessing {glacier_name}:\")\n",
    "\n",
    "        if not nc_files:\n",
    "            print(f\"Warning: No DEM found for {glacier_name}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        sgi_id, rgi_id, rgi_shp = get_rgi_sgi_ids(cfg, glacier_name)\n",
    "\n",
    "        for year in tqdm(range(geodetic_period[0], geodetic_period[1] + 1),\n",
    "                         desc='years',\n",
    "                         leave=False):\n",
    "            # print(f\"  - Processing year: {year}\")\n",
    "\n",
    "            # Skip glacier if required data is missing\n",
    "            if not sgi_id or not rgi_id or not rgi_shp:\n",
    "                print(\n",
    "                    f\"Warning: Missing SGI ID or RGI shapefile for {glacier_name}. Skipping...\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Load SGI masked grid (previously resampled)\n",
    "            try:\n",
    "                path_save = os.path.join(cfg.dataPath, path_SGI_topo,\n",
    "                                         'xr_masked_grids/')\n",
    "                path = os.path.join(path_save, f\"{glacier_name}.zarr\")\n",
    "                ds_coarsened = xr.open_dataset(path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading dataset for {glacier_name}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Create glacier grid\n",
    "            try:\n",
    "                df_grid = create_glacier_grid_SGI(glacier_name, year, rgi_id,\n",
    "                                                  ds_coarsened)\n",
    "                df_grid.reset_index(drop=True, inplace=True)\n",
    "                dataset_grid = mbm.data_processing.Dataset(\n",
    "                    cfg=cfg,\n",
    "                    data=df_grid,\n",
    "                    region_name='CH',\n",
    "                    data_path=cfg.dataPath + path_PMB_GLAMOS_csv)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"Error creating glacier grid for {glacier_name} in {year}: {e}\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Add climate data\n",
    "            try:\n",
    "                era5_climate_data = os.path.join(\n",
    "                    cfg.dataPath, path_ERA5_raw,\n",
    "                    'era5_monthly_averaged_data.nc')\n",
    "                geopotential_data = os.path.join(\n",
    "                    cfg.dataPath, path_ERA5_raw,\n",
    "                    'era5_geopotential_pressure.nc')\n",
    "                dataset_grid.get_climate_features(\n",
    "                    climate_data=era5_climate_data,\n",
    "                    geopotential_data=geopotential_data,\n",
    "                    change_units=True,\n",
    "                    smoothing_vois={\n",
    "                        'vois_climate': vois_climate,\n",
    "                        'vois_other': ['ALTITUDE_CLIMATE']\n",
    "                    })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"Error adding climate data for {glacier_name} in {year}: {e}\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Add potential clear sky radiation\n",
    "            try:\n",
    "                dataset_grid.get_potential_rad(\n",
    "                    os.path.join(cfg.dataPath, path_pcsr, 'zarr/'))\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"Error adding clear sky radiation for {glacier_name} in {year}: {e}\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Add OGGM topographic data\n",
    "            # print('  - Adding OGGM data...')\n",
    "            try:\n",
    "                df_y_gl = dataset_grid.data\n",
    "                df_y_gl.rename(columns={'RGIId': 'RGIId_old'}, inplace=True)\n",
    "\n",
    "                # Add RGI IDs for OGGM data through intersection with shapefiles\n",
    "                df_y_gl = mbm.data_processing.utils.get_rgi(\n",
    "                    data=df_y_gl, glacier_outlines=glacier_outline_rgi)\n",
    "\n",
    "                # Drop points without RGI ID (outside of RGI outlines)\n",
    "                df_y_gl = df_y_gl.dropna(subset=['RGIId'])\n",
    "\n",
    "                # Variables of interest\n",
    "                voi = [\"hugonnet_dhdt\", \"consensus_ice_thickness\", \"millan_v\"]\n",
    "\n",
    "                df_y_gl = add_OGGM_features(df_y_gl, voi,\n",
    "                                            cfg.dataPath + path_OGGM)\n",
    "\n",
    "                # Add GLWD_ID\n",
    "                # print('  - Adding GLWD ID...')\n",
    "                df_y_gl['GLWD_ID'] = df_y_gl.apply(\n",
    "                    lambda x: mbm.data_processing.utils.get_hash(\n",
    "                        f\"{x.GLACIER}_{x.YEAR}\"),\n",
    "                    axis=1)\n",
    "                df_y_gl['GLWD_ID'] = df_y_gl['GLWD_ID'].astype(str)\n",
    "\n",
    "                dataset_grid = mbm.data_processing.Dataset(\n",
    "                    cfg=cfg,\n",
    "                    data=df_y_gl,\n",
    "                    region_name='CH',\n",
    "                    data_path=cfg.dataPath + path_PMB_GLAMOS_csv)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"Error adding OGGM data for {glacier_name} in {year}: {e}\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Convert to monthly time resolution\n",
    "            # print('  - Converting to monthly time resolution...')\n",
    "            try:\n",
    "                dataset_grid.convert_to_monthly(\n",
    "                    meta_data_columns=cfg.metaData,\n",
    "                    vois_climate=vois_climate + ['pcsr'],\n",
    "                    vois_topographical=voi_topographical)\n",
    "                assert 'pcsr' in dataset_grid.data.columns, \"Missing 'pcsr' column after conversion\"\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"Error converting to monthly resolution for {glacier_name} in {year}: {e}\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Rename columns (because slope & aspect not from OGGM)\n",
    "            df_oggm = dataset_grid.data\n",
    "            df_oggm.rename(columns={\n",
    "                'aspect': 'aspect_sgi',\n",
    "                'slope': 'slope_sgi'\n",
    "            },\n",
    "                           inplace=True)\n",
    "\n",
    "            # Save gridded dataset\n",
    "            save_path = os.path.join(folder_path,\n",
    "                                     f\"{glacier_name}_grid_{year}.parquet\")\n",
    "\n",
    "            try:\n",
    "                # dataset_grid.data.to_csv(save_path, index=False)\n",
    "                df_oggm.to_parquet(save_path,\n",
    "                                   engine=\"pyarrow\",\n",
    "                                   compression=\"snappy\")\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"Error saving dataset for {glacier_name} in {year}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all OGGM variables\n",
    "glacier_name = 'aletsch'\n",
    "year = 2016\n",
    "\n",
    "df = pd.read_parquet(\n",
    "    os.path.join(cfg.dataPath, path_glacier_grid_sgi, f\"{glacier_name}/{glacier_name}_grid_{year}.parquet\"))\n",
    "df = df[df.MONTHS == 'sep']\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "voi = [\n",
    "    't2m', 'tp', 'ALTITUDE_CLIMATE', 'ELEVATION_DIFFERENCE', 'hugonnet_dhdt',\n",
    "    'consensus_ice_thickness'\n",
    "]\n",
    "axs = axs.flatten()\n",
    "for i, var in enumerate(voi):\n",
    "    sns.scatterplot(df,\n",
    "                    x='POINT_LON',\n",
    "                    y='POINT_LAT',\n",
    "                    hue=var,\n",
    "                    s=5,\n",
    "                    alpha=0.5,\n",
    "                    palette='twilight_shifted',\n",
    "                    ax=axs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2: GLAMOS grids:\n",
    "\n",
    "For the geodetic MB and gridded MB products computed by GLAMOS, they did not use the SGI grids (from 2015) but their own yearly DEMs. They're not available for all years, but we still compute monthly grids for these available glaciers and years, in order to make the comparison with geodetic MB fairer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdirs, rgidf = initialize_oggm_glacier_directories(\n",
    "    cfg,\n",
    "    rgi_region=\"11\",\n",
    "    rgi_version=\"6\",\n",
    "    base_url=\n",
    "    \"https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.1/elev_bands/W5E5_w_data/\",\n",
    "    log_level='WARNING',\n",
    "    task_list=None,\n",
    ")\n",
    "export_oggm_grids(cfg, gdirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of one glacier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script to convert lv03 to lv95 for Findelen\n",
    "# glacier_name = 'findelen'\n",
    "# sgi_id, rgi_id, rgi_shp = get_rgi_sgi_ids(glacier_name)\n",
    "\n",
    "# folder_path = os.path.join(path_GLAMOS_topo, 'lv03', glacier_name)\n",
    "\n",
    "# for fileName in os.listdir(folder_path):\n",
    "#     year = int(fileName.split('_')[1].split('.grid')[0])  # Extract year from filename\n",
    "\n",
    "#     # Example file\n",
    "#     metadata, grid_data = load_grid_file(folder_path + '/' + fileName)\n",
    "\n",
    "#     # Convert to xarray\n",
    "#     dem_y = convert_to_xarray_geodata(grid_data, metadata)\n",
    "\n",
    "#     dem_lv95_y = transform_xarray_coords_lv03_to_lv95(dem_y)\n",
    "\n",
    "#     # save to lv95 folder:\n",
    "#     filepath = os.path.join(path_GLAMOS_topo, 'lv95', glacier_name, f'gl_{year}_lv95.grid')\n",
    "\n",
    "#     save_xarray_to_grid(dem_lv95_y, filepath, nodata_value=-9999)\n",
    "\n",
    "# dem_lv95_y.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_name = 'findelen'\n",
    "sgi_id, rgi_id, rgi_shp = get_rgi_sgi_ids(cfg, glacier_name)\n",
    "\n",
    "folder_path = os.path.join(cfg.dataPath, path_GLAMOS_topo, 'lv95',\n",
    "                           glacier_name)\n",
    "\n",
    "# Example file\n",
    "fileName = 'gl_2008_lv95.grid'\n",
    "metadata, grid_data = load_grid_file(folder_path + '/' + fileName)\n",
    "\n",
    "# Convert to xarray\n",
    "dem_y = convert_to_xarray_geodata(grid_data, metadata)\n",
    "\n",
    "# Transform the coordinates to WGS84\n",
    "dem_wgs84_y = transform_xarray_coords_lv95_to_wgs84(dem_y)\n",
    "\n",
    "# Create a mask where 'elevation' is not NaN (1 if not NaN, 0 if NaN)\n",
    "ds_gl = xr.Dataset({'dem': dem_wgs84_y})\n",
    "ds_gl[\"glacier_mask\"] = ds_gl[\"dem\"].notnull().astype(np.uint8)\n",
    "\n",
    "dx = abs(ds_gl.x[1] - ds_gl.x[0]).values\n",
    "dy = abs(ds_gl.y[1] - ds_gl.y[0]).values\n",
    "print(f\"Cell size of GLAMOS DEM: {dx} x {dy} meters\")\n",
    "\n",
    "# Extract SGI topo and aspect over GLAMOS DEM\n",
    "ds = xr_GLAMOS_masked_topo(cfg, sgi_id, ds_gl)\n",
    "\n",
    "# Coarson to 30 m resolution if needed\n",
    "ds = coarsenDS(ds)\n",
    "dx_m, dy_m = get_res_from_degrees(ds)\n",
    "print(f\"Coarsened ds resolution: {dx_m} x {dy_m} meters\")\n",
    "\n",
    "# Plot the masked data\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 6))\n",
    "ds.masked_aspect.plot(ax=axs[0], cmap='twilight_shifted', add_colorbar=False)\n",
    "ds.masked_slope.plot(ax=axs[1], cmap='cividis', add_colorbar=False)\n",
    "ds.masked_elev.plot(ax=axs[2], cmap='terrain', add_colorbar=False)\n",
    "ds.glacier_mask.plot(ax=axs[3], cmap='binary', add_colorbar=False)\n",
    "\n",
    "axs[0].set_title(\"Aspect\")\n",
    "axs[1].set_title(\"Slope\")\n",
    "axs[2].set_title(\"DEM\")\n",
    "axs[3].set_title(\"Glacier mask\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yearly masked grids - xarrays:\n",
    "Save a .zarr xarray per glacier per year (not in monthly format) needed in the MBM later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define save path and ensure it exists\n",
    "RUN = False\n",
    "\n",
    "path_xr_grids = os.path.join(cfg.dataPath, path_GLAMOS_topo,\n",
    "                             'xr_masked_grids/')\n",
    "glaciers_glamos_dems = os.listdir(\n",
    "    os.path.join(cfg.dataPath, path_GLAMOS_topo, 'lv95'))\n",
    "\n",
    "if RUN:\n",
    "    emptyfolder(path_xr_grids)\n",
    "    for glacier_name in tqdm(glaciers_glamos_dems, desc=\"Processing glaciers\"):\n",
    "        print(f\"\\nProcessing {glacier_name}...\")\n",
    "\n",
    "        # Handle 'clariden' separately due to special ID format\n",
    "        sgi_id, rgi_id, rgi_shp = get_rgi_sgi_ids(cfg, glacier_name)\n",
    "\n",
    "        # Skip glacier if required data is missing\n",
    "        if not sgi_id or not rgi_shp:\n",
    "            print(\n",
    "                f\"Warning: Missing SGI ID or shapefile for {glacier_name}. Skipping...\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Define glacier folder path\n",
    "        folder_path = os.path.join(\n",
    "            cfg.dataPath, path_GLAMOS_topo, 'lv95',\n",
    "            'stanna' if glacier_name == 'sanktanna' else glacier_name)\n",
    "\n",
    "        # Check if folder exists\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(\n",
    "                f\"Warning: Folder does not exist: {folder_path}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Regular expression to extract years from filenames\n",
    "        pattern = re.compile(r'gl_(\\d{4})_lv95\\.grid')\n",
    "\n",
    "        # Extract available years from filenames\n",
    "        years = sorted({\n",
    "            int(match.group(1))\n",
    "            for filename in os.listdir(folder_path)\n",
    "            if (match := pattern.match(filename))\n",
    "        })\n",
    "\n",
    "        if not years:\n",
    "            print(\n",
    "                f\"Warning: No valid year files found in {folder_path}. Skipping...\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        printed_resolution_normal = False  # Track whether resolution has been printed\n",
    "        printed_resolution_res = False  # Track whether resolution has been printed\n",
    "\n",
    "        for i, year in enumerate(years):\n",
    "            if year < 1951:  # no ERA5 data available before 1951\n",
    "                continue\n",
    "\n",
    "            file_name = f'gl_{year}_lv95.grid'\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            try:\n",
    "                # Load grid file\n",
    "                metadata, grid_data = load_grid_file(file_path)\n",
    "\n",
    "                # Convert to xarray\n",
    "                dem_y = convert_to_xarray_geodata(grid_data, metadata)\n",
    "\n",
    "                # Transform the coordinates to WGS84\n",
    "                dem_wgs84_y = transform_xarray_coords_lv95_to_wgs84(dem_y)\n",
    "\n",
    "                # Create a mask where 'elevation' is not NaN (1 if not NaN, 0 if NaN)\n",
    "                ds_gl = xr.Dataset({'dem': dem_wgs84_y})\n",
    "                ds_gl[\"glacier_mask\"] = ds_gl[\"dem\"].notnull().astype(np.uint8)\n",
    "\n",
    "                # Apply GLAMOS masked topo function\n",
    "                ds = xr_GLAMOS_masked_topo(cfg, sgi_id, ds_gl)\n",
    "\n",
    "                # Print resolution only once for the first valid year\n",
    "                if not printed_resolution_normal:\n",
    "                    dx_m, dy_m = get_res_from_degrees(ds)\n",
    "                    print(f\"ds normal resolution: {dx_m} x {dy_m} meters\")\n",
    "                    printed_resolution_normal = True  # Ensure it doesn't print again\n",
    "\n",
    "                # For small glaciers, save as is:\n",
    "                if dx_m > 20:\n",
    "                    # Coarsen to 50 m resolution\n",
    "                    ds_resampled = coarsenDS(ds, target_res_m=50)\n",
    "\n",
    "                    # Save xarray dataset\n",
    "                    save_path = os.path.join(path_xr_grids,\n",
    "                                             f\"{glacier_name}_{year}.zarr\")\n",
    "\n",
    "                    ds = ds_resampled  # Use the resampled dataset for further processing\n",
    "\n",
    "                    # Print resolution of resampled data only once\n",
    "                    if not printed_resolution_res:\n",
    "                        dx_m, dy_m = get_res_from_degrees(ds_resampled)\n",
    "                        print(\n",
    "                            f\"ds_resampled resolution: {dx_m} x {dy_m} meters\")\n",
    "                        printed_resolution_res = True  # Ensure it doesn't print again\n",
    "\n",
    "                # Save xarray dataset\n",
    "                save_path = os.path.join(path_xr_grids,\n",
    "                                         f\"{glacier_name}_{year}.zarr\")\n",
    "                ds.to_zarr(save_path)\n",
    "\n",
    "                # plot the masked data\n",
    "                if year > 2000:\n",
    "                    fig, axs = plt.subplots(1, 4, figsize=(15, 6))\n",
    "                    ds.masked_aspect.plot(ax=axs[0],\n",
    "                                          cmap='twilight_shifted',\n",
    "                                          add_colorbar=False)\n",
    "                    ds.masked_slope.plot(ax=axs[1],\n",
    "                                         cmap='cividis',\n",
    "                                         add_colorbar=False)\n",
    "                    ds.masked_elev.plot(ax=axs[2],\n",
    "                                        cmap='terrain',\n",
    "                                        add_colorbar=False)\n",
    "                    ds.glacier_mask.plot(ax=axs[3],\n",
    "                                         cmap='binary',\n",
    "                                         add_colorbar=False)\n",
    "                    axs[0].set_title(\"Aspect\")\n",
    "                    axs[1].set_title(\"Slope\")\n",
    "                    axs[2].set_title(\"DEM\")\n",
    "                    axs[3].set_title(\"Glacier mask\")\n",
    "\n",
    "                    # save the figure\n",
    "                    fig_save_path = os.path.join(cfg.dataPath, 'figures', 'topography',\n",
    "                                                 glacier_name,\n",
    "                                                 f\"{glacier_name}_{year}.png\")\n",
    "                    os.makedirs(os.path.dirname(fig_save_path), exist_ok=True)\n",
    "                    plt.savefig(fig_save_path, dpi=300)\n",
    "\n",
    "                    plt.close()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {glacier_name} in {year}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the masked data\n",
    "ds = xr.open_dataset(path_xr_grids + 'plainemorte_2010.zarr')\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 6))\n",
    "ds.masked_aspect.plot(ax=axs[0], cmap='twilight_shifted', add_colorbar=False)\n",
    "ds.masked_slope.plot(ax=axs[1], cmap='cividis', add_colorbar=False)\n",
    "ds.masked_elev.plot(ax=axs[2], cmap='terrain', add_colorbar=False)\n",
    "ds.glacier_mask.plot(ax=axs[3], cmap='binary', add_colorbar=False)\n",
    "\n",
    "axs[0].set_title(\"Aspect\")\n",
    "axs[1].set_title(\"Slope\")\n",
    "axs[2].set_title(\"DEM\")\n",
    "axs[3].set_title(\"Glacier mask\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly masked grids - dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "too_small_glaciers = ['vorab', 'blauschnee', 'joeri']\n",
    "\n",
    "ONLY_GEODETIC_YEARS = True\n",
    "\n",
    "RUN = True\n",
    "if RUN:\n",
    "    os.makedirs(cfg.dataPath + path_glacier_grid_glamos,\n",
    "                exist_ok=True)  # Ensure folder exists\n",
    "    #emptyfolder(cfg.dataPath + path_glacier_grid_glamos)\n",
    "\n",
    "    # for glacier_name in tqdm(years_start_per_gl.keys(),\n",
    "    #                          desc=\"Processing glaciers\"):\n",
    "    for glacier_name in ['clariden']:\n",
    "        if glacier_name in too_small_glaciers:\n",
    "            print(\n",
    "                f\"Skipping {glacier_name}: too small glacier, no aspect & slope\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Get available .zarr files for this glacier\n",
    "        nc_files = [f for f in os.listdir(path_xr_grids) if glacier_name in f]\n",
    "        nc_files.sort()\n",
    "\n",
    "        print(f\"\\nProcessing {glacier_name}: {len(nc_files)} files found\")\n",
    "\n",
    "        if not nc_files:\n",
    "            print(\n",
    "                f\"Warning: No GLAMOS DEM found for {glacier_name}. Skipping...\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        folder_path = os.path.join(cfg.dataPath, path_glacier_grid_glamos,\n",
    "                                   glacier_name)\n",
    "        os.makedirs(folder_path, exist_ok=True)  # Ensure folder exists\n",
    "\n",
    "        # Get existing processed years\n",
    "        existing_files = [\n",
    "            f for f in os.listdir(folder_path)\n",
    "            if re.search(r'_grid_(\\d{4})\\.parquet$', f)\n",
    "        ]\n",
    "        existing_years = {\n",
    "            int(re.search(r'_grid_(\\d{4})\\.parquet$', f).group(1))\n",
    "            for f in existing_files\n",
    "        }\n",
    "\n",
    "        # Get the longest period dynamically for the current glacier\n",
    "        if glacier_name in years_start_per_gl and glacier_name in years_end_per_gl:\n",
    "            geodetic_period = (years_start_per_gl[glacier_name][0],\n",
    "                               years_end_per_gl[glacier_name][-1])\n",
    "            print('Geodetic period:', int(geodetic_period[0]), '-',\n",
    "                  int(geodetic_period[1]))\n",
    "        else:\n",
    "            print(f\"Skipping {glacier_name}: missing start/end years\")\n",
    "            continue\n",
    "\n",
    "        # Identify missing years\n",
    "        missing_years = []\n",
    "        for fileName in nc_files:\n",
    "            match = re.search(r'_(\\d{4})\\.zarr$', fileName)\n",
    "            if match:\n",
    "                year = int(match.group(1))\n",
    "                if ONLY_GEODETIC_YEARS:\n",
    "                    if year >= 1951 and year not in existing_years and year in range(\n",
    "                            geodetic_period[0], geodetic_period[1] + 1):\n",
    "                        missing_years.append((year, fileName))\n",
    "                else:\n",
    "                    if year >= 1951:\n",
    "                        missing_years.append((year, fileName))\n",
    "\n",
    "        if not missing_years:\n",
    "            print(\n",
    "                f\"All years processed for {glacier_name} or no overlap with geodetic period. Skipping...\"\n",
    "            )\n",
    "            continue\n",
    "        else:\n",
    "            print(\n",
    "                f\"Years to process for {glacier_name}: {[y[0] for y in missing_years]}\"\n",
    "            )\n",
    "\n",
    "        for year, fileName in tqdm(missing_years,\n",
    "                                   desc=\"Processing missing years\",\n",
    "                                   leave=False):\n",
    "            fileName = f\"{glacier_name}_{year}.zarr\"\n",
    "            try:\n",
    "                # Load GLAMOS masked grid\n",
    "                file_path = os.path.join(path_xr_grids, fileName)\n",
    "                ds = xr.open_dataset(file_path)\n",
    "\n",
    "                dx_m, dy_m = get_res_from_degrees(ds)\n",
    "                # print(f\"masked grid resolution: {dx_m} x {dy_m} meters\")\n",
    "\n",
    "                # Handle 'clariden' separately due to its unique ID format\n",
    "                sgi_id, rgi_id, rgi_shp = get_rgi_sgi_ids(cfg, glacier_name)\n",
    "\n",
    "                # Skip glacier if required data is missing\n",
    "                if not sgi_id or not rgi_id or not rgi_shp:\n",
    "                    print(\n",
    "                        f\"Warning: Missing SGI ID or RGI shapefile for {glacier_name}. Skipping...\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                # Create glacier grid\n",
    "                df_grid = create_glacier_grid_SGI(glacier_name, year, rgi_id,\n",
    "                                                  ds)\n",
    "                df_grid.reset_index(drop=True, inplace=True)\n",
    "                dataset_grid = mbm.data_processing.Dataset(\n",
    "                    cfg=cfg,\n",
    "                    data=df_grid,\n",
    "                    region_name='CH',\n",
    "                    data_path=cfg.dataPath + path_PMB_GLAMOS_csv)\n",
    "\n",
    "                # Add climate data\n",
    "                era5_climate_data = os.path.join(\n",
    "                    cfg.dataPath, path_ERA5_raw, 'era5_monthly_averaged_data.nc')\n",
    "                geopotential_data = os.path.join(\n",
    "                    cfg.dataPath, path_ERA5_raw, 'era5_geopotential_pressure.nc')\n",
    "                dataset_grid.get_climate_features(\n",
    "                    climate_data=era5_climate_data,\n",
    "                    geopotential_data=geopotential_data,\n",
    "                    change_units=True,\n",
    "                    smoothing_vois={\n",
    "                        'vois_climate': vois_climate,\n",
    "                        'vois_other': ['ALTITUDE_CLIMATE']\n",
    "                    })\n",
    "\n",
    "                # Add potential clear sky radiation\n",
    "                dataset_grid.get_potential_rad(\n",
    "                    os.path.join(cfg.dataPath, path_pcsr, 'zarr/'))\n",
    "\n",
    "                # Process OGGM data\n",
    "                df_y_gl = dataset_grid.data\n",
    "                df_y_gl.rename(columns={'RGIId': 'RGIId_old'}, inplace=True)\n",
    "\n",
    "                # Add RGI IDs through intersection with shapefiles\n",
    "                df_y_gl = mbm.data_processing.utils.get_rgi(\n",
    "                    data=df_y_gl, glacier_outlines=glacier_outline_rgi)\n",
    "\n",
    "                # Drop points without RGI ID\n",
    "                df_y_gl = df_y_gl.dropna(subset=['RGIId'])\n",
    "\n",
    "                # Add OGGM features\n",
    "                voi = [\"hugonnet_dhdt\", \"consensus_ice_thickness\", \"millan_v\"]\n",
    "                df_y_gl = add_OGGM_features(df_y_gl, voi,\n",
    "                                            cfg.dataPath + path_OGGM)\n",
    "\n",
    "                # Add GLWD_ID\n",
    "                df_y_gl['GLWD_ID'] = df_y_gl.apply(\n",
    "                    lambda x: mbm.data_processing.utils.get_hash(\n",
    "                        f\"{x.GLACIER}_{x.YEAR}\"),\n",
    "                    axis=1)\n",
    "                df_y_gl['GLWD_ID'] = df_y_gl['GLWD_ID'].astype(str)\n",
    "\n",
    "                dataset_grid_oggm = mbm.data_processing.Dataset(\n",
    "                    cfg=cfg,\n",
    "                    data=df_y_gl,\n",
    "                    region_name='CH',\n",
    "                    data_path=cfg.dataPath + path_PMB_GLAMOS_csv)\n",
    "\n",
    "                # Convert to monthly time resolution\n",
    "                dataset_grid_oggm.convert_to_monthly(\n",
    "                    meta_data_columns=cfg.metaData,\n",
    "                    vois_climate=vois_climate + ['pcsr'],\n",
    "                    vois_topographical=voi_topographical)\n",
    "\n",
    "                assert 'pcsr' in dataset_grid_oggm.data.columns, \"Missing 'pcsr' column after conversion\"\n",
    "\n",
    "                # Rename columns\n",
    "                df_oggm = dataset_grid_oggm.data\n",
    "                df_oggm.rename(columns={\n",
    "                    'aspect': 'aspect_sgi',\n",
    "                    'slope': 'slope_sgi'\n",
    "                },\n",
    "                               inplace=True)\n",
    "\n",
    "                assert 'POINT_ELEVATION' in df_oggm.columns, \"Missing 'POINT_ELEVATION' column in the final DataFrame\"\n",
    "\n",
    "                # Save gridded dataset\n",
    "                save_path = os.path.join(\n",
    "                    folder_path, f\"{glacier_name}_grid_{year}.parquet\")\n",
    "                df_oggm.to_parquet(save_path,\n",
    "                                   engine=\"pyarrow\",\n",
    "                                   compression=\"snappy\")\n",
    "                print(f\"Saved: {save_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {glacier_name} ({year}): {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GLAMOS masked grid\n",
    "glacier_name = 'adler'\n",
    "year = 2018\n",
    "fileName = '{glacier_name}_{year}.nc'\n",
    "\n",
    "folder_path = os.path.join(cfg.dataPath, path_glacier_grid_glamos,\n",
    "                           glacier_name)\n",
    "# load the dataset\n",
    "df = pd.read_parquet(\n",
    "    os.path.join(folder_path, f\"{glacier_name}_grid_{year}.parquet\"))\n",
    "\n",
    "# Variables of interest\n",
    "voi = [\n",
    "    \"aspect_sgi\",\n",
    "    \"slope_sgi\",\n",
    "]\n",
    "fig, axs = plt.subplots(2, 4, figsize=(15, 10))\n",
    "voi = [\n",
    "    't2m', 'tp', 'ALTITUDE_CLIMATE', 'ELEVATION_DIFFERENCE', 'hugonnet_dhdt',\n",
    "    'consensus_ice_thickness', 'aspect_sgi', 'slope_sgi'\n",
    "]\n",
    "axs = axs.flatten()\n",
    "for i, var in enumerate(voi):\n",
    "    sns.scatterplot(df,\n",
    "                    x='POINT_LON',\n",
    "                    y='POINT_LAT',\n",
    "                    hue=var,\n",
    "                    s=5,\n",
    "                    alpha=0.5,\n",
    "                    palette='twilight_shifted',\n",
    "                    ax=axs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
