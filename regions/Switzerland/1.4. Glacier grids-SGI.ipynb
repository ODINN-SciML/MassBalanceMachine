{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glacier grids from SGI or GLAMOS:\n",
    "\n",
    "Creates monthly grid files for the MBM to make PMB predictions over the whole glacier grid. The files come from the SGI grid and use OGGM topography. Computing takes a long time because of the conversion to monthly format.\n",
    "## Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../')) # Add root of repo to import MBM\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import massbalancemachine as mbm\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import geopandas as gpd\n",
    "\n",
    "# scripts\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "from scripts.plots import *\n",
    "from scripts.geodata import *\n",
    "from scripts.xgb_helpers import *\n",
    "from scripts.config_CH import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)\n",
    "free_up_cuda()  # in case no memory\n",
    "\n",
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "\n",
    "# Climate columns\n",
    "vois_climate = [\n",
    "    't2m', 'tp', 'slhf', 'sshf', 'ssrd', 'fal', 'str', 'u10', 'v10'\n",
    "]\n",
    "# Topographical columns\n",
    "voi_topographical = [\n",
    "    \"aspect\",\n",
    "    \"slope\",\n",
    "    \"hugonnet_dhdt\",\n",
    "    \"consensus_ice_thickness\",\n",
    "    \"millan_v\",\n",
    "    \"topo\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glaciers_glamos_dem = os.listdir(\n",
    "    os.path.join(cfg.dataPath, path_GLAMOS_topo, 'lv95/'))\n",
    "\n",
    "# Glacier outlines:\n",
    "glacier_outline_sgi = gpd.read_file(\n",
    "    os.path.join(cfg.dataPath, path_SGI_topo, 'inventory_sgi2016_r2020',\n",
    "                 'SGI_2016_glaciers_copy.shp'))  # Load the shapefile\n",
    "glacier_outline_rgi = gpd.read_file(cfg.dataPath + path_rgi_outlines)\n",
    "\n",
    "# Sort glaciers by area\n",
    "gl_area = get_gl_area(cfg)\n",
    "gl_area['clariden'] = gl_area['claridenL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodetic_mb = get_geodetic_MB(cfg)\n",
    "\n",
    "# get years per glacier\n",
    "years_start_per_gl = geodetic_mb.groupby(\n",
    "    'glacier_name')['Astart'].unique().apply(list).to_dict()\n",
    "years_end_per_gl = geodetic_mb.groupby('glacier_name')['Aend'].unique().apply(\n",
    "    list).to_dict()\n",
    "\n",
    "periods_per_glacier, geoMB_per_glacier = build_periods_per_glacier(geodetic_mb)\n",
    "periods_per_glacier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 1: SGI (2015) grids (for option 2 see below - GLAMOS grids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine SGI data:\n",
    "### Glacier masks over SGI aspect:\n",
    "This is to check that there is a good overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glacier outlines:\n",
    "glacier_outline_sgi = gpd.read_file(\n",
    "    os.path.join(cfg.dataPath, path_SGI_topo, 'inventory_sgi2016_r2020',\n",
    "                 'SGI_2016_glaciers.shp'))  # Load the shapefile\n",
    "\n",
    "# Clear output folder\n",
    "emptyfolder('figures/SGI_mask/')\n",
    "\n",
    "for glacier_name in tqdm(years_start_per_gl.keys(),\n",
    "                         desc=\"Processing glaciers\"):\n",
    "\n",
    "    # Handle 'clariden' separately due to special ID format\n",
    "    sgi_id, rgi_id, rgi_shp = get_rgi_sgi_ids(cfg, glacier_name)\n",
    "\n",
    "    # Skip if no SGI ID\n",
    "    if not sgi_id:\n",
    "        print(f'No SGI ID found for {glacier_name}')\n",
    "        continue\n",
    "\n",
    "    # Get glacier mask from SGI shapefile\n",
    "    gdf_mask_gl = glacier_outline_sgi[glacier_outline_sgi['sgi-id'] == sgi_id]\n",
    "\n",
    "    # Skip if no glacier mask found\n",
    "    if gdf_mask_gl.empty:\n",
    "        print(f'No glacier mask found for {glacier_name}')\n",
    "        continue\n",
    "\n",
    "    # Locate aspect grid file\n",
    "    aspect_gl = next((f for f in os.listdir(\n",
    "        os.path.join(cfg.dataPath, path_SGI_topo, 'aspect')) if sgi_id in f),\n",
    "                     None)\n",
    "\n",
    "    # Skip if no aspect file found\n",
    "    if not aspect_gl:\n",
    "        print(f'No aspect file found for {glacier_name}')\n",
    "        continue\n",
    "\n",
    "    # Load grid file\n",
    "    metadata_aspect, grid_data_aspect = load_grid_file(\n",
    "        os.path.join(os.path.join(cfg.dataPath, path_SGI_topo, 'aspect'),\n",
    "                     aspect_gl))\n",
    "\n",
    "    # Convert to xarray\n",
    "    aspect = convert_to_xarray_geodata(grid_data_aspect, metadata_aspect)\n",
    "\n",
    "    # Plot the data\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    aspect.plot(ax=ax)\n",
    "    gdf_mask_gl.plot(ax=ax, alpha=0.5)\n",
    "\n",
    "    # Save the figure\n",
    "    output_path = os.path.join('figures', 'SGI_mask', f\"{glacier_name}.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare one example grid of SGI to OGGM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glacier name\n",
    "glacier_name = 'plainemorte'\n",
    "\n",
    "# Get SGI ID and RGI shapefile ID safely\n",
    "try:\n",
    "    sgi_id, rgi_id, rgi_shp = get_rgi_sgi_ids(cfg, glacier_name)\n",
    "except KeyError:\n",
    "    print(f\"Error: {glacier_name} not found in rgi_df\")\n",
    "    sgi_id, rgi_id, rgi_shp = '', '', ''\n",
    "\n",
    "if not sgi_id or not rgi_id or not rgi_shp:\n",
    "    print(f\"Warning: Missing data for {glacier_name}. Skipping...\")\n",
    "else:\n",
    "    # Load SGI masked dataset\n",
    "    ds = xr_SGI_masked_topo(glacier_outline_sgi, sgi_id, cfg)\n",
    "    if ds is None:\n",
    "        print(\n",
    "            f\"Warning: Failed to load SGI dataset for {glacier_name}. Skipping...\"\n",
    "        )\n",
    "    else:\n",
    "        # Load OGGM dataset\n",
    "        oggm_path = os.path.join(cfg.dataPath, path_OGGM, 'xr_grids',\n",
    "                                 f'{rgi_id}.zarr')\n",
    "\n",
    "        try:\n",
    "            ds_oggm = xr.open_zarr(oggm_path)\n",
    "        except FileNotFoundError:\n",
    "            print(\n",
    "                f\"Error: OGGM dataset not found for {glacier_name}. Skipping...\"\n",
    "            )\n",
    "            ds_oggm = None\n",
    "\n",
    "        # Calculate SGI resolution\n",
    "        dx_sgi, dy_sgi = get_res_from_degrees(ds)\n",
    "        print(f\"Cell size of SGI: {dx_sgi:.2f} x {dy_sgi:.2f} meters\")\n",
    "\n",
    "        if ds_oggm is not None:\n",
    "            # Calculate OGGM resolution\n",
    "            dx_oggm = abs(ds_oggm.x[1] - ds_oggm.x[0])\n",
    "            dy_oggm = abs(ds_oggm.y[1] - ds_oggm.y[0])\n",
    "            print(f\"Cell size of OGGM: {dx_oggm:.2f} x {dy_oggm:.2f} meters\")\n",
    "\n",
    "            # Plot the data\n",
    "            fig, axs = plt.subplots(2, 4, figsize=(15, 8))\n",
    "\n",
    "            # SGI Data\n",
    "            ds.masked_aspect.plot(ax=axs[0, 0],\n",
    "                                  cmap='twilight_shifted',\n",
    "                                  add_colorbar=False)\n",
    "            ds.masked_slope.plot(ax=axs[0, 1],\n",
    "                                 cmap='cividis',\n",
    "                                 add_colorbar=False)\n",
    "            ds.masked_elev.plot(ax=axs[0, 2],\n",
    "                                cmap='terrain',\n",
    "                                add_colorbar=False)\n",
    "            ds.glacier_mask.plot(ax=axs[0, 3],\n",
    "                                 cmap='binary',\n",
    "                                 add_colorbar=False)\n",
    "\n",
    "            axs[0, 0].set_title(\"Aspect SGI\")\n",
    "            axs[0, 1].set_title(\"Slope SGI\")\n",
    "            axs[0, 2].set_title(\"DEM SGI\")\n",
    "            axs[0, 3].set_title(\"Glacier mask SGI\")\n",
    "\n",
    "            # OGGM Data\n",
    "            if all(var in ds_oggm\n",
    "                   for var in ['aspect', 'slope', 'topo', 'glacier_mask']):\n",
    "                ds_oggm.aspect.plot(ax=axs[1, 0],\n",
    "                                    cmap='twilight_shifted',\n",
    "                                    add_colorbar=False)\n",
    "                ds_oggm.slope.plot(ax=axs[1, 1],\n",
    "                                   cmap='cividis',\n",
    "                                   add_colorbar=False)\n",
    "                ds_oggm.topo.plot(ax=axs[1, 2],\n",
    "                                  cmap='terrain',\n",
    "                                  add_colorbar=False)\n",
    "                ds_oggm.glacier_mask.plot(ax=axs[1, 3],\n",
    "                                          cmap='binary',\n",
    "                                          add_colorbar=False)\n",
    "\n",
    "                axs[1, 0].set_title(\"Aspect OGGM\")\n",
    "                axs[1, 1].set_title(\"Slope OGGM\")\n",
    "                axs[1, 2].set_title(\"DEM OGGM\")\n",
    "                axs[1, 3].set_title(\"Glacier mask OGGM\")\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Warning: Some OGGM variables are missing in {oggm_path}\")\n",
    "\n",
    "            # Set axis labels\n",
    "            for ax in axs.flatten():\n",
    "                ax.set_xlabel(\"x\")\n",
    "                ax.set_ylabel(\"y\")\n",
    "                ax.legend().remove()\n",
    "\n",
    "            # Optimize layout\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample SGI grid:\n",
    "# Coarson to 30 m resolution\n",
    "ds_resampled = coarsenDS(ds)\n",
    "\n",
    "# Calculate resolution\n",
    "dx_m, dy_m = get_res_from_degrees(ds_resampled)\n",
    "print(f\"Cell size of resampled grid: {dx_m:.2f} x {dy_m:.2f} meters\")\n",
    "\n",
    "# Plot resampled grid\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 6))\n",
    "ds_resampled.masked_aspect.plot(ax=axs[0], cmap='twilight_shifted')\n",
    "ds_resampled.masked_slope.plot(ax=axs[1], cmap='cividis', add_colorbar=False)\n",
    "ds_resampled.masked_elev.plot(ax=axs[2], cmap='terrain', add_colorbar=False)\n",
    "ds_resampled.glacier_mask.plot(ax=axs[3], cmap='binary', add_colorbar=False)\n",
    "\n",
    "axs[0].set_title(\"Aspect\")\n",
    "axs[1].set_title(\"Slope\")\n",
    "axs[2].set_title(\"DEM\")\n",
    "axs[3].set_title(\"Glacier mask\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly masked grids - dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the masked topographical arrays per glacier:\n",
    "glacier_list = sorted(years_start_per_gl.keys())\n",
    "RUN = False\n",
    "if RUN:\n",
    "    create_sgi_topo_masks(cfg,\n",
    "                          glacier_list,\n",
    "                          type='glacier_name',\n",
    "                          path_save=os.path.join(cfg.dataPath, path_SGI_topo,\n",
    "                                                 'xr_masked_grids/'))\n",
    "\n",
    "# open an example:\n",
    "xr.open_zarr(\n",
    "    os.path.join(cfg.dataPath, path_SGI_topo, 'xr_masked_grids/',\n",
    "                 'aletsch.zarr')).masked_aspect.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN = False\n",
    "path_xr_grids = os.path.join(cfg.dataPath, path_SGI_topo, 'xr_masked_grids')\n",
    "\n",
    "# Sort glaciers by area\n",
    "gl_area = get_gl_area(cfg)\n",
    "gl_area['clariden'] = gl_area['claridenL']\n",
    "\n",
    "\n",
    "# Sort the lists by area if available in gl_area\n",
    "def sort_by_area(glacier_list, gl_area):\n",
    "    return sorted(glacier_list, key=lambda g: gl_area.get(g, 0), reverse=False)\n",
    "\n",
    "\n",
    "glacier_list = sort_by_area(years_start_per_gl.keys(), gl_area)\n",
    "\n",
    "if RUN:\n",
    "    emptyfolder(cfg.dataPath + path_glacier_grid_sgi)\n",
    "    for glacier_name in tqdm(glacier_list, desc=\"Processing glaciers\"):\n",
    "        folder_path = os.path.join(cfg.dataPath, path_glacier_grid_sgi,\n",
    "                                   glacier_name)\n",
    "        os.makedirs(folder_path, exist_ok=True)  # Ensure folder exists\n",
    "\n",
    "        # Get existing processed years\n",
    "        existing_files = [\n",
    "            f for f in os.listdir(folder_path)\n",
    "            if re.search(r'_grid_(\\d{4})\\.parquet$', f)\n",
    "        ]\n",
    "        existing_years = {\n",
    "            int(re.search(r'_grid_(\\d{4})\\.parquet$', f).group(1))\n",
    "            for f in existing_files\n",
    "        }\n",
    "\n",
    "        print(f\"\\nProcessing {glacier_name}:\")\n",
    "        # Get the longest period dynamically for the current glacier\n",
    "        if glacier_name in years_start_per_gl and glacier_name in years_end_per_gl:\n",
    "            geodetic_period = (years_start_per_gl[glacier_name][0],\n",
    "                               years_end_per_gl[glacier_name][-1])\n",
    "            print('Geodetic period:', int(geodetic_period[0]), '-',\n",
    "                  int(geodetic_period[1]))\n",
    "        else:\n",
    "            print(f\"Skipping {glacier_name}: missing start/end years\")\n",
    "            continue\n",
    "\n",
    "        # Get available .zarr files for this glacier\n",
    "        nc_files = [f for f in os.listdir(path_xr_grids) if glacier_name in f]\n",
    "        nc_files.sort()\n",
    "\n",
    "        if not nc_files:\n",
    "            print(f\"Warning: No DEM found for {glacier_name}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        sgi_id, rgi_id, rgi_shp = get_rgi_sgi_ids(cfg, glacier_name)\n",
    "\n",
    "        for year in tqdm(range(geodetic_period[0], geodetic_period[1] + 1),\n",
    "                         desc='years',\n",
    "                         leave=False):\n",
    "            # print(f\"  - Processing year: {year}\")\n",
    "\n",
    "            # Skip glacier if required data is missing\n",
    "            if not sgi_id or not rgi_id or not rgi_shp:\n",
    "                print(\n",
    "                    f\"Warning: Missing SGI ID or RGI shapefile for {glacier_name}. Skipping...\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Load SGI masked grid (previously resampled)\n",
    "            try:\n",
    "                path_save = os.path.join(cfg.dataPath, path_SGI_topo,\n",
    "                                         'xr_masked_grids/')\n",
    "                path = os.path.join(path_save, f\"{glacier_name}.zarr\")\n",
    "                ds_coarsened = xr.open_zarr(path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading dataset for {glacier_name}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Create glacier grid\n",
    "            try:\n",
    "                df_grid = create_glacier_grid_SGI(glacier_name, year, rgi_id,\n",
    "                                                  ds_coarsened)\n",
    "                df_grid.reset_index(drop=True, inplace=True)\n",
    "                dataset_grid = mbm.data_processing.Dataset(\n",
    "                    cfg=cfg,\n",
    "                    data=df_grid,\n",
    "                    region_name='CH',\n",
    "                    region_id=11,\n",
    "                    data_path=cfg.dataPath + path_PMB_GLAMOS_csv)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"Error creating glacier grid for {glacier_name} in {year}: {e}\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Add climate data\n",
    "            try:\n",
    "                era5_climate_data = os.path.join(\n",
    "                    cfg.dataPath, path_ERA5_raw,\n",
    "                    'era5_monthly_averaged_data.nc')\n",
    "                geopotential_data = os.path.join(\n",
    "                    cfg.dataPath, path_ERA5_raw,\n",
    "                    'era5_geopotential_pressure.nc')\n",
    "                dataset_grid.get_climate_features(\n",
    "                    climate_data=era5_climate_data,\n",
    "                    geopotential_data=geopotential_data,\n",
    "                    change_units=True,\n",
    "                    smoothing_vois={\n",
    "                        'vois_climate': vois_climate,\n",
    "                        'vois_other': ['ALTITUDE_CLIMATE']\n",
    "                    })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"Error adding climate data for {glacier_name} in {year}: {e}\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Add potential clear sky radiation\n",
    "            try:\n",
    "                dataset_grid.get_potential_rad(\n",
    "                    os.path.join(cfg.dataPath, path_pcsr, 'zarr/'))\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"Error adding clear sky radiation for {glacier_name} in {year}: {e}\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Add OGGM topographic data\n",
    "            try:\n",
    "                df_y_gl = dataset_grid.data\n",
    "                df_y_gl.rename(columns={'RGIId': 'RGIId_old'}, inplace=True)\n",
    "\n",
    "                # Add RGI IDs for OGGM data through intersection with shapefiles\n",
    "                df_y_gl = mbm.data_processing.utils.get_rgi(\n",
    "                    data=df_y_gl, glacier_outlines=glacier_outline_rgi)\n",
    "\n",
    "                # Drop points without RGI ID (outside of RGI outlines)\n",
    "                df_y_gl = df_y_gl.dropna(subset=['RGIId'])\n",
    "\n",
    "                # Variables of interest\n",
    "                voi = [\"hugonnet_dhdt\", \"consensus_ice_thickness\", \"millan_v\"]\n",
    "\n",
    "                df_y_gl = add_OGGM_features(df_y_gl, voi,\n",
    "                                            cfg.dataPath + path_OGGM)\n",
    "\n",
    "                # Add GLWD_ID\n",
    "                df_y_gl['GLWD_ID'] = df_y_gl.apply(\n",
    "                    lambda x: mbm.data_processing.utils.get_hash(\n",
    "                        f\"{x.GLACIER}_{x.YEAR}\"),\n",
    "                    axis=1)\n",
    "                df_y_gl['GLWD_ID'] = df_y_gl['GLWD_ID'].astype(str)\n",
    "\n",
    "                dataset_grid = mbm.data_processing.Dataset(\n",
    "                    cfg=cfg,\n",
    "                    data=df_y_gl,\n",
    "                    region_name='CH',\n",
    "                    region_id=11,\n",
    "                    data_path=cfg.dataPath + path_PMB_GLAMOS_csv)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"Error adding OGGM data for {glacier_name} in {year}: {e}\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Convert to monthly time resolution\n",
    "            try:\n",
    "                dataset_grid.convert_to_monthly(\n",
    "                    meta_data_columns=cfg.metaData,\n",
    "                    vois_climate=vois_climate + ['pcsr'],\n",
    "                    vois_topographical=voi_topographical)\n",
    "                assert 'pcsr' in dataset_grid.data.columns, \"Missing 'pcsr' column after conversion\"\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"Error converting to monthly resolution for {glacier_name} in {year}: {e}\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Rename columns (because slope & aspect not from OGGM)\n",
    "            df_oggm = dataset_grid.data\n",
    "            df_oggm.rename(columns={\n",
    "                'aspect': 'aspect_sgi',\n",
    "                'slope': 'slope_sgi'\n",
    "            },\n",
    "                           inplace=True)\n",
    "\n",
    "            # Save gridded dataset\n",
    "            save_path = os.path.join(folder_path,\n",
    "                                     f\"{glacier_name}_grid_{year}.parquet\")\n",
    "\n",
    "            try:\n",
    "                # dataset_grid.data.to_csv(save_path, index=False)\n",
    "                df_oggm.to_parquet(save_path,\n",
    "                                   engine=\"pyarrow\",\n",
    "                                   compression=\"snappy\")\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"Error saving dataset for {glacier_name} in {year}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all OGGM variables\n",
    "glacier_name = 'aletsch'\n",
    "year = 2008\n",
    "\n",
    "df = pd.read_parquet(\n",
    "    os.path.join(cfg.dataPath, path_glacier_grid_sgi,\n",
    "                 f\"{glacier_name}/{glacier_name}_grid_{year}.parquet\"))\n",
    "df = df[df.MONTHS == 'sep']\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "voi = [\n",
    "    't2m', 'tp', 'ALTITUDE_CLIMATE', 'ELEVATION_DIFFERENCE', 'hugonnet_dhdt',\n",
    "    'consensus_ice_thickness'\n",
    "]\n",
    "axs = axs.flatten()\n",
    "for i, var in enumerate(voi):\n",
    "    sns.scatterplot(df,\n",
    "                    x='POINT_LON',\n",
    "                    y='POINT_LAT',\n",
    "                    hue=var,\n",
    "                    s=5,\n",
    "                    alpha=0.5,\n",
    "                    palette='twilight_shifted',\n",
    "                    ax=axs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2: GLAMOS grids:\n",
    "\n",
    "For the geodetic MB and gridded MB products computed by GLAMOS, they did not use the SGI grids (from 2015) but their own yearly DEMs. They're not available for all years, but we still compute monthly grids for these available glaciers and years, in order to make the comparison with geodetic MB fairer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdirs, rgidf = initialize_oggm_glacier_directories(\n",
    "    cfg,\n",
    "    rgi_region=\"11\",\n",
    "    rgi_version=\"6\",\n",
    "    base_url=\n",
    "    \"https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.1/elev_bands/W5E5_w_data/\",\n",
    "    log_level='WARNING',\n",
    "    task_list=None,\n",
    ")\n",
    "export_oggm_grids(cfg, gdirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of one glacier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script to convert lv03 to lv95 for Findelen\n",
    "# glacier_name = 'findelen'\n",
    "# sgi_id, rgi_id, rgi_shp = get_rgi_sgi_ids(glacier_name)\n",
    "\n",
    "# folder_path = os.path.join(path_GLAMOS_topo, 'lv03', glacier_name)\n",
    "\n",
    "# for fileName in os.listdir(folder_path):\n",
    "#     year = int(fileName.split('_')[1].split('.grid')[0])  # Extract year from filename\n",
    "\n",
    "#     # Example file\n",
    "#     metadata, grid_data = load_grid_file(folder_path + '/' + fileName)\n",
    "\n",
    "#     # Convert to xarray\n",
    "#     dem_y = convert_to_xarray_geodata(grid_data, metadata)\n",
    "\n",
    "#     dem_lv95_y = transform_xarray_coords_lv03_to_lv95(dem_y)\n",
    "\n",
    "#     # save to lv95 folder:\n",
    "#     filepath = os.path.join(path_GLAMOS_topo, 'lv95', glacier_name, f'gl_{year}_lv95.grid')\n",
    "\n",
    "#     save_xarray_to_grid(dem_lv95_y, filepath, nodata_value=-9999)\n",
    "\n",
    "# dem_lv95_y.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_name = 'plainemorte'\n",
    "sgi_id, rgi_id, rgi_shp = get_rgi_sgi_ids(cfg, glacier_name)\n",
    "\n",
    "folder_path = os.path.join(cfg.dataPath, path_GLAMOS_topo, 'lv95',\n",
    "                           glacier_name)\n",
    "\n",
    "# Example file\n",
    "fileName = 'gl_2023_lv95.grid'\n",
    "metadata, grid_data = load_grid_file(folder_path + '/' + fileName)\n",
    "\n",
    "# Convert to xarray\n",
    "dem_y = convert_to_xarray_geodata(grid_data, metadata)\n",
    "\n",
    "# Transform the coordinates to WGS84\n",
    "dem_wgs84_y = transform_xarray_coords_lv95_to_wgs84(dem_y)\n",
    "\n",
    "# Create a mask where 'elevation' is not NaN (1 if not NaN, 0 if NaN)\n",
    "ds_gl = xr.Dataset({'dem': dem_wgs84_y})\n",
    "ds_gl[\"glacier_mask\"] = ds_gl[\"dem\"].notnull().astype(np.uint8)\n",
    "\n",
    "dx = abs(ds_gl.x[1] - ds_gl.x[0]).values\n",
    "dy = abs(ds_gl.y[1] - ds_gl.y[0]).values\n",
    "print(f\"Cell size of GLAMOS DEM: {dx} x {dy} meters\")\n",
    "\n",
    "#Â Extract SGI topo and aspect over GLAMOS DEM\n",
    "ds = xr_GLAMOS_masked_topo(cfg, sgi_id, ds_gl)\n",
    "\n",
    "# Coarson to 50 m resolution if needed\n",
    "ds = coarsenDS(ds)\n",
    "dx_m, dy_m = get_res_from_degrees(ds)\n",
    "print(f\"Coarsened ds resolution: {dx_m} x {dy_m} meters\")\n",
    "\n",
    "# Plot the masked data\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 6))\n",
    "ds.masked_aspect.plot(ax=axs[0], cmap='twilight_shifted', add_colorbar=False)\n",
    "ds.masked_slope.plot(ax=axs[1], cmap='cividis', add_colorbar=False)\n",
    "ds.masked_elev.plot(ax=axs[2], cmap='terrain', add_colorbar=False)\n",
    "ds.glacier_mask.plot(ax=axs[3], cmap='binary', add_colorbar=False)\n",
    "\n",
    "axs[0].set_title(\"Aspect\")\n",
    "axs[1].set_title(\"Slope\")\n",
    "axs[2].set_title(\"DEM\")\n",
    "axs[3].set_title(\"Glacier mask\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yearly masked grids - xarrays:\n",
    "Save a .zarr xarray per glacier per year (not in monthly format) needed in the MBM later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define save path and ensure it exists\n",
    "RUN = True\n",
    "\n",
    "path_xr_grids = os.path.join(cfg.dataPath, path_GLAMOS_topo,\n",
    "                             'xr_masked_grids/')\n",
    "glaciers_glamos_dems = os.listdir(\n",
    "    os.path.join(cfg.dataPath, path_GLAMOS_topo, 'lv95'))\n",
    "\n",
    "if RUN:\n",
    "    emptyfolder(path_xr_grids)\n",
    "    for glacier_name in tqdm(glaciers_glamos_dems, desc=\"Processing glaciers\"):\n",
    "        print(f\"\\nProcessing {glacier_name}...\")\n",
    "\n",
    "        # Handle 'clariden' separately due to special ID format\n",
    "        sgi_id, rgi_id, rgi_shp = get_rgi_sgi_ids(cfg, glacier_name)\n",
    "\n",
    "        # Skip glacier if required data is missing\n",
    "        if not sgi_id or not rgi_shp:\n",
    "            print(\n",
    "                f\"Warning: Missing SGI ID or shapefile for {glacier_name}. Skipping...\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Define glacier folder path\n",
    "        folder_path = os.path.join(\n",
    "            cfg.dataPath, path_GLAMOS_topo, 'lv95',\n",
    "            'stanna' if glacier_name == 'sanktanna' else glacier_name)\n",
    "\n",
    "        # Check if folder exists\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(\n",
    "                f\"Warning: Folder does not exist: {folder_path}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Regular expression to extract years from filenames\n",
    "        pattern = re.compile(r'gl_(\\d{4})_lv95\\.grid')\n",
    "\n",
    "        # Extract available years from filenames\n",
    "        years = sorted({\n",
    "            int(match.group(1))\n",
    "            for filename in os.listdir(folder_path)\n",
    "            if (match := pattern.match(filename))\n",
    "        })\n",
    "\n",
    "        if not years:\n",
    "            print(\n",
    "                f\"Warning: No valid year files found in {folder_path}. Skipping...\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        printed_resolution_normal = False  # Track whether resolution has been printed\n",
    "        printed_resolution_res = False  # Track whether resolution has been printed\n",
    "\n",
    "        for i, year in enumerate(years):\n",
    "            if year < 1951:  # no ERA5 data available before 1951\n",
    "                continue\n",
    "\n",
    "            file_name = f'gl_{year}_lv95.grid'\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            try:\n",
    "                # Load grid file\n",
    "                metadata, grid_data = load_grid_file(file_path)\n",
    "\n",
    "                # Convert to xarray\n",
    "                dem_y = convert_to_xarray_geodata(grid_data, metadata)\n",
    "\n",
    "                # Transform the coordinates to WGS84\n",
    "                dem_wgs84_y = transform_xarray_coords_lv95_to_wgs84(dem_y)\n",
    "\n",
    "                # Create a mask where 'elevation' is not NaN (1 if not NaN, 0 if NaN)\n",
    "                ds_gl = xr.Dataset({'dem': dem_wgs84_y})\n",
    "                ds_gl[\"glacier_mask\"] = ds_gl[\"dem\"].notnull().astype(np.uint8)\n",
    "\n",
    "                # Apply GLAMOS masked topo function\n",
    "                ds = xr_GLAMOS_masked_topo(cfg, sgi_id, ds_gl)\n",
    "\n",
    "                # Print resolution only once for the first valid year\n",
    "                if not printed_resolution_normal:\n",
    "                    dx_m, dy_m = get_res_from_degrees(ds)\n",
    "                    print(f\"ds normal resolution: {dx_m} x {dy_m} meters\")\n",
    "                    printed_resolution_normal = True  # Ensure it doesn't print again\n",
    "\n",
    "                # For small glaciers, save as is:\n",
    "                if dx_m > 20:\n",
    "                    # Coarsen to 50 m resolution\n",
    "                    ds_resampled = coarsenDS(ds, target_res_m=50)\n",
    "\n",
    "                    # Save xarray dataset\n",
    "                    save_path = os.path.join(path_xr_grids,\n",
    "                                             f\"{glacier_name}_{year}.zarr\")\n",
    "\n",
    "                    ds = ds_resampled  # Use the resampled dataset for further processing\n",
    "\n",
    "                    # Print resolution of resampled data only once\n",
    "                    if not printed_resolution_res:\n",
    "                        dx_m, dy_m = get_res_from_degrees(ds_resampled)\n",
    "                        print(\n",
    "                            f\"ds_resampled resolution: {dx_m} x {dy_m} meters\")\n",
    "                        printed_resolution_res = True  # Ensure it doesn't print again\n",
    "\n",
    "                # Save xarray dataset\n",
    "                save_path = os.path.join(path_xr_grids,\n",
    "                                         f\"{glacier_name}_{year}.zarr\")\n",
    "                ds.to_zarr(save_path)\n",
    "\n",
    "                # plot the masked data\n",
    "                if year > 2000:\n",
    "                    fig, axs = plt.subplots(1, 4, figsize=(15, 6))\n",
    "                    ds.masked_aspect.plot(ax=axs[0],\n",
    "                                          cmap='twilight_shifted',\n",
    "                                          add_colorbar=False)\n",
    "                    ds.masked_slope.plot(ax=axs[1],\n",
    "                                         cmap='cividis',\n",
    "                                         add_colorbar=False)\n",
    "                    ds.masked_elev.plot(ax=axs[2],\n",
    "                                        cmap='terrain',\n",
    "                                        add_colorbar=False)\n",
    "                    ds.glacier_mask.plot(ax=axs[3],\n",
    "                                         cmap='binary',\n",
    "                                         add_colorbar=False)\n",
    "                    axs[0].set_title(\"Aspect\")\n",
    "                    axs[1].set_title(\"Slope\")\n",
    "                    axs[2].set_title(\"DEM\")\n",
    "                    axs[3].set_title(\"Glacier mask\")\n",
    "\n",
    "                    # save the figure\n",
    "                    fig_save_path = os.path.join(cfg.dataPath, 'figures',\n",
    "                                                 'topography', glacier_name,\n",
    "                                                 f\"{glacier_name}_{year}.png\")\n",
    "                    os.makedirs(os.path.dirname(fig_save_path), exist_ok=True)\n",
    "                    plt.savefig(fig_save_path, dpi=300)\n",
    "\n",
    "                    plt.close()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {glacier_name} in {year}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the masked data\n",
    "ds = xr.open_zarr(path_xr_grids + 'plainemorte_2010.zarr')\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 6))\n",
    "ds.masked_aspect.plot(ax=axs[0], cmap='twilight_shifted', add_colorbar=True)\n",
    "ds.masked_slope.plot(ax=axs[1], cmap='cividis', add_colorbar=True)\n",
    "ds.masked_elev.plot(ax=axs[2], cmap='terrain', add_colorbar=True)\n",
    "ds.glacier_mask.plot(ax=axs[3], cmap='binary', add_colorbar=False)\n",
    "\n",
    "axs[0].set_title(\"Aspect\")\n",
    "axs[1].set_title(\"Slope\")\n",
    "axs[2].set_title(\"DEM\")\n",
    "axs[3].set_title(\"Glacier mask\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly masked grids - dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "too_small_glaciers = ['vorab', 'blauschnee', 'joeri']\n",
    "\n",
    "ONLY_GEODETIC_YEARS = True\n",
    "\n",
    "RUN = False\n",
    "if RUN:\n",
    "    os.makedirs(cfg.dataPath + path_glacier_grid_glamos,\n",
    "                exist_ok=True)  # Ensure folder exists\n",
    "    #emptyfolder(cfg.dataPath + path_glacier_grid_glamos)\n",
    "\n",
    "    # for glacier_name in tqdm(years_start_per_gl.keys(),\n",
    "    #                          desc=\"Processing glaciers\"):\n",
    "    for glacier_name in ['aletsch']:\n",
    "        if glacier_name in too_small_glaciers:\n",
    "            print(\n",
    "                f\"Skipping {glacier_name}: too small glacier, no aspect & slope\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Get available .zarr files for this glacier\n",
    "        nc_files = [f for f in os.listdir(path_xr_grids) if glacier_name in f]\n",
    "        nc_files.sort()\n",
    "\n",
    "        print(f\"\\nProcessing {glacier_name}: {len(nc_files)} files found\")\n",
    "\n",
    "        if not nc_files:\n",
    "            print(\n",
    "                f\"Warning: No GLAMOS DEM found for {glacier_name}. Skipping...\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        folder_path = os.path.join(cfg.dataPath, path_glacier_grid_glamos,\n",
    "                                   glacier_name)\n",
    "        os.makedirs(folder_path, exist_ok=True)  # Ensure folder exists\n",
    "\n",
    "        # Get existing processed years\n",
    "        existing_files = [\n",
    "            f for f in os.listdir(folder_path)\n",
    "            if re.search(r'_grid_(\\d{4})\\.parquet$', f)\n",
    "        ]\n",
    "        existing_years = {\n",
    "            int(re.search(r'_grid_(\\d{4})\\.parquet$', f).group(1))\n",
    "            for f in existing_files\n",
    "        }\n",
    "\n",
    "        # Get the longest period dynamically for the current glacier\n",
    "        if glacier_name in years_start_per_gl and glacier_name in years_end_per_gl:\n",
    "            geodetic_period = (years_start_per_gl[glacier_name][0],\n",
    "                               years_end_per_gl[glacier_name][-1])\n",
    "            print('Geodetic period:', int(geodetic_period[0]), '-',\n",
    "                  int(geodetic_period[1]))\n",
    "        else:\n",
    "            print(f\"Skipping {glacier_name}: missing start/end years\")\n",
    "            continue\n",
    "\n",
    "        # Identify missing years\n",
    "        missing_years = []\n",
    "        for fileName in nc_files:\n",
    "            match = re.search(r'_(\\d{4})\\.zarr$', fileName)\n",
    "            if match:\n",
    "                year = int(match.group(1))\n",
    "                if ONLY_GEODETIC_YEARS:\n",
    "                    if year >= 1951 and year not in existing_years and year in range(\n",
    "                            geodetic_period[0], geodetic_period[1] + 1):\n",
    "                        missing_years.append((year, fileName))\n",
    "                else:\n",
    "                    if year >= 1951:\n",
    "                        missing_years.append((year, fileName))\n",
    "\n",
    "        if not missing_years:\n",
    "            print(\n",
    "                f\"All years processed for {glacier_name} or no overlap with geodetic period. Skipping...\"\n",
    "            )\n",
    "            continue\n",
    "        else:\n",
    "            print(\n",
    "                f\"Years to process for {glacier_name}: {[y[0] for y in missing_years]}\"\n",
    "            )\n",
    "\n",
    "        for year, fileName in tqdm(missing_years,\n",
    "                                   desc=\"Processing missing years\",\n",
    "                                   leave=False):\n",
    "            fileName = f\"{glacier_name}_{year}.zarr\"\n",
    "            try:\n",
    "                # Load GLAMOS masked grid\n",
    "                file_path = os.path.join(path_xr_grids, fileName)\n",
    "                ds = xr.open_zarr(file_path)\n",
    "\n",
    "                dx_m, dy_m = get_res_from_degrees(ds)\n",
    "                # print(f\"masked grid resolution: {dx_m} x {dy_m} meters\")\n",
    "\n",
    "                # Handle 'clariden' separately due to its unique ID format\n",
    "                sgi_id, rgi_id, rgi_shp = get_rgi_sgi_ids(cfg, glacier_name)\n",
    "\n",
    "                # Skip glacier if required data is missing\n",
    "                if not sgi_id or not rgi_id or not rgi_shp:\n",
    "                    print(\n",
    "                        f\"Warning: Missing SGI ID or RGI shapefile for {glacier_name}. Skipping...\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                # Create glacier grid\n",
    "                df_grid = create_glacier_grid_SGI(glacier_name, year, rgi_id,\n",
    "                                                  ds)\n",
    "                df_grid.reset_index(drop=True, inplace=True)\n",
    "                dataset_grid = mbm.data_processing.Dataset(\n",
    "                    cfg=cfg,\n",
    "                    data=df_grid,\n",
    "                    region_name='CH',\n",
    "                    region_id=11,\n",
    "                    data_path=cfg.dataPath + path_PMB_GLAMOS_csv)\n",
    "\n",
    "                # Add climate data\n",
    "                era5_climate_data = os.path.join(\n",
    "                    cfg.dataPath, path_ERA5_raw,\n",
    "                    'era5_monthly_averaged_data.nc')\n",
    "                geopotential_data = os.path.join(\n",
    "                    cfg.dataPath, path_ERA5_raw,\n",
    "                    'era5_geopotential_pressure.nc')\n",
    "                dataset_grid.get_climate_features(\n",
    "                    climate_data=era5_climate_data,\n",
    "                    geopotential_data=geopotential_data,\n",
    "                    change_units=True,\n",
    "                    smoothing_vois={\n",
    "                        'vois_climate': vois_climate,\n",
    "                        'vois_other': ['ALTITUDE_CLIMATE']\n",
    "                    })\n",
    "\n",
    "                # Add potential clear sky radiation\n",
    "                dataset_grid.get_potential_rad(\n",
    "                    os.path.join(cfg.dataPath, path_pcsr, 'zarr/'))\n",
    "\n",
    "                # Process OGGM data\n",
    "                df_y_gl = dataset_grid.data\n",
    "                df_y_gl.rename(columns={'RGIId': 'RGIId_old'}, inplace=True)\n",
    "\n",
    "                # Add RGI IDs through intersection with shapefiles\n",
    "                df_y_gl = mbm.data_processing.utils.get_rgi(\n",
    "                    data=df_y_gl, glacier_outlines=glacier_outline_rgi)\n",
    "\n",
    "                # Drop points without RGI ID\n",
    "                df_y_gl = df_y_gl.dropna(subset=['RGIId'])\n",
    "\n",
    "                # Add OGGM features\n",
    "                voi = [\"hugonnet_dhdt\", \"consensus_ice_thickness\", \"millan_v\"]\n",
    "                df_y_gl = add_OGGM_features(df_y_gl, voi,\n",
    "                                            cfg.dataPath + path_OGGM)\n",
    "\n",
    "                # Add GLWD_ID\n",
    "                df_y_gl['GLWD_ID'] = df_y_gl.apply(\n",
    "                    lambda x: mbm.data_processing.utils.get_hash(\n",
    "                        f\"{x.GLACIER}_{x.YEAR}\"),\n",
    "                    axis=1)\n",
    "                df_y_gl['GLWD_ID'] = df_y_gl['GLWD_ID'].astype(str)\n",
    "\n",
    "                dataset_grid_oggm = mbm.data_processing.Dataset(\n",
    "                    cfg=cfg,\n",
    "                    data=df_y_gl,\n",
    "                    region_name='CH',\n",
    "                    region_id=11,\n",
    "                    data_path=cfg.dataPath + path_PMB_GLAMOS_csv)\n",
    "\n",
    "                # Convert to monthly time resolution\n",
    "                dataset_grid_oggm.convert_to_monthly(\n",
    "                    meta_data_columns=cfg.metaData,\n",
    "                    vois_climate=vois_climate + ['pcsr'],\n",
    "                    vois_topographical=voi_topographical)\n",
    "\n",
    "                assert 'pcsr' in dataset_grid_oggm.data.columns, \"Missing 'pcsr' column after conversion\"\n",
    "\n",
    "                # Rename columns\n",
    "                df_oggm = dataset_grid_oggm.data\n",
    "                df_oggm.rename(columns={\n",
    "                    'aspect': 'aspect_sgi',\n",
    "                    'slope': 'slope_sgi'\n",
    "                },\n",
    "                               inplace=True)\n",
    "\n",
    "                assert 'POINT_ELEVATION' in df_oggm.columns, \"Missing 'POINT_ELEVATION' column in the final DataFrame\"\n",
    "\n",
    "                # Save gridded dataset\n",
    "                save_path = os.path.join(\n",
    "                    folder_path, f\"{glacier_name}_grid_{year}.parquet\")\n",
    "                df_oggm.to_parquet(save_path,\n",
    "                                   engine=\"pyarrow\",\n",
    "                                   compression=\"snappy\")\n",
    "                print(f\"Saved: {save_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {glacier_name} ({year}): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset_grid.data.copy()\n",
    "df = df[df.YEAR == 2008]\n",
    "fig, axs = plt.subplots(1, 5, figsize=(20, 10))\n",
    "voi = [\n",
    "    't2m_sep', 'tp_sep', 'ELEVATION_DIFFERENCE', 'aspect', 'slope', \n",
    "]\n",
    "axs = axs.flatten()\n",
    "for i, var in enumerate(voi):\n",
    "    sns.scatterplot(df,\n",
    "                    x='POINT_LON',\n",
    "                    y='POINT_LAT',\n",
    "                    hue=var,\n",
    "                    s=5,\n",
    "                    alpha=0.5,\n",
    "                    palette='twilight_shifted',\n",
    "                    ax=axs[i])\n",
    "    axs[i].set_title(var)\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stake data ONCE instead of for every glacier\n",
    "stake_file = os.path.join(cfg.dataPath, path_PMB_GLAMOS_csv,\n",
    "                          \"CH_wgms_dataset_all.csv\")\n",
    "df_stakes = pd.read_csv(stake_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GLAMOS masked grid\n",
    "glacier_name = 'schwarzberg'\n",
    "year = 2018\n",
    "\n",
    "month = 'sep'  # Example month, adjust as needed\n",
    "\n",
    "folder_path = os.path.join(cfg.dataPath, path_glacier_grid_glamos,\n",
    "                           glacier_name)\n",
    "# load the dataset\n",
    "df = pd.read_parquet(\n",
    "    os.path.join(folder_path, f\"{glacier_name}_grid_{year}.parquet\"))\n",
    "df = df[df.MONTHS == month]\n",
    "\n",
    "stake_locs = df_stakes[df_stakes.GLACIER == glacier_name]\n",
    "\n",
    "# Variables of interest\n",
    "voi = [\n",
    "    \"aspect_sgi\",\n",
    "    \"slope_sgi\",\n",
    "]\n",
    "fig, axs = plt.subplots(3, 4, figsize=(15, 10))\n",
    "voi = [\n",
    "    't2m', 'tp', 'ELEVATION_DIFFERENCE', 'hugonnet_dhdt',\n",
    "    'consensus_ice_thickness', 'millan_v', 'aspect_sgi', 'slope_sgi', 'pcsr'\n",
    "]\n",
    "axs = axs.flatten()\n",
    "for i, var in enumerate(voi):\n",
    "    sns.scatterplot(df,\n",
    "                    x='POINT_LON',\n",
    "                    y='POINT_LAT',\n",
    "                    hue=var,\n",
    "                    s=5,\n",
    "                    alpha=0.5,\n",
    "                    palette='twilight_shifted',\n",
    "                    ax=axs[i])\n",
    "    axs[i].set_title(var)\n",
    "    \n",
    "\n",
    "    # scatter stake location\n",
    "    sns.scatterplot(stake_locs,\n",
    "                    x='POINT_LON',\n",
    "                    y='POINT_LAT',\n",
    "                    color='red',\n",
    "                    s=10,\n",
    "                    alpha=0.5,\n",
    "                    ax=axs[i])\n",
    "    \n",
    "    # remove legend\n",
    "    #axs[i].legend_.remove()\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible to complete missing GLAMOS DEMs with SGI grids?\n",
    "\n",
    "For DEMs that are missing in the GLAMOS set, complete years with SGI grids."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glaciers completely missing GLAMOS DEMS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "folder_path_sgi = os.path.join(cfg.dataPath, path_glacier_grid_sgi)\n",
    "folder_path_glamos = os.path.join(cfg.dataPath, path_glacier_grid_glamos)\n",
    "folder_path_complete = os.path.join(\n",
    "    cfg.dataPath, 'GLAMOS/topo/gridded_topo_inputs/SGI_and_GLAMOS_grid/')\n",
    "os.makedirs(folder_path_complete, exist_ok=True)\n",
    "emptyfolder(folder_path_complete)\n",
    "\n",
    "\n",
    "def is_folder_empty(path):\n",
    "    return len(os.listdir(path)) == 0\n",
    "\n",
    "\n",
    "# Glacier subfolders\n",
    "subfolders_sgi = sorted([\n",
    "    f for f in os.listdir(folder_path_sgi)\n",
    "    if os.path.isdir(os.path.join(folder_path_sgi, f))\n",
    "])\n",
    "subfolders_glamos = sorted([\n",
    "    f for f in os.listdir(folder_path_glamos)\n",
    "    if os.path.isdir(os.path.join(folder_path_glamos, f))\n",
    "])\n",
    "\n",
    "# --- STEP 1: Copy SGI where GLAMOS is missing or empty ---\n",
    "print(\"Copying SGI folders where GLAMOS is missing or empty:\")\n",
    "missing_glaciers_glamos = []\n",
    "for glacier in subfolders_sgi:\n",
    "    sgi_folder = os.path.join(folder_path_sgi, glacier)\n",
    "    glamos_folder = os.path.join(folder_path_glamos, glacier)\n",
    "    dst = os.path.join(folder_path_complete, glacier)\n",
    "\n",
    "    if (glacier not in subfolders_glamos) or is_folder_empty(glamos_folder):\n",
    "        if not os.path.exists(dst):\n",
    "            try:\n",
    "                shutil.copytree(sgi_folder, dst)\n",
    "                print(f\"Copied {glacier} from SGI to complete path.\")\n",
    "                missing_glaciers_glamos.append(glacier)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to copy {glacier} from SGI: {e}\")\n",
    "\n",
    "# --- STEP 2: Copy all non-empty GLAMOS folders ---\n",
    "print(\"\\nCopying all non-empty GLAMOS folders:\")\n",
    "for glacier in subfolders_glamos:\n",
    "    glamos_folder = os.path.join(folder_path_glamos, glacier)\n",
    "    dst = os.path.join(folder_path_complete, glacier)\n",
    "\n",
    "    if not is_folder_empty(glamos_folder):\n",
    "        if not os.path.exists(\n",
    "                dst):  # Do not overwrite anything already copied from SGI\n",
    "            try:\n",
    "                shutil.copytree(glamos_folder, dst)\n",
    "                print(f\"Copied {glacier} from GLAMOS to complete path.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to copy {glacier} from GLAMOS: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_glaciers_glamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glaciers present in SGI but no GLAMOS DEMs: \n",
    "\n",
    "-'albigna': no, there is no GLAMOS gridded MB predictions, only from 1950-1960\n",
    "- 'corvatsch': no SGI grid is bad quality\n",
    "- 'forno': no, there is no GLAMOS gridded MB predictions, only from 1950-1960\n",
    "- 'gorner': GLAMOS gridded MB predictions\n",
    "- 'joeri': no, no DEM from SGI \n",
    "- 'limmern': no, no DEM from SGI\n",
    "- 'morteratsch': no GLAMOS gridded MB predictions\n",
    "- 'plattalva': no recent GLAMOS gridded MB predictions\n",
    "- 'sanktanna': no SGI grid is bad quality\n",
    "- 'tortin': no GLAMOS gridded MB predictions, only 2023\n",
    "\n",
    "- 'oberaar': might be possible. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PREDICTIONS_NN = cfg.dataPath + path_distributed_MB_glamos + 'MBM/glamos_dems_NN_full/'\n",
    "\n",
    "glacier_name = 'oberaar'\n",
    "start_year = years_start_per_gl[glacier_name][0]\n",
    "end_year = years_end_per_gl[glacier_name][-1]\n",
    "expected_years = set(range(start_year, end_year + 1))\n",
    "\n",
    "for year in expected_years:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 8), sharex=True, sharey=True)\n",
    "\n",
    "    # GLAMOS file path\n",
    "    file_ann = f\"{year}_ann_fix_lv95.grid\"\n",
    "    grid_path_ann = os.path.join(cfg.dataPath, path_distributed_MB_glamos,\n",
    "                                 'GLAMOS', glacier_name, file_ann)\n",
    "    # Load GLAMOS data and convert to WGS84\n",
    "    metadata_ann, grid_data_ann = load_grid_file(grid_path_ann)\n",
    "    ds_glamos_ann = convert_to_xarray_geodata(grid_data_ann, metadata_ann)\n",
    "    ds_glamos_wgs84_ann = transform_xarray_coords_lv95_to_wgs84(ds_glamos_ann)\n",
    "\n",
    "    # GLAMOS plot\n",
    "    ds_glamos_wgs84_ann.plot.imshow(\n",
    "        ax=axes[0], cbar_kwargs={\"label\": \"Mass Balance [m w.e.]\"})\n",
    "    axes[0].set_title(\"GLAMOS (Annual)\")\n",
    "\n",
    "    mbm_file_nn = os.path.join(PATH_PREDICTIONS_NN, glacier_name,\n",
    "                               f\"{glacier_name}_{year}_annual.zarr\")\n",
    "    ds_mbm_nn = apply_gaussian_filter(xr.open_dataset(mbm_file_nn))\n",
    "\n",
    "    ds_mbm_nn.pred_masked.plot.imshow(\n",
    "        ax=axes[1], cbar_kwargs={\"label\": \"Mass Balance [m w.e.]\"})\n",
    "    axes[1].set_title(\"MBM NN (Annual)\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        f\"{glacier_name.capitalize()} Glacier â Annual MB Comparison ({year})\",\n",
    "        fontsize=20)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern to extract year from filename\n",
    "year_pattern = re.compile(r\"_grid_(\\d{4})\\.parquet$\")\n",
    "\n",
    "for glacier_name in years_start_per_gl:\n",
    "    start_year = years_start_per_gl[glacier_name][0]\n",
    "    end_year = years_end_per_gl[glacier_name][-1]\n",
    "    expected_years = set(range(start_year, end_year + 1))\n",
    "\n",
    "    # Glacier folders\n",
    "    folder_glacier_complete = os.path.join(folder_path_complete, glacier_name)\n",
    "    folder_glacier_sgi = os.path.join(folder_path_sgi, glacier_name)\n",
    "\n",
    "    if not os.path.exists(folder_glacier_complete):\n",
    "        print(f\"Complete folder not found for glacier: {glacier_name}\")\n",
    "        continue\n",
    "\n",
    "    # Get years already in the complete folder\n",
    "    found_years = set()\n",
    "    for fname in os.listdir(folder_glacier_complete):\n",
    "        match = year_pattern.search(fname)\n",
    "        if match:\n",
    "            year = int(match.group(1))\n",
    "            found_years.add(year)\n",
    "\n",
    "    missing_years = sorted(expected_years - found_years)\n",
    "\n",
    "    if missing_years:\n",
    "        print(f\"Missing years for glacier {glacier_name}: {missing_years}\")\n",
    "\n",
    "        # Try copying missing files from SGI\n",
    "        for year in missing_years:\n",
    "            pattern = f\"_grid_{year}.parquet\"\n",
    "            try:\n",
    "                matching_files = [\n",
    "                    f for f in os.listdir(folder_glacier_sgi)\n",
    "                    if f.endswith(pattern)\n",
    "                ]\n",
    "                if not matching_files:\n",
    "                    print(f\"  No file found in SGI for year {year}\")\n",
    "                    continue\n",
    "\n",
    "                for fname in matching_files:\n",
    "                    src = os.path.join(folder_glacier_sgi, fname)\n",
    "                    dst = os.path.join(folder_glacier_complete, fname)\n",
    "\n",
    "                    shutil.copy2(src, dst)\n",
    "                    print(f\"  Copied {fname} from SGI to complete path.\")\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"  Error copying year {year} for glacier {glacier_name}: {e}\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PREDICTIONS_NN = cfg.dataPath + path_distributed_MB_glamos + 'MBM/glamos_dems_NN_full/'\n",
    "\n",
    "glacier_name = 'schwarzbach'\n",
    "start_year = years_start_per_gl[glacier_name][0]\n",
    "end_year = years_end_per_gl[glacier_name][-1]\n",
    "expected_years = set(range(start_year, end_year + 1))\n",
    "\n",
    "# expected_years = range(2020, 2024)\n",
    "for year in expected_years:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 8), sharex=True, sharey=True)\n",
    "\n",
    "    # GLAMOS file path\n",
    "    file_ann = f\"{year}_ann_fix_lv95.grid\"\n",
    "    grid_path_ann = os.path.join(cfg.dataPath, path_distributed_MB_glamos,\n",
    "                                 'GLAMOS', glacier_name, file_ann)\n",
    "    # Load GLAMOS data and convert to WGS84\n",
    "    metadata_ann, grid_data_ann = load_grid_file(grid_path_ann)\n",
    "    ds_glamos_ann = convert_to_xarray_geodata(grid_data_ann, metadata_ann)\n",
    "    ds_glamos_wgs84_ann = transform_xarray_coords_lv95_to_wgs84(ds_glamos_ann)\n",
    "\n",
    "    # GLAMOS plot\n",
    "    ds_glamos_wgs84_ann.plot.imshow(\n",
    "        ax=axes[0], cbar_kwargs={\"label\": \"Mass Balance [m w.e.]\"})\n",
    "    axes[0].set_title(\"GLAMOS (Annual)\")\n",
    "\n",
    "    mbm_file_nn = os.path.join(PATH_PREDICTIONS_NN, glacier_name,\n",
    "                               f\"{glacier_name}_{year}_annual.zarr\")\n",
    "    ds_mbm_nn = apply_gaussian_filter(xr.open_dataset(mbm_file_nn))\n",
    "\n",
    "    ds_mbm_nn.pred_masked.plot.imshow(\n",
    "        ax=axes[1], cbar_kwargs={\"label\": \"Mass Balance [m w.e.]\"})\n",
    "    axes[1].set_title(\"MBM NN (Annual)\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        f\"{glacier_name.capitalize()} Glacier â Annual MB Comparison ({year})\",\n",
    "        fontsize=20)\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
