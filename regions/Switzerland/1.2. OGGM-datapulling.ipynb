{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# OGGM - data pulling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pyproj\n",
    "from pyproj import Transformer\n",
    "import salem\n",
    "from tqdm.notebook import tqdm\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from oggm import cfg, utils, workflow, tasks\n",
    "\n",
    "cfg.initialize(logging_level='WARNING')\n",
    "cfg.PARAMS['border'] = 10\n",
    "cfg.PARAMS['use_multiprocessing'] = True\n",
    "cfg.PARAMS['continue_on_error'] = True\n",
    "# Module logger\n",
    "log = logging.getLogger('.'.join(__name__.split('.')[:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Download OGGM data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory\n",
    "working_dir = '../../../data/OGGM/'\n",
    "cfg.PATHS['working_dir'] = working_dir\n",
    "\n",
    "# Set RGI version and region:\n",
    "rgi_region = \"11\"  # Central Europe\n",
    "rgi_version = \"6\"\n",
    "rgi_dir = utils.get_rgi_dir(version=rgi_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = utils.get_rgi_region_file(region=rgi_region, version=rgi_version)\n",
    "rgidf = gpd.read_file(path)\n",
    "\n",
    "# We use the directories with the shop data in it: \"W5E5_w_data\"\n",
    "base_url = \"https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.1/elev_bands/W5E5_w_data/\"\n",
    "gdirs = workflow.init_glacier_directories(\n",
    "    rgidf,\n",
    "    from_prepro_level=3,\n",
    "    prepro_base_url=base_url,\n",
    "    prepro_border=10,\n",
    "    reset=True,\n",
    "    force=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tested tasks\n",
    "task_list = [\n",
    "    tasks.gridded_attributes,\n",
    "    # tasks.gridded_mb_attributes,\n",
    "    # get_gridded_features,\n",
    "]\n",
    "for task in task_list:\n",
    "    workflow.execute_entity_task(task, gdirs, print_log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Load PMB data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PMB data:\n",
    "path_PMB_GLAMOS_csv = '../../../data/GLAMOS/point/csv/'\n",
    "df_pmb = pd.read_csv(path_PMB_GLAMOS_csv + 'df_pmb_50s_clean.csv')\n",
    "# Histogram of mass balance\n",
    "df_pmb['POINT_BALANCE'].hist(bins=20)\n",
    "plt.xlabel('m w.e.')\n",
    "df_pmb.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get info of that sample:\n",
    "i = 0\n",
    "RGI = df_pmb.iloc[i].RGIId\n",
    "POINT_LAT, POINT_LON = df_pmb.iloc[i].POINT_LAT, df_pmb.iloc[i].POINT_LON\n",
    "\n",
    "# Get oggm data for that RGI ID\n",
    "for gdir in gdirs:\n",
    "    if gdir.rgi_id == RGI:\n",
    "        break\n",
    "# gdir = find_gdir(gdirs, RGI)\n",
    "\n",
    "with xr.open_dataset(gdir.get_filepath(\"gridded_data\")) as ds:\n",
    "    ds = ds.load()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Merge with OGGM data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables of interest from oggm\n",
    "voi = [\n",
    "    \"aspect\", \"slope\", \"dis_from_border\", \"topo\", \"hugonnet_dhdt\",\n",
    "    \"consensus_ice_thickness\", \"millan_ice_thickness\", \"millan_v\", \"millan_vx\",\n",
    "    \"millan_vy\"\n",
    "]\n",
    "\n",
    "# Initialise empty:\n",
    "for var in voi:\n",
    "    df_pmb[var] = np.nan\n",
    "\n",
    "for i in tqdm(range(len(df_pmb)), desc='rows'):\n",
    "    # Get info of that sample:\n",
    "    RGI = df_pmb.iloc[i].RGIId\n",
    "    POINT_LAT, POINT_LON = df_pmb.iloc[i].POINT_LAT, df_pmb.iloc[i].POINT_LON\n",
    "\n",
    "    # Get oggm data for that RGI ID\n",
    "    for gdir in gdirs:\n",
    "        if gdir.rgi_id == RGI:\n",
    "            break\n",
    "    # gdir = find_gdir(gdirs, RGI)\n",
    "\n",
    "    with xr.open_dataset(gdir.get_filepath(\"gridded_data\")) as ds:\n",
    "        ds = ds.load()\n",
    "\n",
    "    # Transform stake coord to glacier system:\n",
    "    transf = pyproj.Transformer.from_proj(salem.wgs84,\n",
    "                                          gdir.grid.proj,\n",
    "                                          always_xy=True)\n",
    "    x_stake, y_stake = transf.transform(POINT_LON, POINT_LAT)  # x,y stake\n",
    "\n",
    "    # Get glacier variables closest to these coordinates:\n",
    "    stake = ds.sel(x=x_stake, y=y_stake, method=\"nearest\")\n",
    "\n",
    "    # Calculate min, max and median topography of glacier:\n",
    "    # min_glacier = ds.where(ds.glacier_mask == 1).topo.min().values\n",
    "    # max_glacier = ds.where(ds.glacier_mask == 1).topo.max().values\n",
    "    # med_glacier = ds.where(ds.glacier_mask == 1).topo.median().values\n",
    "\n",
    "    # Select variables of interest:\n",
    "    stake_var = stake[voi]\n",
    "    stake_var_df = stake_var.to_pandas()\n",
    "\n",
    "    for var in stake_var_df.index:\n",
    "        df_pmb.at[i, var] = stake_var_df.loc[var]\n",
    "\n",
    "df_pmb.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv:\n",
    "df_pmb.to_csv(path_PMB_GLAMOS_csv + 'CH_wgms_dataset.csv', index=False)\n",
    "df_pmb.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Add avalanche data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory\n",
    "working_dir = '../../../data/OGGM/'\n",
    "cfg.PATHS['working_dir'] = working_dir\n",
    "\n",
    "# Set RGI version and region:\n",
    "rgi_region = \"11\"  # Central Europe\n",
    "rgi_version = \"6\"\n",
    "rgi_dir = utils.get_rgi_dir(version=rgi_version)\n",
    "\n",
    "path = utils.get_rgi_region_file(region=rgi_region, version=rgi_version)\n",
    "rgidf = gpd.read_file(path)\n",
    "\n",
    "# We use the directories with the shop data in it: \"W5E5_w_data\"\n",
    "base_url = 'https://cluster.klima.uni-bremen.de/~mkneib/global_whypso/'\n",
    "gdirs = workflow.init_glacier_directories(\n",
    "    rgidf,\n",
    "    prepro_base_url=base_url,\n",
    "    from_prepro_level=3,\n",
    "    prepro_border=80,\n",
    "    reset=True,\n",
    "    force=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdir = gdirs[0]\n",
    "# Get the path to the gridded data file & open it\n",
    "with xr.open_dataset(gdir.get_filepath('gridded_data')) as ds:\n",
    "    ds = ds.load()\n",
    "ds.snowslide_1m.where(ds.glacier_mask).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables of interest from oggm\n",
    "voi = [\"snowslide_1m\"]\n",
    "\n",
    "# Initialise empty:\n",
    "for var in voi:\n",
    "    df_pmb[var] = np.nan\n",
    "\n",
    "for i, row in tqdm(enumerate(df_pmb.iterrows()), desc='rows'):\n",
    "    # Get info of that sample:\n",
    "    RGI = df_pmb.iloc[i].RGIId\n",
    "    POINT_LAT, POINT_LON = df_pmb.iloc[i].POINT_LAT, df_pmb.iloc[i].POINT_LON\n",
    "\n",
    "    # Get oggm data for that RGI ID\n",
    "    for gdir in gdirs:\n",
    "        if gdir.rgi_id == RGI:\n",
    "            break\n",
    "    # gdir = find_gdir(gdirs, RGI)\n",
    "\n",
    "    with xr.open_dataset(gdir.get_filepath(\"gridded_data\")) as ds:\n",
    "        ds = ds.load()\n",
    "\n",
    "    # Transform stake coord to glacier system:\n",
    "    transf = pyproj.Transformer.from_proj(salem.wgs84,\n",
    "                                          gdir.grid.proj,\n",
    "                                          always_xy=True)\n",
    "    x_stake, y_stake = transf.transform(POINT_LON, POINT_LAT)  # x,y stake\n",
    "\n",
    "    # Get glacier variables closest to these coordinates:\n",
    "    stake = ds.sel(x=x_stake, y=y_stake, method=\"nearest\")\n",
    "\n",
    "    # Select variables of interest:\n",
    "    stake_var = stake[voi]\n",
    "    stake_var_df = stake_var.to_pandas()\n",
    "\n",
    "    for var in stake_var_df.index:\n",
    "        df_pmb.at[i, var] = stake_var_df.loc[var]\n",
    "\n",
    "df_pmb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pmb_subset = df_pmb[(df_pmb.GLACIER == 'aletsch')&(df_pmb.YEAR > 2010)]\n",
    "x_stakes, y_stakes, snowslide_1m_ = [], [], []\n",
    "for i in tqdm(range(len((df_pmb_subset))), desc='rows'):\n",
    "    # Get info of that sample:\n",
    "    RGI = df_pmb_subset.iloc[i].RGIId\n",
    "    POINT_LAT, POINT_LON = df_pmb_subset.iloc[i].POINT_LAT, df_pmb_subset.iloc[i].POINT_LON\n",
    "\n",
    "    # Get oggm data for that RGI ID\n",
    "    for gdir in gdirs:\n",
    "        if gdir.rgi_id == RGI:\n",
    "            break\n",
    "    # gdir = find_gdir(gdirs, RGI)\n",
    "\n",
    "    with xr.open_dataset(gdir.get_filepath(\"gridded_data\")) as ds:\n",
    "        ds = ds.load()\n",
    "\n",
    "    # Transform stake coord to glacier system:\n",
    "    transf = pyproj.Transformer.from_proj(salem.wgs84,\n",
    "                                          gdir.grid.proj,\n",
    "                                          always_xy=True)\n",
    "    x_stake, y_stake = transf.transform(POINT_LON, POINT_LAT)  # x,y stake\n",
    "\n",
    "    # Get glacier variables closest to these coordinates:\n",
    "    stake = ds.sel(x=x_stake, y=y_stake, method=\"nearest\")\n",
    "    \n",
    "    x_stakes.append(x_stake)\n",
    "    y_stakes.append(y_stake)\n",
    "    snowslide_1m_.append(stake.snowslide_1m.values)\n",
    "   \n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1) \n",
    "ds.snowslide_1m.where(ds.glacier_mask).plot()\n",
    "# plot stake\n",
    "for x_stake, y_stake in zip(x_stakes, y_stakes):\n",
    "    plt.scatter(x_stake, y_stake, color='r')\n",
    "    \n",
    "# plot distribution of snowslide_1m\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(snowslide_1m_)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
