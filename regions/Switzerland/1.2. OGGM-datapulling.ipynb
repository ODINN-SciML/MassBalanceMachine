{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# OGGM - data pulling\n",
    "\n",
    "Adds topographical variables from OGGM to the PMB data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pyproj\n",
    "import salem\n",
    "from tqdm.notebook import tqdm\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from oggm import utils, workflow, tasks\n",
    "from oggm import cfg as oggmCfg\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import math\n",
    "from os.path import isfile, join, isdir\n",
    "from shapely.geometry import Point\n",
    "\n",
    "oggmCfg.initialize(logging_level='WARNING')\n",
    "oggmCfg.PARAMS['border'] = 10\n",
    "oggmCfg.PARAMS['use_multiprocessing'] = True\n",
    "oggmCfg.PARAMS['continue_on_error'] = True\n",
    "# Module logger\n",
    "log = logging.getLogger('.'.join(__name__.split('.')[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926b1a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyfolder(path):\n",
    "    if os.path.exists(path):\n",
    "        # Loop through all items in the directory\n",
    "        for item in os.listdir(path):\n",
    "            item_path = join(path, item)\n",
    "            if isfile(item_path):\n",
    "                os.remove(item_path)  # Remove file\n",
    "            elif isdir(item_path):\n",
    "                emptyfolder(item_path)  # Recursively empty the folder\n",
    "                os.rmdir(item_path)  # Remove the now-empty folder\n",
    "    else:\n",
    "        createPath(path)\n",
    "\n",
    "\n",
    "def createPath(path):\n",
    "    os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6fb794",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_prcp_array = np.linspace(0.5, 20, 51)\n",
    "# we basically do here the same as in massbalance.decide_winter_precip_factor(gdir)\n",
    "a, b = oggmCfg.PARAMS['winter_prcp_fac_ab']\n",
    "r0, r1 = oggmCfg.PARAMS['prcp_fac_min'], oggmCfg.PARAMS['prcp_fac_max']\n",
    "prcp_fac = a * np.log(w_prcp_array) + b\n",
    "# don't allow extremely low/high prcp. factors!!!\n",
    "prcp_fac_array = utils.clip_array(prcp_fac, r0, r1)\n",
    "plt.plot(w_prcp_array, prcp_fac_array)\n",
    "plt.xlabel(r'winter daily mean precipitation' + '\\n' +\n",
    "           r'(kg m$^{-2}$ day$^{-1}$)')\n",
    "plt.ylabel('precipitation factor (prcp_fac)')\n",
    "plt.title('Fig. 1')\n",
    "\n",
    "# save arrays\n",
    "np.save('w_prcp_array.npy', w_prcp_array)\n",
    "np.save('prcp_fac_array.npy', prcp_fac_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Download OGGM data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory\n",
    "working_dir = '../../../data/OGGM/'\n",
    "oggmCfg.PATHS['working_dir'] = working_dir\n",
    "\n",
    "# Set RGI version and region:\n",
    "rgi_region = \"11\"  # Central Europe\n",
    "rgi_version = \"6\"\n",
    "rgi_dir = utils.get_rgi_dir(version=rgi_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = utils.get_rgi_region_file(region=rgi_region, version=rgi_version)\n",
    "rgidf = gpd.read_file(path)\n",
    "\n",
    "# We use the directories with the shop data in it: \"W5E5_w_data\"\n",
    "base_url = \"https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.1/elev_bands/W5E5_w_data/\"\n",
    "gdirs = workflow.init_glacier_directories(\n",
    "    rgidf,\n",
    "    from_prepro_level=3,\n",
    "    prepro_base_url=base_url,\n",
    "    prepro_border=10,\n",
    "    reset=True,\n",
    "    force=True,\n",
    ")\n",
    "\n",
    "# Tested tasks\n",
    "task_list = [\n",
    "    tasks.gridded_attributes,\n",
    "    # tasks.gridded_mb_attributes,\n",
    "    # get_gridded_features,\n",
    "]\n",
    "for task in task_list:\n",
    "    workflow.execute_entity_task(task, gdirs, print_log=False)\n",
    "    \n",
    "    # save OGGM xr for all needed glaciers: \n",
    "emptyfolder('../../../data/OGGM/xr_grids/')\n",
    "for gdir in tqdm(gdirs):\n",
    "    RGIId = gdir.rgi_id\n",
    "    with xr.open_dataset(gdir.get_filepath(\"gridded_data\")) as ds:\n",
    "        ds = ds.load()\n",
    "        \n",
    "    # save ds\n",
    "    ds.to_netcdf(f'../../../data/OGGM/xr_grids/{RGIId}.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec939184",
   "metadata": {},
   "source": [
    "## Load PMB data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PMB data:\n",
    "path_PMB_GLAMOS_csv = '../../../data/GLAMOS/point/csv/'\n",
    "df_pmb = pd.read_csv(path_PMB_GLAMOS_csv + f'df_pmb_all.csv')\n",
    "\n",
    "print('Number of winter and annual samples:', len(df_pmb))\n",
    "print('Number of annual samples:',\n",
    "      len(df_pmb[df_pmb.PERIOD == 'annual']))\n",
    "print('Number of winter samples:',\n",
    "      len(df_pmb[df_pmb.PERIOD == 'winter']))\n",
    "\n",
    "# Get OGGM info of one sample:\n",
    "RGI = df_pmb.iloc[0].RGIId\n",
    "# Get oggm data for that RGI ID\n",
    "for gdir in gdirs:\n",
    "    if gdir.rgi_id == RGI:\n",
    "        break\n",
    "with xr.open_dataset(gdir.get_filepath(\"gridded_data\")) as ds:\n",
    "    ds = ds.load()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286b6200",
   "metadata": {},
   "source": [
    "## Merge with OGGM data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325eb199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load shapefiles\n",
    "# Load RGI shapefile for the specified region and version\n",
    "path = utils.get_rgi_region_file(region=rgi_region, version=rgi_version)\n",
    "rgidf = gpd.read_file(path)\n",
    "\n",
    "# All possible variables of interest from oggm\n",
    "# voi = [\n",
    "#     \"aspect\", \"slope\", \"dis_from_border\", \"topo\", \"hugonnet_dhdt\",\n",
    "#     \"consensus_ice_thickness\", \"millan_ice_thickness\", \"millan_v\", \"millan_vx\",\n",
    "#     \"millan_vy\"\n",
    "# ]\n",
    "\n",
    "voi = [\n",
    "    \"aspect\",\n",
    "    \"slope\",\n",
    "    \"topo\",\n",
    "    \"hugonnet_dhdt\",\n",
    "    \"consensus_ice_thickness\",\n",
    "    \"millan_v\",\n",
    "]\n",
    "\n",
    "# Initialise empty:\n",
    "for var in voi:\n",
    "    df_pmb[var] = np.nan\n",
    "   \n",
    "df_pmb['within_glacier_shape'] = False\n",
    "    \n",
    "grouped = df_pmb.groupby(\"RGIId\")\n",
    "\n",
    "# Process each group\n",
    "for rgi_id, group in grouped:\n",
    "    # Get oggm data for that RGI ID\n",
    "    for gdir in gdirs:\n",
    "        if gdir.rgi_id == rgi_id:\n",
    "            break\n",
    "\n",
    "    with xr.open_dataset(gdir.get_filepath(\"gridded_data\")) as ds:\n",
    "        ds = ds.load()\n",
    "        \n",
    "    # Find the specific shape for the current RGI ID\n",
    "    glacier_shape = rgidf[rgidf[\"RGIId\"] == rgi_id]\n",
    "    if glacier_shape.empty:\n",
    "        print(f\"Warning: No shape found for RGIId {rgi_id}, skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Define the coordinate transformation\n",
    "    transf = pyproj.Transformer.from_proj(\n",
    "        pyproj.CRS.from_user_input(\"EPSG:4326\"),  # Input CRS (WGS84)\n",
    "        pyproj.CRS.from_user_input(ds.pyproj_srs),  # Output CRS from dataset\n",
    "        always_xy=True\n",
    "    )\n",
    "    \n",
    "    # Transform all coordinates in the group\n",
    "    lon, lat = group[\"POINT_LON\"].values, group[\"POINT_LAT\"].values\n",
    "    x_stake, y_stake = transf.transform(lon, lat)\n",
    "    \n",
    "    # Create a GeoDataFrame for df_pmb points\n",
    "    geometry = [Point(xy) for xy in zip(group[\"POINT_LON\"], group[\"POINT_LAT\"])]\n",
    "    points_rgi = gpd.GeoDataFrame(group, geometry=geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "    # Filter points that intersect with this specific shape\n",
    "    glacier_shape = glacier_shape.to_crs(points_rgi.crs)  # Ensure CRS matches\n",
    "    points_in_glacier = gpd.sjoin(points_rgi.loc[group.index], glacier_shape, predicate=\"within\", how=\"inner\")\n",
    "            \n",
    "    # Select nearest values for all points\n",
    "    stake = ds.sel(\n",
    "        x=xr.DataArray(x_stake, dims=\"points\"),\n",
    "        y=xr.DataArray(y_stake, dims=\"points\"),\n",
    "        method=\"nearest\"\n",
    "    )\n",
    "\n",
    "    # Extract variables of interest\n",
    "    stake_var = stake[voi]\n",
    "\n",
    "    # Convert the extracted data to a DataFrame\n",
    "    stake_var_df = stake_var.to_dataframe()\n",
    "\n",
    "    # Update the DataFrame with the extracted values\n",
    "    for var in voi:\n",
    "        df_pmb.loc[group.index, var] = stake_var_df[var].values\n",
    "    \n",
    "    df_pmb.loc[points_in_glacier.index, 'within_glacier_shape'] = True\n",
    "    \n",
    "# change from radians to degrees so that it agrees with sgi data\n",
    "df_pmb['aspect'] = df_pmb['aspect'].apply(lambda x: math.degrees(x))\n",
    "df_pmb['slope'] = df_pmb['slope'].apply(lambda x: math.degrees(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be3b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "glacierName = 'aletsch'\n",
    "# stakes\n",
    "df_stakes = df_pmb.copy()\n",
    "df_stakes = df_stakes[(df_stakes['GLACIER'] == glacierName)]\n",
    "RGIId = df_stakes.RGIId.unique()[0]\n",
    "print(RGIId)\n",
    "# open OGGM xr for glacier\n",
    "# Get oggm data for that RGI grid\n",
    "ds_oggm = xr.open_dataset(f'../../../data/OGGM/xr_grids/{RGIId}.nc')\n",
    "\n",
    "# Define the coordinate transformation\n",
    "transf = pyproj.Transformer.from_proj(\n",
    "pyproj.CRS.from_user_input(\"EPSG:4326\"),  # Input CRS (WGS84)\n",
    "pyproj.CRS.from_user_input(ds_oggm.pyproj_srs),  # Output CRS from dataset\n",
    "always_xy=True\n",
    ")\n",
    "\n",
    "# Transform all coordinates in the group\n",
    "lon, lat = df_stakes[\"POINT_LON\"].values, df_stakes[\"POINT_LAT\"].values\n",
    "x_stake, y_stake = transf.transform(lon, lat)\n",
    "df_stakes['x'] = x_stake\n",
    "df_stakes['y'] = y_stake\n",
    "\n",
    "# plot stakes\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = plt.subplot(121)\n",
    "ds_oggm.glacier_mask.plot(cmap = 'binary', ax = ax)\n",
    "sns.scatterplot(df_stakes, x = 'x', y = 'y', hue = 'within_glacier_shape', ax = ax, palette = ['r', 'b'])\n",
    "ax.set_title('Stakes on glacier OGGM')\n",
    "\n",
    "ax = plt.subplot(122)\n",
    "path_SGI_topo = '../../../data/GLAMOS/topo/SGI2020/'\n",
    "sgi_grid = xr.open_dataset(path_SGI_topo+f'xr_masked_grids/{glacierName}.nc')\n",
    "sgi_grid.glacier_mask.plot(cmap = 'binary', ax = ax)\n",
    "sns.scatterplot(df_stakes, x = 'POINT_LON', y = 'POINT_LAT', hue = 'within_glacier_shape', ax = ax, palette = ['r', 'b'])\n",
    "ax.set_title('Stakes on glacier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b393278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv:\n",
    "# Drop points that are not within the glacier shape\n",
    "df_pmb = df_pmb[df_pmb['within_glacier_shape']]\n",
    "# Drop the within_glacier_shape column\n",
    "df_pmb = df_pmb.drop(columns=['within_glacier_shape'])\n",
    "\n",
    "print('Number of winter and annual samples:', len(df_pmb))\n",
    "print('Number of annual samples:',\n",
    "      len(df_pmb[df_pmb.PERIOD == 'annual']))\n",
    "print('Number of winter samples:',\n",
    "      len(df_pmb[df_pmb.PERIOD == 'winter']))\n",
    "# Save to csv\n",
    "df_pmb.to_csv(path_PMB_GLAMOS_csv + f'CH_wgms_dataset_all.csv',\n",
    "              index=False)\n",
    "df_pmb.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0cd366",
   "metadata": {},
   "source": [
    "## Add SGI data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9112499",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pmb = pd.read_csv(path_PMB_GLAMOS_csv + f'CH_wgms_dataset_all.csv')\n",
    "\n",
    "# Example\n",
    "path_SGI_topo = '../../../data/GLAMOS/topo/SGI2020/'\n",
    "i = 0\n",
    "GlacierName = 'clariden'\n",
    "df_pmb_gl = df_pmb[df_pmb.GLACIER == GlacierName]\n",
    "\n",
    "stake_coordinates = df_pmb_gl[['POINT_LON', 'POINT_LAT']].values\n",
    "# Open SGI grid:\n",
    "ds_sgi = xr.open_dataset(path_SGI_topo + 'xr_masked_grids/' +\n",
    "                         f'{GlacierName}.nc')\n",
    "\n",
    "# Plot the masked data\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 6))\n",
    "ds_sgi.masked_aspect.plot(ax=axs[0], cmap='twilight_shifted')\n",
    "ds_sgi.masked_slope.plot(ax=axs[1], cmap='cividis')\n",
    "ds_sgi.masked_elev.plot(ax=axs[2], cmap='terrain')\n",
    "ds_sgi.glacier_mask.plot(ax=axs[3], cmap='binary')\n",
    "axs[3].scatter(stake_coordinates[:, 0], stake_coordinates[:, 1], c='r', s=10)\n",
    "axs[0].set_title(\"Aspect\")\n",
    "axs[1].set_title(\"Slope\")\n",
    "axs[2].set_title(\"DEM\")\n",
    "axs[3].set_title(\"Glacier mask\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700ebaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and variables of interest\n",
    "path_SGI_topo = '../../../data/GLAMOS/topo/SGI2020/'\n",
    "path_masked_grids = os.path.join(path_SGI_topo, 'xr_masked_grids/')\n",
    "voi = [\"masked_aspect\", \"masked_slope\", \"masked_elev\"]\n",
    "\n",
    "# Get fully processed glacier names\n",
    "fully_processed = set(\n",
    "    re.split(r'.nc', f)[0] for f in os.listdir(path_masked_grids) if f.endswith('.nc')\n",
    ")\n",
    "\n",
    "# Filter DataFrame for fully processed glaciers\n",
    "df_pmb_filtered = df_pmb[df_pmb.GLACIER.isin(fully_processed)].copy()\n",
    "\n",
    "# Initialize empty columns for variables of interest\n",
    "for var in voi:\n",
    "    df_pmb_filtered[var] = np.nan\n",
    "\n",
    "# Group rows by glacier name to process each glacier in bulk\n",
    "grouped = df_pmb_filtered.groupby(\"GLACIER\")\n",
    "\n",
    "# Process each glacier\n",
    "for glacier_name, group in tqdm(grouped, desc=\"Processing glaciers\"):\n",
    "    try:\n",
    "        # Open the dataset for the current glacier\n",
    "        file_path = os.path.join(path_masked_grids, f\"{glacier_name}.nc\")\n",
    "        ds_sgi = xr.open_dataset(file_path)\n",
    "\n",
    "        # Transform coordinates for the group\n",
    "        lon = group[\"POINT_LON\"].values\n",
    "        lat = group[\"POINT_LAT\"].values\n",
    "\n",
    "        # Select nearest values for all points in the group\n",
    "        stake = ds_sgi.sel(\n",
    "            lon=xr.DataArray(lon, dims=\"points\"),\n",
    "            lat=xr.DataArray(lat, dims=\"points\"),\n",
    "            method=\"nearest\"\n",
    "        )\n",
    "\n",
    "        # Extract variables of interest and convert to a DataFrame\n",
    "        stake_var = stake[voi].to_dataframe().reset_index()\n",
    "\n",
    "        # Map extracted values back to the original DataFrame\n",
    "        for var in voi:\n",
    "            df_pmb_filtered.loc[group.index, var] = stake_var[var].values\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for glacier: {glacier_name}\")\n",
    "        continue\n",
    "\n",
    "# Rename columns\n",
    "df_pmb_filtered.rename(columns={\n",
    "    \"masked_aspect\": \"aspect_sgi\",\n",
    "    \"masked_slope\": \"slope_sgi\",\n",
    "    \"masked_elev\": \"topo_sgi\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = os.path.join(path_PMB_GLAMOS_csv, 'CH_wgms_dataset_all.csv')\n",
    "df_pmb_filtered.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df_pmb_filtered.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b5d530",
   "metadata": {},
   "outputs": [],
   "source": [
    "glacierName = 'clariden'\n",
    "df_pmb_gl = df_pmb_filtered[(df_pmb_filtered.GLACIER == glacierName)]\n",
    "\n",
    "# Plot aspect and sgi aspect\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 6))\n",
    "axs[0].scatter(df_pmb_gl.aspect, df_pmb_gl.aspect_sgi)\n",
    "axs[0].set_xlabel('aspect oggm')\n",
    "axs[0].set_ylabel('aspect sgi')\n",
    "axs[0].set_title('Aspect')\n",
    "\n",
    "axs[1].scatter(df_pmb_gl.slope, df_pmb_gl.slope_sgi)\n",
    "axs[1].set_xlabel('slope oggm')\n",
    "axs[1].set_ylabel('slope sgi')\n",
    "axs[1].set_title('Slope')\n",
    "\n",
    "# same for topo\n",
    "axs[2].scatter(df_pmb_gl.topo, df_pmb_gl.topo_sgi)\n",
    "axs[2].set_xlabel('topo oggm')\n",
    "axs[2].set_ylabel('topo sgi')\n",
    "axs[2].set_title('Topo')\n",
    "# add 1:1 line\n",
    "for ax in axs:\n",
    "    ax.plot(ax.get_xlim(), ax.get_xlim(), ls=\"--\", c=\".3\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d22fbc6",
   "metadata": {},
   "source": [
    "## Add avalanche data: (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907cb3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory\n",
    "working_dir = '../../../data/OGGM/'\n",
    "oggmCfg.PATHS['working_dir'] = working_dir\n",
    "\n",
    "# Set RGI version and region:\n",
    "rgi_region = \"11\"  # Central Europe\n",
    "rgi_version = \"6\"\n",
    "rgi_dir = utils.get_rgi_dir(version=rgi_version)\n",
    "\n",
    "path = utils.get_rgi_region_file(region=rgi_region, version=rgi_version)\n",
    "rgidf = gpd.read_file(path)\n",
    "\n",
    "# We use the directories with the shop data in it: \"W5E5_w_data\"\n",
    "base_url = 'https://cluster.klima.uni-bremen.de/~mkneib/global_whypso/'\n",
    "gdirs = workflow.init_glacier_directories(\n",
    "    rgidf,\n",
    "    prepro_base_url=base_url,\n",
    "    from_prepro_level=3,\n",
    "    prepro_border=80,\n",
    "    reset=True,\n",
    "    force=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bbe1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdir = gdirs[0]\n",
    "# Get the path to the gridded data file & open it\n",
    "with xr.open_dataset(gdir.get_filepath('gridded_data')) as ds:\n",
    "    ds = ds.load()\n",
    "ds.snowslide_1m.where(ds.glacier_mask).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa13da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PMB data:\n",
    "path_PMB_GLAMOS_csv = '../../../data/GLAMOS/point/csv/'\n",
    "\n",
    "df_pmb = pd.read_csv(path_PMB_GLAMOS_csv + f'CH_wgms_dataset_all.csv')\n",
    "df_pmb.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af40dab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables of interest from oggm\n",
    "voi = [\"snowslide_1m\"]\n",
    "\n",
    "# Initialise empty:\n",
    "for var in voi:\n",
    "    df_pmb[var] = np.nan\n",
    "\n",
    "for i in tqdm(range(len(df_pmb)), desc='rows'):\n",
    "    # Get info of that sample:\n",
    "    RGI = df_pmb.iloc[i].RGIId\n",
    "    POINT_LAT, POINT_LON = df_pmb.iloc[i].POINT_LAT, df_pmb.iloc[i].POINT_LON\n",
    "\n",
    "    # Get oggm data for that RGI ID\n",
    "    for gdir in gdirs:\n",
    "        if gdir.rgi_id == RGI:\n",
    "            break\n",
    "    # gdir = find_gdir(gdirs, RGI)\n",
    "\n",
    "    with xr.open_dataset(gdir.get_filepath(\"gridded_data\")) as ds:\n",
    "        ds = ds.load()\n",
    "\n",
    "    # Transform stake coord to glacier system:\n",
    "    transf = pyproj.Transformer.from_proj(salem.wgs84,\n",
    "                                          gdir.grid.proj,\n",
    "                                          always_xy=True)\n",
    "    x_stake, y_stake = transf.transform(POINT_LON, POINT_LAT)  # x,y stake\n",
    "\n",
    "    # Get glacier variables closest to these coordinates:\n",
    "    stake = ds.sel(x=x_stake, y=y_stake, method=\"nearest\")\n",
    "\n",
    "    # Select variables of interest:\n",
    "    stake_var = stake[voi]\n",
    "    stake_var_df = stake_var.to_pandas()\n",
    "\n",
    "    for var in stake_var_df.index:\n",
    "        df_pmb.at[i, var] = stake_var_df.loc[var]\n",
    "\n",
    "df_pmb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff205a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv:\n",
    "df_pmb.to_csv(path_PMB_GLAMOS_csv + f'CH_wgms_dataset_all.csv',\n",
    "              index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9ee314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of snowslide_1m:\n",
    "df_pmb['snowslide_1m'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2226f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find glaciers with snowslide_1m > 1:\n",
    "df_pmb[df_pmb['snowslide_1m'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f94d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pmb_subset = df_pmb[(df_pmb.GLACIER == 'tsanfleuron')\n",
    "                       & (df_pmb.YEAR > 2010)]\n",
    "x_stakes, y_stakes, snowslide_1m_ = [], [], []\n",
    "for i in tqdm(range(len((df_pmb_subset))), desc='rows'):\n",
    "    # Get info of that sample:\n",
    "    RGI = df_pmb_subset.iloc[i].RGIId\n",
    "    POINT_LAT, POINT_LON = df_pmb_subset.iloc[i].POINT_LAT, df_pmb_subset.iloc[\n",
    "        i].POINT_LON\n",
    "\n",
    "    # Get oggm data for that RGI ID\n",
    "    for gdir in gdirs:\n",
    "        if gdir.rgi_id == RGI:\n",
    "            break\n",
    "    # gdir = find_gdir(gdirs, RGI)\n",
    "\n",
    "    with xr.open_dataset(gdir.get_filepath(\"gridded_data\")) as ds:\n",
    "        ds = ds.load()\n",
    "\n",
    "    # Transform stake coord to glacier system:\n",
    "    transf = pyproj.Transformer.from_proj(salem.wgs84,\n",
    "                                          gdir.grid.proj,\n",
    "                                          always_xy=True)\n",
    "    x_stake, y_stake = transf.transform(POINT_LON, POINT_LAT)  # x,y stake\n",
    "\n",
    "    # Get glacier variables closest to these coordinates:\n",
    "    stake = ds.sel(x=x_stake, y=y_stake, method=\"nearest\")\n",
    "\n",
    "    x_stakes.append(x_stake)\n",
    "    y_stakes.append(y_stake)\n",
    "    snowslide_1m_.append(stake.snowslide_1m.values)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "ds.snowslide_1m.where(ds.glacier_mask).plot()\n",
    "# plot stake\n",
    "for x_stake, y_stake in zip(x_stakes, y_stakes):\n",
    "    plt.scatter(x_stake, y_stake, color='r')\n",
    "\n",
    "# plot distribution of snowslide_1m\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(snowslide_1m_)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c66d48a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
