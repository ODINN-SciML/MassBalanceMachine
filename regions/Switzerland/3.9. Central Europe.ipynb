{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glacier grids from RGI:\n",
    "\n",
    "Creates monthly grid files for the MBM to make PMB predictions over the whole glacier grid. The files come from the RGI grid with OGGM topography. Computing takes a long time because of the conversion to monthly format.\n",
    "## Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import massbalancemachine as mbm\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from cmcrameri import cm\n",
    "from oggm import utils, workflow\n",
    "from oggm import cfg as oggmCfg\n",
    "import geopandas as gpd\n",
    "import geopandas as gpd\n",
    "import traceback\n",
    "import salem\n",
    "import oggm\n",
    "\n",
    "\n",
    "# scripts\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "from scripts.plots import *\n",
    "from scripts.geodata import *\n",
    "from scripts.xgb_helpers import *\n",
    "from scripts.config_CH import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)\n",
    "free_up_cuda()  # in case no memory\n",
    "\n",
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "\n",
    "# Climate columns\n",
    "vois_climate = [\n",
    "    't2m', 'tp', 'slhf', 'sshf', 'ssrd', 'fal', 'str', 'u10', 'v10'\n",
    "]\n",
    "# Topographical columns\n",
    "voi_topographical = [\n",
    "    \"aspect\",\n",
    "    \"slope\",\n",
    "    \"hugonnet_dhdt\",\n",
    "    \"consensus_ice_thickness\",\n",
    "    \"millan_v\",\n",
    "    \"topo\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdirs, rgidf = initialize_oggm_glacier_directories(\n",
    "    cfg,\n",
    "    rgi_region=\"11\",\n",
    "    rgi_version=\"6\",\n",
    "    base_url=\n",
    "    \"https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.1/elev_bands/W5E5_w_data/\",\n",
    "    log_level='WARNING',\n",
    "    task_list=None,\n",
    ")\n",
    "# Save OGGM xr for all needed glaciers in RGI region 11.6:\n",
    "export_oggm_grids(cfg, gdirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGI Ids:\n",
    "# Read glacier ids:\n",
    "rgi_df = pd.read_csv(cfg.dataPath + path_glacier_ids, sep=',')\n",
    "rgi_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "rgi_df.sort_values(by='short_name', inplace=True)\n",
    "rgi_df.set_index('short_name', inplace=True)\n",
    "rgi_df.loc['rhone']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create RGI grids for all glaciers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_RGIs = cfg.dataPath + path_OGGM + 'xr_grids/'\n",
    "glaciers = os.listdir(path_RGIs)\n",
    "\n",
    "print(f\"Found {len(glaciers)} glaciers in RGI region 11.6\")\n",
    "\n",
    "# Open an example\n",
    "# rgi_gl = gdirs[0].rgi_id\n",
    "rgi_gl = 'RGI60-11.01238'\n",
    "\n",
    "ds = xr.open_dataset(path_RGIs + rgi_gl + '.zarr')\n",
    "glacier_mask = np.where(ds['glacier_mask'].values == 0, np.nan,\n",
    "                        ds['glacier_mask'].values)\n",
    "\n",
    "# Create glacier mask\n",
    "ds = ds.assign(masked_slope=glacier_mask * ds['slope'])\n",
    "ds = ds.assign(masked_elev=glacier_mask * ds['topo'])\n",
    "ds = ds.assign(masked_aspect=glacier_mask * ds['aspect'])\n",
    "ds = ds.assign(masked_dis=glacier_mask * ds['dis_from_border'])\n",
    "\n",
    "# Assign other variables only if available\n",
    "if 'hugonnet_dhdt' in ds:\n",
    "    ds = ds.assign(masked_hug=glacier_mask * ds['hugonnet_dhdt'])\n",
    "if 'consensus_ice_thickness' in ds:\n",
    "    ds = ds.assign(masked_cit=glacier_mask * ds['consensus_ice_thickness'])\n",
    "if 'millan_v' in ds:\n",
    "    ds = ds.assign(masked_miv=glacier_mask * ds['millan_v'])\n",
    "\n",
    "glacier_indices = np.where(ds['glacier_mask'].values == 1)\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 8), sharey=True)\n",
    "\n",
    "ds.masked_aspect.plot(ax=axs[0], cmap='twilight_shifted', add_colorbar=False)\n",
    "ds.masked_slope.plot(ax=axs[1], cmap='cividis', add_colorbar=False)\n",
    "ds.masked_elev.plot(ax=axs[2], cmap='terrain', add_colorbar=False)\n",
    "ds.glacier_mask.plot(ax=axs[3], cmap='binary', add_colorbar=False)\n",
    "\n",
    "axs[0].set_title(\"Aspect OGGM\")\n",
    "axs[1].set_title(\"Slope OGGM\")\n",
    "axs[2].set_title(\"DEM OGGM\")\n",
    "axs[3].set_title(\"Glacier mask OGGM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_glacier_grid_RGI(ds: xr.Dataset, years: list,\n",
    "                            glacier_indices: \"tuple[np.array, np.array]\",\n",
    "                            gdir: oggm.GlacierDirectory, rgi_gl: str):\n",
    "\n",
    "    # Assuming the coordinate variables are named 'x' and 'y' in your dataset\n",
    "    x_coords = ds['x'].values\n",
    "    y_coords = ds['y'].values\n",
    "\n",
    "    # Retrieve the x and y values using the glacier indices\n",
    "    glacier_x_vals = x_coords[glacier_indices[1]]\n",
    "    glacier_y_vals = y_coords[glacier_indices[0]]\n",
    "\n",
    "    # Convert glacier coordinates to latitude and longitude\n",
    "    # Transform stake coord to glacier system:\n",
    "    transf = pyproj.Transformer.from_proj(gdir.grid.proj,\n",
    "                                          salem.wgs84,\n",
    "                                          always_xy=True)\n",
    "    lon, lat = transf.transform(glacier_x_vals, glacier_y_vals)\n",
    "\n",
    "    # Glacier mask as boolean array:\n",
    "    gl_mask_bool = ds['glacier_mask'].values.astype(bool)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    data_grid = {\n",
    "        'RGIId': [rgi_gl] * len(ds.masked_elev.values[gl_mask_bool]),\n",
    "        'POINT_LAT': lat,\n",
    "        'POINT_LON': lon,\n",
    "        'aspect': ds.masked_aspect.values[gl_mask_bool],\n",
    "        'slope': ds.masked_slope.values[gl_mask_bool],\n",
    "        'topo': ds.masked_elev.values[gl_mask_bool],\n",
    "    }\n",
    "\n",
    "    # add other variables if available\n",
    "    if 'masked_hug' in ds:\n",
    "        data_grid['hugonnet_dhdt'] = ds.masked_hug.values[gl_mask_bool]\n",
    "    if 'masked_cit' in ds:\n",
    "        data_grid['consensus_ice_thickness'] = ds.masked_cit.values[\n",
    "            gl_mask_bool]\n",
    "    if 'masked_miv' in ds:\n",
    "        data_grid['millan_v'] = ds.masked_miv.values[gl_mask_bool]\n",
    "\n",
    "    df_grid = pd.DataFrame(data_grid)\n",
    "\n",
    "    # Match to WGMS format:\n",
    "    df_grid['POINT_ID'] = np.arange(1, len(df_grid) + 1)\n",
    "    df_grid['N_MONTHS'] = 12\n",
    "    df_grid['POINT_ELEVATION'] = df_grid[\n",
    "        'topo']  # no other elevation available\n",
    "    df_grid['POINT_BALANCE'] = 0  # fake PMB for simplicity (not used)\n",
    "    num_rows_per_year = len(df_grid)\n",
    "    # Repeat the DataFrame num_years times\n",
    "    df_grid = pd.concat([df_grid] * len(years), ignore_index=True)\n",
    "    # Add the 'year' and date columns to the DataFrame\n",
    "    df_grid['YEAR'] = np.repeat(\n",
    "        years, num_rows_per_year\n",
    "    )  # 'year' column that has len(df_grid) instances of year\n",
    "    df_grid['FROM_DATE'] = df_grid['YEAR'].apply(lambda x: str(x) + '1001')\n",
    "    df_grid['TO_DATE'] = df_grid['YEAR'].apply(lambda x: str(x + 1) + '0930')\n",
    "    df_grid[\"PERIOD\"] = \"annual\"\n",
    "\n",
    "    return df_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_masked_glacier(path_RGIs, rgi_gl):\n",
    "    # Load dataset\n",
    "    ds = xr.open_dataset(path_RGIs + rgi_gl + '.zarr')\n",
    "\n",
    "    # Check if 'glacier_mask' exists\n",
    "    if 'glacier_mask' not in ds:\n",
    "        raise ValueError(f\"'glacier_mask' variable not found in dataset {rgi_gl}\")\n",
    "\n",
    "    # Create glacier mask\n",
    "    glacier_mask = np.where(ds['glacier_mask'].values == 0, np.nan,\n",
    "                            ds['glacier_mask'].values)\n",
    "\n",
    "    # Apply mask to core variables\n",
    "    ds = ds.assign(masked_slope=glacier_mask * ds['slope'])\n",
    "    ds = ds.assign(masked_elev=glacier_mask * ds['topo'])\n",
    "    ds = ds.assign(masked_aspect=glacier_mask * ds['aspect'])\n",
    "    ds = ds.assign(masked_dis=glacier_mask * ds['dis_from_border'])\n",
    "\n",
    "    # Apply mask to optional variables if present\n",
    "    if 'hugonnet_dhdt' in ds:\n",
    "        ds = ds.assign(masked_hug=glacier_mask * ds['hugonnet_dhdt'])\n",
    "    if 'consensus_ice_thickness' in ds:\n",
    "        ds = ds.assign(masked_cit=glacier_mask * ds['consensus_ice_thickness'])\n",
    "    if 'millan_v' in ds:\n",
    "        ds = ds.assign(masked_miv=glacier_mask * ds['millan_v'])\n",
    "\n",
    "    # Indices where glacier_mask == 1\n",
    "    glacier_indices = np.where(ds['glacier_mask'].values == 1)\n",
    "\n",
    "    return ds, glacier_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create masked grids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_xr_grids = os.path.join(cfg.dataPath, 'GLAMOS/topo/RGI_v6_11/', 'xr_masked_grids/')\n",
    "\n",
    "RUN = False\n",
    "if RUN:\n",
    "    emptyfolder(path_xr_grids)\n",
    "\n",
    "    for gdir in tqdm(gdirs):\n",
    "        rgi_gl = gdir.rgi_id\n",
    "\n",
    "        try:\n",
    "            # Create masked glacier dataset\n",
    "            ds, glacier_indices = create_masked_glacier(path_RGIs, rgi_gl)\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping {rgi_gl}: {e}\")\n",
    "            continue  # Skip to next glacier\n",
    "\n",
    "        dx_m, dy_m = get_res_from_projected(ds)\n",
    "\n",
    "        # Coarsen to 50 m resolution if needed\n",
    "        if 20 < dx_m < 50:\n",
    "            ds = coarsenDS_mercator(ds, target_res_m=50)\n",
    "            dx_m, dy_m = get_res_from_projected(ds)\n",
    "\n",
    "        # Save xarray dataset\n",
    "        save_path = os.path.join(path_xr_grids, f\"{rgi_gl}.zarr\")\n",
    "        ds.to_zarr(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create monthly dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gdir in gdirs:\n",
    "    if gdir.rgi_id == 'RGI60-11.01238':\n",
    "        gdir_rhone = gdir\n",
    "        \n",
    "years = range(2000, 2024)\n",
    "\n",
    "path_rgi_alps = os.path.join(cfg.dataPath, 'GLAMOS/topo/gridded_topo_inputs/RGI_v6_11/')\n",
    "os.makedirs(path_rgi_alps, exist_ok=True)\n",
    "emptyfolder(path_rgi_alps)\n",
    "\n",
    "valid_rgis = [f.replace('.zarr', '') for f in os.listdir(path_xr_grids) if f.endswith('.zarr')]\n",
    "\n",
    "for gdir in tqdm(gdirs, desc=\"Processing glaciers\"):\n",
    "    rgi_gl = gdir.rgi_id\n",
    "\n",
    "    if rgi_gl not in valid_rgis:\n",
    "        print(f\"Skipping {rgi_gl}: not found in valid RGI glaciers\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        file_path = os.path.join(path_xr_grids, f\"{rgi_gl}.zarr\")\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"Missing file: {file_path}\")\n",
    "\n",
    "        ds = xr.open_dataset(file_path)\n",
    "\n",
    "        # Get glacier_indices safely\n",
    "        if 'glacier_mask' in ds:\n",
    "            glacier_indices = np.where(ds['glacier_mask'].values == 1)\n",
    "        else:\n",
    "            raise ValueError(f\"Missing 'glacier_mask' in dataset for {rgi_gl}\")\n",
    "\n",
    "        # Create glacier grid\n",
    "        try:\n",
    "            df_grid = create_glacier_grid_RGI(ds, years, glacier_indices, gdir, rgi_gl)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed creating glacier grid for {rgi_gl}: {e}\")\n",
    "            continue\n",
    "\n",
    "        df_grid.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Add GLWD_ID\n",
    "        df_grid['GLWD_ID'] = df_grid.apply(\n",
    "            lambda x: mbm.data_processing.utils.get_hash(f\"{x.RGIId}_{x.YEAR}\"), axis=1)\n",
    "        df_grid['GLWD_ID'] = df_grid['GLWD_ID'].astype(str)\n",
    "        df_grid['GLACIER'] = df_grid['RGIId']\n",
    "\n",
    "        # Wrap Dataset creation & climate feature extraction\n",
    "        try:\n",
    "            dataset_grid = mbm.data_processing.Dataset(\n",
    "                cfg=cfg,\n",
    "                data=df_grid,\n",
    "                region_name='CH',\n",
    "                data_path=os.path.join(cfg.dataPath, path_PMB_GLAMOS_csv)\n",
    "            )\n",
    "\n",
    "            era5_climate_data = os.path.join(cfg.dataPath, path_ERA5_raw, 'era5_monthly_averaged_data_Alps.nc')\n",
    "            geopotential_data = os.path.join(cfg.dataPath, path_ERA5_raw, 'era5_geopotential_pressure_Alps.nc')\n",
    "\n",
    "            dataset_grid.get_climate_features(\n",
    "                climate_data=era5_climate_data,\n",
    "                geopotential_data=geopotential_data,\n",
    "                change_units=True,\n",
    "                smoothing_vois={\n",
    "                    'vois_climate': vois_climate,\n",
    "                    'vois_other': ['ALTITUDE_CLIMATE']\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Failed adding climate features for {rgi_gl}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Prepare output folder\n",
    "        folder_path = os.path.join(path_rgi_alps, rgi_gl)\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "        # Process each year\n",
    "        for year in years:\n",
    "            try:\n",
    "                df_grid_y = dataset_grid.data[dataset_grid.data.YEAR == year].copy()\n",
    "\n",
    "                voi_topographical_sub = [voi for voi in voi_topographical if voi in df_grid_y.columns]\n",
    "\n",
    "                dataset_grid_yearly = mbm.data_processing.Dataset(\n",
    "                    cfg=cfg,\n",
    "                    data=df_grid_y,\n",
    "                    region_name='CH',\n",
    "                    data_path=os.path.join(cfg.dataPath, path_PMB_GLAMOS_csv)\n",
    "                )\n",
    "\n",
    "                dataset_grid_yearly.convert_to_monthly(\n",
    "                    meta_data_columns=cfg.metaData,\n",
    "                    vois_climate=vois_climate,\n",
    "                    vois_topographical=voi_topographical_sub\n",
    "                )\n",
    "\n",
    "                save_path = os.path.join(folder_path, f\"{rgi_gl}_grid_{year}.parquet\")\n",
    "                dataset_grid_yearly.data.to_parquet(save_path, engine=\"pyarrow\", compression=\"snappy\")\n",
    "                print(f\"Saved: {save_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed processing {rgi_gl} for year {year}: {e}\")\n",
    "                continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error with glacier {rgi_gl}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gdir in gdirs:\n",
    "    if gdir.rgi_id == 'RGI60-11.01238':\n",
    "        gdir_rhone = gdir\n",
    "\n",
    "# Look at one example\n",
    "# load the dataset\n",
    "year = 2000\n",
    "rgi_gl = gdir_rhone.rgi_id\n",
    "\n",
    "df = pd.read_parquet(\n",
    "    os.path.join(path_rgi_alps, rgi_gl, f\"{rgi_gl}_grid_{year}.parquet\"))\n",
    "df = df[df.MONTHS == 'sep']\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "voi = [\n",
    "    't2m', 'tp', 'ALTITUDE_CLIMATE', 'ELEVATION_DIFFERENCE', 'hugonnet_dhdt',\n",
    "    'consensus_ice_thickness'\n",
    "]\n",
    "axs = axs.flatten()\n",
    "for i, var in enumerate(voi):\n",
    "    sns.scatterplot(df,\n",
    "                    x='POINT_LON',\n",
    "                    y='POINT_LAT',\n",
    "                    hue=var,\n",
    "                    s=5,\n",
    "                    alpha=0.5,\n",
    "                    palette='twilight_shifted',\n",
    "                    ax=axs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
