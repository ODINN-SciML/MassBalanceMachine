{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glacier grids from RGI:\n",
    "\n",
    "Creates monthly grid files for the MBM to make PMB predictions over the whole glacier grid. The files come from the RGI grid and use OGGM topography. Computing takes a long time because of the conversion to monthly format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import massbalancemachine as mbm\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from cmcrameri import cm\n",
    "from oggm import utils, workflow\n",
    "from oggm import cfg as oggmCfg\n",
    "import geopandas as gpd\n",
    "import geopandas as gpd\n",
    "\n",
    "# scripts\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "from scripts.plots import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)\n",
    "free_up_cuda()  # in case no memory\n",
    "\n",
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "custom_working_dir = '../../../data/OGGM/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Climate columns\n",
    "vois_climate = [\n",
    "    't2m', 'tp', 'slhf', 'sshf', 'ssrd', 'fal', 'str', 'u10', 'v10'\n",
    "]\n",
    "# Topographical columns\n",
    "voi_topographical = [\n",
    "    \"aspect\",\n",
    "    \"slope\",\n",
    "    \"hugonnet_dhdt\",\n",
    "    \"consensus_ice_thickness\",\n",
    "    \"millan_v\",\n",
    "    \"topo\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read PMB data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGI Ids:\n",
    "# Read glacier ids:\n",
    "rgi_df = pd.read_csv(path_glacier_ids, sep=',')\n",
    "rgi_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "rgi_df.sort_values(by='short_name', inplace=True)\n",
    "rgi_df.set_index('short_name', inplace=True)\n",
    "rgi_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_glamos = pd.read_csv(path_PMB_GLAMOS_csv + 'CH_wgms_dataset_all.csv')\n",
    "\n",
    "# Cut the data to the glaciers that have pcsr data:\n",
    "glDirect = [\n",
    "    re.search(r'xr_direct_(.*?)\\.nc', f).group(1)\n",
    "    for f in os.listdir(path_pcsr + 'csv/')\n",
    "]\n",
    "\n",
    "data_glamos = data_glamos[data_glamos.GLACIER.isin(glDirect)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order glaciers per area:\n",
    "shapefile_path = \"../../../data/GLAMOS/topo/SGI2020/SGI_2016_glaciers_copy.shp\"\n",
    "gdf_shapefiles = gpd.read_file(shapefile_path)  # Load the shapefile\n",
    "\n",
    "gl_area = {}\n",
    "for glacierName in rgi_df.index:\n",
    "    if glacierName == 'clariden':\n",
    "        sgi_id = rgi_df.loc['claridenL']['sgi-id'].strip()\n",
    "        rgi_shp = rgi_df.loc['claridenL']['rgi_id_v6_2016_shp']\n",
    "    else:\n",
    "        sgi_id = rgi_df.loc[glacierName]['sgi-id'].strip()\n",
    "        rgi_shp = rgi_df.loc[glacierName]['rgi_id_v6_2016_shp']\n",
    "\n",
    "    # 2016 shapefile of glacier\n",
    "    gdf_mask_gl = gdf_shapefiles[gdf_shapefiles.RGIId == rgi_shp]\n",
    "    gl_area[glacierName] = gdf_mask_gl.Area.values[0]\n",
    "\n",
    "gl_area['clariden'] = gl_area['claridenL']\n",
    "rgi_df.loc['clariden'] = rgi_df.loc['claridenL']\n",
    "\n",
    "\n",
    "# Sort the lists by area if available in gl_area\n",
    "def sort_by_area(glacier_list, gl_area):\n",
    "    return sorted(glacier_list, key=lambda g: gl_area.get(g, 0), reverse=True)\n",
    "\n",
    "\n",
    "glacier_list = sort_by_area(data_glamos.GLACIER.unique(), gl_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which rgis are in the OGGM directory:\n",
    "oggmCfg.initialize(logging_level=\"WARNING\")\n",
    "oggmCfg.PARAMS[\"border\"] = 10\n",
    "oggmCfg.PARAMS[\"use_multiprocessing\"] = True\n",
    "oggmCfg.PARAMS[\"continue_on_error\"] = True\n",
    "oggmCfg.PATHS[\"working_dir\"] = custom_working_dir\n",
    "\n",
    "path = utils.get_rgi_region_file(region=\"11\", version=\"6\")\n",
    "rgidf = gpd.read_file(path)\n",
    "\n",
    "# Intersect dataframe with list of available glaciers in GLAMOS\n",
    "# to reduce computation load in OGGM\n",
    "rgidf = rgidf.loc[rgidf['RGIId'].isin(data_glamos.RGIId.unique())]\n",
    "\n",
    "# We use the directories with the shop data in it: \"W5E5_w_data\"\n",
    "base_url = \"https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.1/elev_bands/W5E5_w_data/\"\n",
    "gdirs = workflow.init_glacier_directories(\n",
    "    rgidf,\n",
    "    from_prepro_level=3,\n",
    "    prepro_base_url=base_url,\n",
    "    prepro_border=10,\n",
    "    reset=True,\n",
    "    force=True,\n",
    ")\n",
    "rgis = list(\n",
    "    set(data_glamos.RGIId.unique()) & set(gdir.rgi_id for gdir in gdirs))\n",
    "print('Number of rgis:', len(rgis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute glacier grids:\n",
    "Add topo, climate variables and convert to monthly (takes a long time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN = False\n",
    "# Manual RGI ID overrides\n",
    "rgi_overrides = {'morteratsch': 'RGI60-11.01946', 'pers': 'RGI60-11.01946'}\n",
    "\n",
    "if RUN:\n",
    "    emptyfolder(path_glacier_grid_rgi)\n",
    "\n",
    "    for glacierName in tqdm(glacier_list, desc='Processing glaciers'):\n",
    "        print('\\n-----------------------------------')\n",
    "        print(glacierName)\n",
    "\n",
    "        # Get RGI ID, applying manual overrides if necessary\n",
    "        rgi_gl = rgi_overrides.get(glacierName, rgi_df.at[glacierName,\n",
    "                                                          'rgi_id.v6'])\n",
    "\n",
    "        # Load stake data for that glacier\n",
    "        data_gl = data_glamos[data_glamos.RGIId == rgi_gl]\n",
    "        dataset_gl = mbm.Dataset(cfg=cfg,\n",
    "                                 data=data_gl,\n",
    "                                 region_name='CH',\n",
    "                                 data_path=path_PMB_GLAMOS_csv)\n",
    "\n",
    "        # Get gridded glacier data from OGGM\n",
    "        df_grid = dataset_gl.create_glacier_grid(custom_working_dir)\n",
    "\n",
    "        # Add metadata\n",
    "        df_grid[\"PERIOD\"] = \"annual\"\n",
    "        df_grid[\"GLACIER\"] = glacierName\n",
    "\n",
    "        dataset_grid = mbm.Dataset(cfg=cfg,\n",
    "                                   data=df_grid,\n",
    "                                   region_name='CH',\n",
    "                                   data_path=path_PMB_GLAMOS_csv)\n",
    "\n",
    "        # Add climate data\n",
    "        era5_climate_data = os.path.join(path_ERA5_raw,\n",
    "                                         'era5_monthly_averaged_data.nc')\n",
    "        geopotential_data = os.path.join(path_ERA5_raw,\n",
    "                                         'era5_geopotential_pressure.nc')\n",
    "\n",
    "        dataset_grid.get_climate_features(climate_data=era5_climate_data,\n",
    "                                          geopotential_data=geopotential_data,\n",
    "                                          change_units=True)\n",
    "\n",
    "        # Add potential clear sky radiation\n",
    "        print('Adding potential clear sky radiation')\n",
    "        dataset_grid.get_potential_rad(os.path.join(path_pcsr, 'csv/'))\n",
    "\n",
    "        # Convert to monthly time resolution\n",
    "        print('Converting to monthly time resolution')\n",
    "        dataset_grid.convert_to_monthly(meta_data_columns=cfg.metaData,\n",
    "                                        vois_climate=vois_climate + ['pcsr'],\n",
    "                                        vois_topographical=voi_topographical)\n",
    "\n",
    "        assert 'pcsr' in dataset_grid.data.columns, \"pcsr column not found in dataset\"\n",
    "\n",
    "        # Save gridded dataset\n",
    "        output_path = os.path.join(path_glacier_grid_rgi,\n",
    "                                   f\"{glacierName}_grid.csv\")\n",
    "        print(f'Saving gridded dataset to {output_path}')\n",
    "        dataset_grid.data.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check grids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacierName = 'rhone'\n",
    "rgi_gl = rgi_overrides.get(glacierName, rgi_df.at[glacierName, 'rgi_id.v6'])\n",
    "\n",
    "# Load stake data for that glacier\n",
    "data_gl = data_glamos[data_glamos.RGIId == rgi_gl]\n",
    "dataset_gl = mbm.Dataset(cfg=cfg,\n",
    "                         data=data_gl,\n",
    "                         region_name='CH',\n",
    "                         data_path=path_PMB_GLAMOS_csv)\n",
    "\n",
    "ds, glacier_indices, gdir = dataset_gl.get_glacier_mask(custom_working_dir)\n",
    "# Plot glacier attributes of oggm:\n",
    "plotGlAttr(ds, cmap=cm.devon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MBM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
