{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glacier grids from RGI:\n",
    "\n",
    "Creates monthly grid files for the MBM to make PMB predictions over the whole glacier grid. The files come from the RGI grid and use OGGM topography. Computing takes a long time because of the conversion to monthly format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import massbalancemachine as mbm\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from cmcrameri import cm\n",
    "from oggm import utils, workflow\n",
    "from oggm import cfg as oggmCfg\n",
    "import geopandas as gpd\n",
    "import geopandas as gpd\n",
    "import traceback\n",
    "\n",
    "# scripts\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "from scripts.plots import *\n",
    "from scripts.geodata import *\n",
    "from scripts.xgb_helpers import *\n",
    "from scripts.config_CH import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)\n",
    "free_up_cuda()  # in case no memory\n",
    "\n",
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "\n",
    "# Climate columns\n",
    "vois_climate = [\n",
    "    't2m', 'tp', 'slhf', 'sshf', 'ssrd', 'fal', 'str', 'u10', 'v10'\n",
    "]\n",
    "# Topographical columns\n",
    "voi_topographical = [\n",
    "    \"aspect\",\n",
    "    \"slope\",\n",
    "    \"hugonnet_dhdt\",\n",
    "    \"consensus_ice_thickness\",\n",
    "    \"millan_v\",\n",
    "    \"topo\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read PMB data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>sgi-id</th>\n",
       "      <th>rgi_id_v6_2016_shp</th>\n",
       "      <th>rgi_id.v6</th>\n",
       "      <th>rgi_id.v7</th>\n",
       "      <th>Issue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adler</th>\n",
       "      <td>Adler</td>\n",
       "      <td>B56-14</td>\n",
       "      <td>RGI60-11.B56-14</td>\n",
       "      <td>RGI60-11.02764</td>\n",
       "      <td>RGI2000-v7.0-G-11-01075</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>albigna</th>\n",
       "      <td>Albigna</td>\n",
       "      <td>C84-16</td>\n",
       "      <td>RGI60-11.C84-16</td>\n",
       "      <td>RGI60-11.02285</td>\n",
       "      <td>RGI2000-v7.0-G-11-02309</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           full_name  sgi-id rgi_id_v6_2016_shp       rgi_id.v6  \\\n",
       "short_name                                                        \n",
       "adler          Adler  B56-14    RGI60-11.B56-14  RGI60-11.02764   \n",
       "albigna      Albigna  C84-16    RGI60-11.C84-16  RGI60-11.02285   \n",
       "\n",
       "                          rgi_id.v7  Issue  \n",
       "short_name                                  \n",
       "adler       RGI2000-v7.0-G-11-01075  False  \n",
       "albigna     RGI2000-v7.0-G-11-02309   True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RGI Ids:\n",
    "# Read glacier ids:\n",
    "rgi_df = pd.read_csv(path_glacier_ids, sep=',')\n",
    "rgi_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "rgi_df.sort_values(by='short_name', inplace=True)\n",
    "rgi_df.set_index('short_name', inplace=True)\n",
    "rgi_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of glaciers with pcsr: 31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['schwarzbach',\n",
       " 'taelliboden',\n",
       " 'pizol',\n",
       " 'sanktanna',\n",
       " 'corvatsch',\n",
       " 'sexrouge',\n",
       " 'murtel',\n",
       " 'plattalva',\n",
       " 'tortin',\n",
       " 'basodino',\n",
       " 'limmern',\n",
       " 'adler',\n",
       " 'hohlaub',\n",
       " 'albigna',\n",
       " 'tsanfleuron',\n",
       " 'silvretta',\n",
       " 'oberaar',\n",
       " 'gries',\n",
       " 'clariden',\n",
       " 'gietro',\n",
       " 'schwarzberg',\n",
       " 'forno',\n",
       " 'plainemorte',\n",
       " 'allalin',\n",
       " 'otemma',\n",
       " 'findelen',\n",
       " 'rhone',\n",
       " 'morteratsch',\n",
       " 'corbassiere',\n",
       " 'gorner',\n",
       " 'aletsch']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_glamos = pd.read_csv(path_PMB_GLAMOS_csv + 'CH_wgms_dataset_all.csv')\n",
    "glDirect = [\n",
    "    re.search(r'xr_direct_(.*?)\\.nc', f).group(1)\n",
    "    for f in os.listdir(path_pcsr + 'csv/')\n",
    "]\n",
    "data_glamos = data_glamos[data_glamos.GLACIER.isin(glDirect)]\n",
    "glacier_list = list(data_glamos.GLACIER.unique())\n",
    "print('Number of glaciers with pcsr:', len(glacier_list))\n",
    "\n",
    "# Glacier outlines:\n",
    "glacier_outline_rgi = gpd.read_file(\n",
    "    '../../../data/GLAMOS/RGI/nsidc0770_11.rgi60.CentralEurope/11_rgi60_CentralEurope.shp'\n",
    ")\n",
    "\n",
    "# Sort glaciers by area\n",
    "gl_area = get_gl_area()\n",
    "gl_area['clariden'] = gl_area['claridenL']\n",
    "\n",
    "\n",
    "# Sort the lists by area if available in gl_area\n",
    "def sort_by_area(glacier_list, gl_area):\n",
    "    return sorted(glacier_list, key=lambda g: gl_area.get(g, 0), reverse=False)\n",
    "\n",
    "\n",
    "glacier_list = sort_by_area(glacier_list, gl_area)\n",
    "glacier_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 08:46:54: oggm.cfg: Reading default parameters from the OGGM `params.cfg` configuration file.\n",
      "2025-03-03 08:46:54: oggm.cfg: Multiprocessing switched OFF according to the parameter file.\n",
      "2025-03-03 08:46:54: oggm.cfg: Multiprocessing: using all available processors (N=32)\n",
      "2025-03-03 08:46:54: oggm.cfg: PARAMS['border'] changed from `80` to `10`.\n",
      "2025-03-03 08:46:54: oggm.cfg: Multiprocessing switched ON after user settings.\n",
      "2025-03-03 08:46:54: oggm.cfg: PARAMS['continue_on_error'] changed from `False` to `True`.\n",
      "2025-03-03 08:46:54: oggm.workflow: init_glacier_directories from prepro level 3 on 32 glaciers.\n",
      "2025-03-03 08:46:54: oggm.workflow: Execute entity tasks [gdir_from_prepro] on 32 glaciers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rgis: 32\n"
     ]
    }
   ],
   "source": [
    "# Check which rgis are in the OGGM directory:\n",
    "oggmCfg.initialize(logging_level=\"WARNING\")\n",
    "oggmCfg.PARAMS[\"border\"] = 10\n",
    "oggmCfg.PARAMS[\"use_multiprocessing\"] = True\n",
    "oggmCfg.PARAMS[\"continue_on_error\"] = True\n",
    "custom_working_dir = '../../../data/OGGM/'\n",
    "oggmCfg.PATHS[\"working_dir\"] = custom_working_dir\n",
    "\n",
    "# Intersect dataframe with list of available glaciers in GLAMOS\n",
    "# to reduce computation load in OGGM\n",
    "rgidf = gpd.read_file(utils.get_rgi_region_file(region=\"11\", version=\"6\"))\n",
    "rgidf = rgidf.loc[rgidf['RGIId'].isin(data_glamos.RGIId.unique())]\n",
    "\n",
    "# We use the directories with the shop data in it: \"W5E5_w_data\"\n",
    "base_url = \"https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.1/elev_bands/W5E5_w_data/\"\n",
    "gdirs = workflow.init_glacier_directories(\n",
    "    rgidf,\n",
    "    from_prepro_level=3,\n",
    "    prepro_base_url=base_url,\n",
    "    prepro_border=10,\n",
    "    reset=True,\n",
    "    force=True,\n",
    ")\n",
    "rgis = list(\n",
    "    set(data_glamos.RGIId.unique()) & set(gdir.rgi_id for gdir in gdirs))\n",
    "print('Number of rgis:', len(rgis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute glacier grids:\n",
    "Add topo, climate variables and convert to monthly (takes a long time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655c3f47a39f48b4b0e13a0fedda0f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing glaciers:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 08:51:21: oggm.cfg: Reading default parameters from the OGGM `params.cfg` configuration file.\n",
      "2025-03-03 08:51:21: oggm.cfg: Multiprocessing switched OFF according to the parameter file.\n",
      "2025-03-03 08:51:21: oggm.cfg: Multiprocessing: using all available processors (N=32)\n",
      "2025-03-03 08:51:21: oggm.cfg: PARAMS['border'] changed from `80` to `10`.\n",
      "2025-03-03 08:51:21: oggm.cfg: Multiprocessing switched ON after user settings.\n",
      "2025-03-03 08:51:21: oggm.cfg: PARAMS['continue_on_error'] changed from `False` to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 08:51:21: oggm.workflow: init_glacier_directories from prepro level 3 on 1 glaciers.\n",
      "2025-03-03 08:51:21: oggm.workflow: Execute entity tasks [gdir_from_prepro] on 1 glaciers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------\n",
      "Processing: schwarzbach\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 08:51:21: oggm.workflow: Execute entity tasks [gridded_attributes] on 1 glaciers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding climate data...\n"
     ]
    }
   ],
   "source": [
    "# Set this flag to enable/disable the script execution\n",
    "RUN = True\n",
    "\n",
    "# Manual RGI ID overrides\n",
    "RGI_OVERRIDES = {'morteratsch': 'RGI60-11.01946', 'pers': 'RGI60-11.01946'}\n",
    "\n",
    "if RUN:\n",
    "    try:\n",
    "        emptyfolder(path_glacier_grid_rgi)\n",
    "    except Exception as e:\n",
    "        print(f\"Error clearing folder '{path_glacier_grid_rgi}': {e}\")\n",
    "    \n",
    "    for glacier_name in tqdm(glacier_list, desc='Processing glaciers'):\n",
    "        try:\n",
    "            print(f'\\n{\"-\" * 35}\\nProcessing: {glacier_name}')\n",
    "\n",
    "            # Retrieve RGI ID with manual overrides if applicable\n",
    "            rgi_gl = RGI_OVERRIDES.get(glacier_name, rgi_df.at[glacier_name, 'rgi_id.v6'])\n",
    "\n",
    "            # Load stake data for the glacier\n",
    "            data_gl = data_glamos[data_glamos.RGIId == rgi_gl]\n",
    "            if data_gl.empty:\n",
    "                raise ValueError(f\"No stake data found for glacier '{glacier_name}' (RGI ID: {rgi_gl})\")\n",
    "\n",
    "            dataset_gl = mbm.Dataset(cfg=cfg, data=data_gl, region_name='CH', data_path=path_PMB_GLAMOS_csv)\n",
    "\n",
    "            # Create gridded glacier dataset from OGGM\n",
    "            df_grid = dataset_gl.create_glacier_grid_RGI(custom_working_dir)\n",
    "            if df_grid.empty:\n",
    "                raise ValueError(f\"Failed to generate gridded dataset for glacier '{glacier_name}'\")\n",
    "\n",
    "            df_grid[\"GLACIER\"] = glacier_name\n",
    "            df_grid.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            dataset_grid = mbm.Dataset(cfg=cfg, data=df_grid, region_name='CH', data_path=path_PMB_GLAMOS_csv)\n",
    "\n",
    "            # Paths to climate data\n",
    "            era5_climate_data = os.path.join(path_ERA5_raw, 'era5_monthly_averaged_data.nc')\n",
    "            geopotential_data = os.path.join(path_ERA5_raw, 'era5_geopotential_pressure.nc')\n",
    "\n",
    "            # Add climate data\n",
    "            print('Adding climate data...')\n",
    "            dataset_grid.get_climate_features(\n",
    "                climate_data=era5_climate_data,\n",
    "                geopotential_data=geopotential_data,\n",
    "                change_units=True\n",
    "            )\n",
    "\n",
    "            # Add potential clear sky radiation\n",
    "            print('Adding potential clear sky radiation...')\n",
    "            dataset_grid.get_potential_rad(os.path.join(path_pcsr, 'csv/'))\n",
    "\n",
    "            YEARS = np.sort(dataset_grid.data.YEAR.unique())\n",
    "            \n",
    "            # Process each year separately\n",
    "            for year in YEARS:\n",
    "                try:\n",
    "                    print(f'Converting to monthly time resolution for {year}...')\n",
    "                    df_grid_y = dataset_grid.data[dataset_grid.data.YEAR == year].copy()\n",
    "                    dataset_grid_yearly = mbm.Dataset(cfg=cfg, data=df_grid_y, region_name='CH', data_path=path_PMB_GLAMOS_csv)\n",
    "                    dataset_grid_yearly.convert_to_monthly(\n",
    "                        meta_data_columns=cfg.metaData,\n",
    "                        vois_climate=vois_climate + ['pcsr'],\n",
    "                        vois_topographical=voi_topographical,\n",
    "                        year=year  # Assuming the function accepts a year parameter\n",
    "                    )\n",
    "\n",
    "                    # Ensure 'pcsr' column exists before saving\n",
    "                    if 'pcsr' not in dataset_grid_yearly.data.columns:\n",
    "                        raise ValueError(f\"'pcsr' column not found in dataset for glacier '{glacier_name}' in year {year}\")\n",
    "\n",
    "                    # Save the dataset for the specific year\n",
    "                    save_path = os.path.join(path_glacier_grid_rgi, f\"{glacier_name}_grid_{year}.parquet\")\n",
    "                    print(f'Saving gridded dataset to: {save_path}')\n",
    "                    dataset_grid_yearly.data.to_parquet(save_path, engine=\"pyarrow\", compression=\"snappy\")\n",
    "\n",
    "                except Exception as year_error:\n",
    "                    print(f\"⚠️ Error processing glacier '{glacier_name}' for year {year}: {year_error}\")\n",
    "                    traceback.print_exc()\n",
    "                    continue  # Continue with the next year\n",
    "\n",
    "        except Exception as glacier_error:\n",
    "            print(f\"Error processing glacier '{glacier_name}': {glacier_error}\")\n",
    "            traceback.print_exc()\n",
    "            continue  # Continue processing the next glacier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check grids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_name = 'rhone'\n",
    "rgi_gl = RGI_OVERRIDES.get(glacier_name, rgi_df.at[glacier_name, 'rgi_id.v6'])\n",
    "\n",
    "# Load stake data for that glacier\n",
    "data_gl = data_glamos[data_glamos.RGIId == rgi_gl]\n",
    "dataset_gl = mbm.Dataset(cfg=cfg,\n",
    "                         data=data_gl,\n",
    "                         region_name='CH',\n",
    "                         data_path=path_PMB_GLAMOS_csv)\n",
    "\n",
    "ds, glacier_indices, gdir = dataset_gl.get_glacier_mask(custom_working_dir)\n",
    "# Plot glacier attributes of oggm:\n",
    "plotGlAttr(ds, cmap=cm.devon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MBM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
