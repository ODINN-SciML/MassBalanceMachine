{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../')) # Add root of repo to import MBM\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "from calendar import month_abbr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from cmcrameri import cm\n",
    "import xarray as xr\n",
    "import massbalancemachine as mbm\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "from scripts.plots import *\n",
    "from scripts.config_CH import *\n",
    "from scripts.xgb_helpers import *\n",
    "from scripts.geodata import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)\n",
    "free_up_cuda()\n",
    "\n",
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "colors = get_cmap_hex(cm.batlow, 10)\n",
    "color_dark_blue = colors[0]\n",
    "color_pink = '#c51b7d'\n",
    "\n",
    "# RGI Ids:\n",
    "# Read rgi ids:\n",
    "rgi_df = pd.read_csv(cfg.dataPath + path_glacier_ids, sep=',')\n",
    "rgi_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "rgi_df.sort_values(by='short_name', inplace=True)\n",
    "rgi_df.set_index('short_name', inplace=True)\n",
    "\n",
    "vois_climate = [\n",
    "    't2m', 'tp', 'slhf', 'sshf', 'ssrd', 'fal', 'str', 'u10', 'v10'\n",
    "]\n",
    "\n",
    "vois_topographical = [\n",
    "    # \"aspect\", # OGGM\n",
    "    # \"slope\", # OGGM\n",
    "    \"aspect_sgi\",  # SGI\n",
    "    \"slope_sgi\",  # SGI\n",
    "    \"hugonnet_dhdt\",  # OGGM\n",
    "    \"consensus_ice_thickness\",  # OGGM\n",
    "    \"millan_v\",  # OGGM\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read GL data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_glamos = pd.read_csv(cfg.dataPath + path_PMB_GLAMOS_csv +\n",
    "                          'CH_wgms_dataset_all.csv')\n",
    "\n",
    "# Glaciers with data of potential clear sky radiation\n",
    "# Format to same names as stakes:\n",
    "glDirect = np.sort([\n",
    "    re.search(r'xr_direct_(.*?)\\.zarr', f).group(1)\n",
    "    for f in os.listdir(cfg.dataPath + path_pcsr + 'zarr/')\n",
    "])\n",
    "\n",
    "restgl = np.sort(Diff(list(glDirect), list(data_glamos.GLACIER.unique())))\n",
    "\n",
    "print('Glaciers with potential clear sky radiation data:\\n', glDirect)\n",
    "print('Number of glaciers:', len(glDirect))\n",
    "print('Glaciers without potential clear sky radiation data:\\n', restgl)\n",
    "\n",
    "# Filter out glaciers without data:\n",
    "data_glamos = data_glamos[data_glamos.GLACIER.isin(glDirect)]\n",
    "\n",
    "data_glamos.dropna(inplace=True)\n",
    "\n",
    "print('Number of glaciers:', len(data_glamos['GLACIER'].unique()))\n",
    "print('Number of winter and annual samples:', len(data_glamos))\n",
    "print('Number of annual samples:',\n",
    "      len(data_glamos[data_glamos.PERIOD == 'annual']))\n",
    "print('Number of winter samples:',\n",
    "      len(data_glamos[data_glamos.PERIOD == 'winter']))\n",
    "\n",
    "# Capitalize glacier names:\n",
    "glacierCap = {}\n",
    "for gl in data_glamos['GLACIER'].unique():\n",
    "    if isinstance(gl, str):  # Ensure the glacier name is a string\n",
    "        if gl.lower() == 'claridenu':\n",
    "            glacierCap[gl] = 'Clariden_U'\n",
    "        elif gl.lower() == 'claridenl':\n",
    "            glacierCap[gl] = 'Clariden_L'\n",
    "        else:\n",
    "            glacierCap[gl] = gl.capitalize()\n",
    "    else:\n",
    "        print(f\"Warning: Non-string glacier name encountered: {gl}\")\n",
    "\n",
    "data_glamos.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of mean mass balance per glacier:\n",
    "# Get the mean mass balance per glacier\n",
    "data_glamos_ = data_glamos.copy()\n",
    "data_glamos_['GLACIER'] = data_glamos['GLACIER'].apply(lambda x: glacierCap[x])\n",
    "\n",
    "mean_mb_per_glacier = data_glamos_.groupby(\n",
    "    ['GLACIER', 'YEAR', 'PERIOD'])['POINT_BALANCE'].mean().reset_index()\n",
    "mean_mb_per_glacier = mean_mb_per_glacier[mean_mb_per_glacier['PERIOD'] ==\n",
    "                                          'annual']\n",
    "\n",
    "matrix = mean_mb_per_glacier.pivot(\n",
    "    index='GLACIER', columns='YEAR',\n",
    "    values='POINT_BALANCE').sort_values(by='GLACIER')\n",
    "\n",
    "# get elevation of glaciers:\n",
    "gl_per_el = data_glamos_.groupby(['GLACIER'])['POINT_ELEVATION'].mean()\n",
    "gl_per_el = gl_per_el.sort_values(ascending=False)\n",
    "\n",
    "# Order matrix:\n",
    "matrix = matrix.loc[gl_per_el.index]\n",
    "matrix.index = pd.Categorical(matrix.index,\n",
    "                              categories=matrix.index,\n",
    "                              ordered=True)\n",
    "\n",
    "# Plot heatmap:\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "heatmap = sns.heatmap(\n",
    "    data=matrix,\n",
    "    center=0,\n",
    "    cmap=cm.vik_r,\n",
    "    cbar_kws={'label': '[m w.e. $a^{-1}$]'},\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "# Plot elevation:\n",
    "fig = plt.figure(figsize=(10, 2))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "sns.lineplot(gl_per_el.sort_values(ascending=True),\n",
    "             ax=ax,\n",
    "             color='gray',\n",
    "             marker='v')\n",
    "ax.set_xticklabels('', rotation=90)\n",
    "ax.set_ylabel('')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data:\n",
    "### Input dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Transform data to monthly format (run or load data):\n",
    "paths = {\n",
    "    'csv_path': cfg.dataPath + path_PMB_GLAMOS_csv,\n",
    "    'era5_climate_data':\n",
    "    cfg.dataPath + path_ERA5_raw + 'era5_monthly_averaged_data.nc',\n",
    "    'geopotential_data':\n",
    "    cfg.dataPath + path_ERA5_raw + 'era5_geopotential_pressure.nc',\n",
    "    'radiation_save_path': cfg.dataPath + path_pcsr + 'zarr/'\n",
    "}\n",
    "RUN = True\n",
    "dataloader_gl = process_or_load_data(run_flag=RUN,\n",
    "                                     data_glamos=data_glamos,\n",
    "                                     paths=paths,\n",
    "                                     cfg=cfg,\n",
    "                                     vois_climate=vois_climate,\n",
    "                                     vois_topographical=vois_topographical)\n",
    "data_monthly = dataloader_gl.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct for elevation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess GloGEM factors\n",
    "path_glogem_factors = os.path.join(cfg.dataPath + path_glogem,\n",
    "                                   'reference_run_GloGEM2024.csv')\n",
    "glogem_factors = pd.read_csv(path_glogem_factors)\n",
    "glogem_factors.rename(columns={'ID': 'RGIId'}, inplace=True)\n",
    "glogem_factors['RGIId'] = glogem_factors['RGIId'].apply(\n",
    "    lambda x: format_rgi_code(x))\n",
    "\n",
    "c_prec_dic, t_off_dic = {}, {}\n",
    "for gl in data_monthly.GLACIER.unique():\n",
    "    rgi_gl = data_monthly[data_monthly.GLACIER == gl].RGIId.unique()[0]\n",
    "    factor_gl = glogem_factors[glogem_factors.RGIId == rgi_gl]\n",
    "    c_prec_dic[gl] = factor_gl['Cprec'].values[0]\n",
    "    t_off_dic[gl] = factor_gl['T_off'].values[0]\n",
    "\n",
    "# Mean of dic values\n",
    "mean_c_prec = np.max(list(c_prec_dic.values()))\n",
    "mean_t_off = np.max(list(t_off_dic.values()))\n",
    "print(f\"Mean Cprec: {mean_c_prec}, Mean T_off: {mean_t_off}\")\n",
    "\n",
    "# Correct t2m and tp for elevation\n",
    "dataloader_gl.correct_for_elevation()\n",
    "\n",
    "# Plot the distribution of corrected and uncorrected precipitation and temperature\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Precipitation\n",
    "sns.histplot(data_monthly['tp'],\n",
    "             bins=50,\n",
    "             kde=True,\n",
    "             label='tp',\n",
    "             alpha=0.5,\n",
    "             ax=axes[0])\n",
    "sns.histplot(data_monthly['tp_corr'],\n",
    "             bins=50,\n",
    "             kde=True,\n",
    "             label='tp_corr',\n",
    "             alpha=0.5,\n",
    "             ax=axes[0])\n",
    "axes[0].set_title('Distribution of Precipitation')\n",
    "axes[0].set_xlabel('Precipitation (tp / tp_corr)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Temperature\n",
    "sns.histplot(data_monthly['t2m'],\n",
    "             bins=50,\n",
    "             kde=True,\n",
    "             label='t2m',\n",
    "             alpha=0.5,\n",
    "             ax=axes[1])\n",
    "sns.histplot(data_monthly['t2m_corr'],\n",
    "             bins=50,\n",
    "             kde=True,\n",
    "             label='t2m_corr',\n",
    "             alpha=0.5,\n",
    "             ax=axes[1])\n",
    "axes[1].set_title('Distribution of Temperature')\n",
    "axes[1].set_xlabel('Temperature (t2m / t2m_corr)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for correlation analysis\n",
    "df = dataloader_gl.data.copy().dropna()\n",
    "\n",
    "# Define the columns to keep\n",
    "columns_to_keep = [\n",
    "    col for col in df.columns if col not in [\n",
    "        'GLACIER', 'PERIOD', 'YEAR', 'POINT_LON', 'POINT_LAT', 'POINT_BALANCE',\n",
    "        'ALTITUDE_CLIMATE', 'POINT_ELEVATION', 'RGIId', 'POINT_ID', 'ID',\n",
    "        'GLWD_ID', 'N_MONTHS', 'MONTHS'\n",
    "    ]\n",
    "]\n",
    "df = df[columns_to_keep]\n",
    "\n",
    "# Rename columns based on long names (if applicable)\n",
    "df.rename(columns=vois_climate_long_name, inplace=True)\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Plot the heatmap\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    mask=mask,\n",
    "    cmap='coolwarm',\n",
    "    vmax=1,\n",
    "    vmin=-1,\n",
    "    center=0,\n",
    "    annot=True,  # Add correlation values\n",
    "    fmt=\".2f\",\n",
    "    square=True,\n",
    "    linewidths=.5,\n",
    "    cbar_kws={\"shrink\": 0.8})\n",
    "\n",
    "# Enhance readability\n",
    "plt.title(\"Feature Intercorrelation Heatmap\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Num. meas per year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of measurements per year:\n",
    "dataloader_gl.data.groupby(['YEAR', 'PERIOD']).size().unstack().plot(\n",
    "    kind='bar',\n",
    "    stacked=True,\n",
    "    figsize=(20, 5),\n",
    "    color=[color_dark_blue, color_pink])\n",
    "plt.title('Number of measurements per year for all glaciers')\n",
    "\n",
    "# Plot winter and annual separately:\n",
    "fig, axs = plt.subplots(2, 1, figsize=(20, 10), sharey=False)\n",
    "dataloader_gl.data[dataloader_gl.data.PERIOD == 'winter'].groupby(\n",
    "    ['YEAR', 'PERIOD']).size().unstack().plot(kind='bar',\n",
    "                                              ax=axs[0],\n",
    "                                              color=[color_pink],\n",
    "                                              legend=False)\n",
    "axs[0].set_title('Number of winter measurements per year for all glaciers',\n",
    "                 fontsize=24)\n",
    "\n",
    "dataloader_gl.data[dataloader_gl.data.PERIOD == 'annual'].groupby(\n",
    "    ['YEAR', 'PERIOD']).size().unstack().plot(kind='bar',\n",
    "                                              stacked=True,\n",
    "                                              ax=axs[1],\n",
    "                                              color=[color_dark_blue],\n",
    "                                              legend=False)\n",
    "axs[1].set_title('Number of annual measurements per year for all glaciers',\n",
    "                 fontsize=24)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check of variables:\n",
    "df = dataloader_gl.data\n",
    "var_to_plot = ['POINT_BALANCE'] + vois_climate + ['pcsr']\n",
    "df = df[(df.GLACIER == 'corvatsch') & (df.YEAR == 2015)].groupby(\n",
    "    ['MONTHS'])[var_to_plot].mean().reset_index()\n",
    "df['month_nb'] = df.MONTHS.apply(\n",
    "    lambda x: list(month_abbr).index(x.capitalize()))\n",
    "df.sort_values(by='month_nb', inplace=True)\n",
    "fig, ax = plt.subplots(3, 4, figsize=(10, 8))\n",
    "\n",
    "for i, var in enumerate(var_to_plot):\n",
    "    df.plot(x='MONTHS', y=var, marker='o', ax=ax.flatten()[i], legend=False)\n",
    "    if var in vois_climate_long_name.keys():\n",
    "        ax.flatten()[i].set_title(vois_climate_long_name[var], fontsize=12)\n",
    "    else:\n",
    "        ax.flatten()[i].set_title(var, fontsize=12)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the topo variables:\n",
    "df = dataloader_gl.data\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 6))\n",
    "for i, var in enumerate(vois_topographical + ['ELEVATION_DIFFERENCE']):\n",
    "    ax = axs.flatten()[i]\n",
    "    sns.histplot(df[var], ax=ax, kde=True)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_title(var)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocking on glaciers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_glaciers = [\n",
    "    'tortin', 'plattalva', 'sanktanna', 'schwarzberg', 'hohlaub', 'pizol',\n",
    "    'corvatsch', 'tsanfleuron', 'forno'\n",
    "]\n",
    "\n",
    "# Ensure all test glaciers exist in the dataset\n",
    "existing_glaciers = set(dataloader_gl.data.GLACIER.unique())\n",
    "missing_glaciers = [g for g in test_glaciers if g not in existing_glaciers]\n",
    "\n",
    "if missing_glaciers:\n",
    "    print(\n",
    "        f\"Warning: The following test glaciers are not in the dataset: {missing_glaciers}\"\n",
    "    )\n",
    "\n",
    "# Define training glaciers correctly\n",
    "train_glaciers = [i for i in existing_glaciers if i not in test_glaciers]\n",
    "\n",
    "data_test = dataloader_gl.data[dataloader_gl.data.GLACIER.isin(test_glaciers)]\n",
    "print('Size of test data:', len(data_test))\n",
    "\n",
    "data_train = dataloader_gl.data[dataloader_gl.data.GLACIER.isin(\n",
    "    train_glaciers)]\n",
    "print('Size of train data:', len(data_train))\n",
    "\n",
    "if len(data_train) == 0:\n",
    "    print(\"Warning: No training data available!\")\n",
    "else:\n",
    "    test_perc = (len(data_test) / len(data_train)) * 100\n",
    "    print('Percentage of test size: {:.2f}%'.format(test_perc))\n",
    "\n",
    "# Number of annual versus winter measurements:\n",
    "print('Train:')\n",
    "print('Number of winter and annual samples:', len(data_train))\n",
    "print('Number of annual samples:',\n",
    "      len(data_train[data_train.PERIOD == 'annual']))\n",
    "print('Number of winter samples:',\n",
    "      len(data_train[data_train.PERIOD == 'winter']))\n",
    "\n",
    "# Same for test\n",
    "data_test_annual = data_test[data_test.PERIOD == 'annual']\n",
    "data_test_winter = data_test[data_test.PERIOD == 'winter']\n",
    "\n",
    "print('Test:')\n",
    "print('Number of winter and annual samples:', len(data_test))\n",
    "print('Number of annual samples:', len(data_test_annual))\n",
    "print('Number of winter samples:', len(data_test_winter))\n",
    "\n",
    "print('Total:')\n",
    "print('Number of monthly rows:', len(dataloader_gl.data))\n",
    "print('Number of annual rows:',\n",
    "      len(dataloader_gl.data[dataloader_gl.data.PERIOD == 'annual']))\n",
    "print('Number of winter rows:',\n",
    "      len(dataloader_gl.data[dataloader_gl.data.PERIOD == 'winter']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap annual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHeatmap(test_glaciers, data_glamos, glacierCap, period='annual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap winter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHeatmap(test_glaciers, data_glamos, glacierCap, period='winter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits, test_set, train_set = get_CV_splits(dataloader_gl,\n",
    "                                            test_split_on='GLACIER',\n",
    "                                            test_splits=test_glaciers,\n",
    "                                            random_state=cfg.seed)\n",
    "\n",
    "print('Test glaciers: ({}) {}'.format(len(test_set['splits_vals']),\n",
    "                                      test_set['splits_vals']))\n",
    "test_perc = (len(test_set['df_X']) / len(train_set['df_X'])) * 100\n",
    "print('Percentage of test size: {:.2f}%'.format(test_perc))\n",
    "print('Size of test set:', len(test_set['df_X']))\n",
    "print('Train glaciers: ({}) {}'.format(len(train_set['splits_vals']),\n",
    "                                       train_set['splits_vals']))\n",
    "print('Size of train set:', len(train_set['df_X']))\n",
    "\n",
    "visualiseSplits(test_set['y'], train_set['y'], splits)\n",
    "visualiseInputs(train_set, test_set, vois_climate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distributions of test glaciers:\n",
    "f, ax = plt.subplots(len(test_glaciers),\n",
    "                     len(vois_climate) + 3,\n",
    "                     figsize=(16, 10),\n",
    "                     sharey='row',\n",
    "                     sharex='col')\n",
    "\n",
    "for i, test_gl in enumerate(test_glaciers):\n",
    "    test_df_gl = test_set['df_X'][test_set['df_X'].GLACIER == test_gl]\n",
    "    test_df_gl['POINT_BALANCE'].plot.hist(ax=ax[i, 0],\n",
    "                                          color=color_dark_blue,\n",
    "                                          alpha=0.6,\n",
    "                                          density=False)\n",
    "    ax[i, 0].set_title('PMB')\n",
    "    ax[i, 0].set_ylabel(test_gl)\n",
    "    ax[i, 0].set_xlabel('[m w.e.]')\n",
    "    test_df_gl['ELEVATION_DIFFERENCE'].plot.hist(ax=ax[i, 1],\n",
    "                                                 color=color_dark_blue,\n",
    "                                                 alpha=0.6,\n",
    "                                                 density=False)\n",
    "    ax[i, 1].set_title('ELV_DIFF')\n",
    "    ax[i, 1].set_xlabel('[m]')\n",
    "\n",
    "    for j, voi_clim in enumerate(vois_climate + ['pcsr']):\n",
    "        ax[i, 2 + j].set_title(voi_clim)\n",
    "        test_df_gl[voi_clim].plot.hist(ax=ax[i, 2 + j],\n",
    "                                       color=color_dark_blue,\n",
    "                                       alpha=0.6,\n",
    "                                       density=False)\n",
    "        ax[i, 2 + j].set_xlabel(vois_units[voi_clim])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,\n",
    "                     len(test_glaciers),\n",
    "                     figsize=(20, 5),\n",
    "                     sharey='row',\n",
    "                     sharex='row')\n",
    "\n",
    "for i, test_gl in enumerate(test_glaciers):\n",
    "    test_df_gl = test_set['df_X'][test_set['df_X'].GLACIER == test_gl]\n",
    "    test_df_gl.POINT_ELEVATION.plot.hist(color=color_dark_blue,\n",
    "                                         alpha=0.5,\n",
    "                                         density=False,\n",
    "                                         ax=ax[i])\n",
    "    # add vertical line for altitude climate\n",
    "    alt_climate = test_df_gl.ALTITUDE_CLIMATE.mean()\n",
    "    ax[i].axvline(x=alt_climate,\n",
    "                  color='red',\n",
    "                  linestyle='--',\n",
    "                  label='Altitude climate')\n",
    "    ax[i].set_xlabel('Elevation [m]')\n",
    "    ax[i].legend()\n",
    "    ax[i].set_title(test_gl)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of measurements per year:\n",
    "fig, ax = plt.subplots(2, 1, figsize=(15, 10))\n",
    "data_test.groupby(['YEAR', 'PERIOD']).size().unstack().plot(\n",
    "    kind='bar', stacked=True, color=[color_dark_blue, color_pink], ax=ax[0])\n",
    "ax[0].set_title('Number of measurements per year for test glaciers')\n",
    "\n",
    "# Number of measurements per year:\n",
    "data_train.groupby(['YEAR', 'PERIOD']).size().unstack().plot(\n",
    "    kind='bar', stacked=True, color=[color_dark_blue, color_pink], ax=ax[1])\n",
    "ax[1].set_title('Number of measurements per year for train glaciers')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search\n",
    "# For each of the XGBoost parameter, define the grid range\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5, 6, 7, 8],\n",
    "    'n_estimators':\n",
    "    [50, 100, 200, 300, 400, 500, 600,\n",
    "     700],  # number of trees (too many = overfitting, too few = underfitting)\n",
    "    'learning_rate': [0.01, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "}\n",
    "\n",
    "param_init = {\n",
    "    'device': 'cuda:0',\n",
    "    'tree_method': 'hist',\n",
    "    \"random_state\": cfg.seed,\n",
    "    \"n_jobs\": cfg.numJobs\n",
    "}\n",
    "\n",
    "vois_climate = [\n",
    "    't2m', 'tp', 'slhf', 'sshf', 'ssrd', 'fal', 'str', 'u10', 'v10'\n",
    "]\n",
    "\n",
    "vois_topographical = [\n",
    "    \"aspect_sgi\",\n",
    "    \"slope_sgi\",\n",
    "    \"hugonnet_dhdt\",\n",
    "    \"consensus_ice_thickness\",\n",
    "    \"millan_v\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Feature columns:\n",
    "# features_topo = [\n",
    "#     'ELEVATION_DIFFERENCE', 'pcsr',\n",
    "# ] + list(vois_topographical)\n",
    "\n",
    "# feature_columns = features_topo + list(vois_climate)\n",
    "\n",
    "# cfg.setFeatures(feature_columns)\n",
    "\n",
    "# all_columns = feature_columns + cfg.fieldsNotFeatures\n",
    "\n",
    "# df_X_train_subset = train_set['df_X'][all_columns]\n",
    "# print('Shape of training dataset:', df_X_train_subset.shape)\n",
    "# print('Shape of testing dataset:', test_set['df_X'][all_columns].shape)\n",
    "# print('Running with features:', feature_columns)\n",
    "\n",
    "# RUN = False\n",
    "# if RUN:\n",
    "#     # Create a CustomXGBoostRegressor instance\n",
    "#     custom_xgboost = mbm.models.CustomXGBoostRegressor(cfg, **param_init)\n",
    "#     custom_xgboost.randomsearch(\n",
    "#         parameters=param_grid,\n",
    "#         n_iter=45,\n",
    "#         splits=splits,\n",
    "#         features=df_X_train_subset,\n",
    "#         targets=train_set['y'],\n",
    "#     )\n",
    "\n",
    "#     # save best model\n",
    "#     custom_xgboost.save_model(f'xgb_gl_split_sgi_corr.pkl')\n",
    "# else:\n",
    "#     # read model\n",
    "#     custom_xgboost = mbm.models.CustomXGBoostRegressor(cfg)\n",
    "#     custom_xgboost.load_model(\n",
    "#         f'xgb_gl_split_sgi_corr.pkl')  # model with SGI aspect&slope\n",
    "\n",
    "# # Get best parameters and estimator\n",
    "# best_params = custom_xgboost.param_search.best_params_\n",
    "# best_estimator = custom_xgboost.param_search.best_estimator_\n",
    "# print(\"Best parameters:\\n\", best_params)\n",
    "# print(\"Best score:\\n\", custom_xgboost.param_search.best_score_)\n",
    "\n",
    "# # Make predictions on test:\n",
    "# # Set to CPU for predictions:\n",
    "# best_estimator_cpu = best_estimator.set_params(device='cpu')\n",
    "\n",
    "# # Make predictions on test\n",
    "# features_test, metadata_test = best_estimator_cpu._create_features_metadata(\n",
    "#     test_set['df_X'][all_columns])\n",
    "# y_pred = best_estimator_cpu.predict(features_test)\n",
    "# print('Shape of the test:', features_test.shape)\n",
    "\n",
    "# # Make predictions aggr to meas ID:\n",
    "# y_pred_agg = best_estimator_cpu.aggrPredict(metadata_test, features_test)\n",
    "\n",
    "# # Calculate scores\n",
    "# score = best_estimator_cpu.score(test_set['df_X'][all_columns],\n",
    "#                                  test_set['y'])  # negative\n",
    "# print('Overall score:', np.abs(score))\n",
    "\n",
    "# plotGridSearchScore(cv_results_=custom_xgboost.param_search.cv_results_,\n",
    "#                     lossType=cfg.loss)\n",
    "# plotGridSearchParams(custom_xgboost.param_search.cv_results_,\n",
    "#                      param_grid,\n",
    "#                      lossType=cfg.loss)\n",
    "# plotGridSearchParams(custom_xgboost.param_search.cv_results_,\n",
    "#                      param_grid,\n",
    "#                      lossType=cfg.loss,\n",
    "#                      N=10)\n",
    "\n",
    "# FIPlot(best_estimator, feature_columns, vois_climate)\n",
    "\n",
    "# # Make predictions on test:\n",
    "# # Set to CPU for predictions:\n",
    "# best_estimator_cpu = best_estimator.set_params(device='cpu')\n",
    "\n",
    "# features_test, metadata_test = best_estimator_cpu._create_features_metadata(\n",
    "#     test_set['df_X'][all_columns])\n",
    "# y_pred = best_estimator_cpu.predict(features_test)\n",
    "# print('Shape of the test:', features_test.shape)\n",
    "\n",
    "# y_pred_agg = best_estimator_cpu.aggrPredict(metadata_test, features_test)\n",
    "# grouped_ids = getDfAggregatePred(test_set, y_pred_agg, all_columns)\n",
    "# PlotPredictions(grouped_ids, y_pred, metadata_test, test_set,\n",
    "#                 best_estimator_cpu)\n",
    "# plt.suptitle(f'XGBoost tested on {test_glaciers}', fontsize=20)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions of custom parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_params = {'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 800}\n",
    "\n",
    "# Feature columns:\n",
    "feature_columns = [\n",
    "    'ELEVATION_DIFFERENCE'\n",
    "] + list(vois_climate) + list(vois_topographical) + ['pcsr']\n",
    "\n",
    "all_columns = feature_columns + cfg.fieldsNotFeatures\n",
    "df_X_train_subset = train_set['df_X'][all_columns]\n",
    "print('Shape of training dataset:', df_X_train_subset.shape)\n",
    "print('Shape of testing dataset:', test_set['df_X'][all_columns].shape)\n",
    "print('Running with features:', feature_columns)\n",
    "\n",
    "params = {**param_init, **custom_params}\n",
    "print(params)\n",
    "custom_model = mbm.models.CustomXGBoostRegressor(cfg, **params)\n",
    "\n",
    "# Fit on train data:\n",
    "custom_model.fit(train_set['df_X'][all_columns], train_set['y'])\n",
    "\n",
    "# Make predictions on test\n",
    "custom_model = custom_model.set_params(device='cpu')\n",
    "features_test, metadata_test = custom_model._create_features_metadata(\n",
    "    test_set['df_X'][all_columns])\n",
    "y_pred = custom_model.predict(features_test)\n",
    "print('Shape of the test:', features_test.shape)\n",
    "\n",
    "# Make predictions aggr to meas ID:\n",
    "y_pred_agg = custom_model.aggrPredict(metadata_test, features_test)\n",
    "\n",
    "# Calculate scores\n",
    "score = custom_model.score(test_set['df_X'][all_columns],\n",
    "                           test_set['y'])  # negative\n",
    "print('Overall score:', np.abs(score))\n",
    "\n",
    "grouped_ids = getDfAggregatePred(test_set, y_pred_agg, all_columns)\n",
    "PlotPredictions(grouped_ids, y_pred, metadata_test, test_set, custom_model)\n",
    "plt.suptitle(f'MBM tested on {test_glaciers}', fontsize=20)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate predictions to annual or winter:\n",
    "gl_per_el = data_glamos[data_glamos.PERIOD == 'annual'].groupby(\n",
    "    ['GLACIER'])['POINT_ELEVATION'].mean()\n",
    "gl_per_el = gl_per_el.sort_values(ascending=False)\n",
    "\n",
    "test_gl_per_el = gl_per_el[test_glaciers].sort_values().index\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(20, 15), sharex=True)\n",
    "\n",
    "PlotIndividualGlacierPredVsTruth(grouped_ids,\n",
    "                                 axs=axs,\n",
    "                                 color_annual=color_dark_blue,\n",
    "                                 color_winter=color_pink,\n",
    "                                 custom_order=test_gl_per_el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIPlot(custom_model, feature_columns, vois_climate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrapolate in space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geodetic MB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodetic_mb = get_geodetic_MB(cfg)\n",
    "\n",
    "# filter to glaciers with potential clear sky radiation data\n",
    "geodetic_mb = geodetic_mb[geodetic_mb.glacier_name.isin(glDirect)]\n",
    "\n",
    "# get years per glacier\n",
    "years_start_per_gl = geodetic_mb.groupby(\n",
    "    'glacier_name')['Astart'].unique().apply(list).to_dict()\n",
    "years_end_per_gl = geodetic_mb.groupby('glacier_name')['Aend'].unique().apply(\n",
    "    list).to_dict()\n",
    "\n",
    "periods_per_glacier, _ = build_periods_per_glacier(geodetic_mb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glacier wide MB: \n",
    "Compute 2D fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_list = list(data_glamos.GLACIER.unique())\n",
    "print('Number of glaciers with pcsr:', len(glacier_list))\n",
    "\n",
    "geodetic_glaciers = periods_per_glacier.keys()\n",
    "print('Number of glaciers with geodetic MB:', len(geodetic_glaciers))\n",
    "\n",
    "# Intersection of both\n",
    "common_glaciers = list(set(geodetic_glaciers) & set(glacier_list))\n",
    "print('Number of common glaciers:', len(common_glaciers))\n",
    "\n",
    "# Sort glaciers by area\n",
    "gl_area = get_gl_area(cfg)\n",
    "gl_area['clariden'] = gl_area['claridenL']\n",
    "\n",
    "\n",
    "# Sort the lists by area if available in gl_area\n",
    "def sort_by_area(glacier_list, gl_area):\n",
    "    return sorted(glacier_list, key=lambda g: gl_area.get(g, 0), reverse=False)\n",
    "\n",
    "\n",
    "glacier_list = sort_by_area(common_glaciers, gl_area)\n",
    "glacier_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GLAMOS grids & Normal T & P:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "path_save_glw = cfg.dataPath + '/GLAMOS/distributed_MB_grids/MBM/glamos_dems/'\n",
    "path_xr_grids = cfg.dataPath + '/GLAMOS/topo/GLAMOS_DEM/xr_masked_grids/'  # GLAMOS DEMs\n",
    "# Feature columns\n",
    "vois_climate = [\n",
    "    't2m', 'tp', 'slhf', 'sshf', 'ssrd', 'fal', 'str', 'u10', 'v10'\n",
    "]\n",
    "feature_columns = [\n",
    "    'ELEVATION_DIFFERENCE'\n",
    "] + list(vois_climate) + list(vois_topographical) + ['pcsr']\n",
    "all_columns = feature_columns + cfg.fieldsNotFeatures\n",
    "print('Running for feature columns:', all_columns)\n",
    "\n",
    "RUN = True\n",
    "if RUN:\n",
    "    emptyfolder(path_save_glw)\n",
    "\n",
    "    for glacier_name in glacier_list:\n",
    "        glacier_path = os.path.join(cfg.dataPath, path_glacier_grid_glamos,\n",
    "                                    glacier_name)\n",
    "\n",
    "        if not os.path.exists(glacier_path):\n",
    "            print(f\"Folder not found for {glacier_name}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        glacier_files = sorted(\n",
    "            [f for f in os.listdir(glacier_path) if glacier_name in f])\n",
    "\n",
    "        geodetic_range = range(np.min(periods_per_glacier[glacier_name]),\n",
    "                               np.max(periods_per_glacier['aletsch']) + 1)\n",
    "\n",
    "        years = [\n",
    "            int(file_name.split('_')[2].split('.')[0])\n",
    "            for file_name in glacier_files\n",
    "        ]\n",
    "        years = [y for y in years if y in geodetic_range]\n",
    "\n",
    "        print(f\"Processing {glacier_name} ({len(years)} files)\")\n",
    "\n",
    "        for year in tqdm(years, desc=f\"Processing {glacier_name}\",\n",
    "                         leave=False):\n",
    "            file_name = f\"{glacier_name}_grid_{year}.parquet\"\n",
    "\n",
    "            # Load parquet input glacier grid file in monthly format (pre-processed)\n",
    "            df_grid_monthly = pd.read_parquet(\n",
    "                os.path.join(cfg.dataPath, path_glacier_grid_glamos,\n",
    "                             glacier_name, file_name))\n",
    "            df_grid_monthly.drop_duplicates(inplace=True)\n",
    "\n",
    "            # Keep only necessary columns, avoiding missing columns issues\n",
    "            df_grid_monthly = df_grid_monthly[[\n",
    "                col for col in all_columns if col in df_grid_monthly.columns\n",
    "            ]]\n",
    "\n",
    "            # Create geodata object\n",
    "            geoData = mbm.geodata.GeoData(df_grid_monthly)\n",
    "\n",
    "            # Computes and saves gridded MB for a year and glacier\n",
    "            path_glacier_dem = os.path.join(path_xr_grids,\n",
    "                                            f\"{glacier_name}_{year}.zarr\")\n",
    "            geoData.gridded_MB_pred(df_grid_monthly, \n",
    "                                    custom_model,\n",
    "                                    glacier_name,\n",
    "                                    year,\n",
    "                                    all_columns,\n",
    "                                    path_glacier_dem,\n",
    "                                    path_save_glw,\n",
    "                                    save_monthly_pred=True,\n",
    "                                    type_model='XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_name = 'clariden'\n",
    "year = 2010\n",
    "# open xarray\n",
    "xr.open_dataset(\n",
    "    path_save_glw +\n",
    "    f'{glacier_name}/{glacier_name}_{year}_annual.zarr').pred_masked.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_name = 'clariden'\n",
    "year = 2010\n",
    "# open xarray\n",
    "xr.open_dataset(\n",
    "    path_save_glw +\n",
    "    f'{glacier_name}/{glacier_name}_{year}_aug.zarr').pred_masked.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
