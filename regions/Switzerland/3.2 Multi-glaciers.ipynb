{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import massbalancemachine as mbm\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, LineString, Point\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GroupKFold, KFold, train_test_split, GroupShuffleSplit\n",
    "from calendar import month_abbr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from cmcrameri import cm\n",
    "from oggm import cfg, utils, workflow, tasks\n",
    "import logging\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "\n",
    "import config\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "from scripts.plots import *\n",
    "from scripts.xgb_helpers import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(config.SEED)\n",
    "free_up_cuda()\n",
    "\n",
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "\n",
    "cmap = cm.devon\n",
    "color_palette_glaciers = sns.color_palette(get_cmap_hex(cmap, 15))\n",
    "\n",
    "# For bars and lines:\n",
    "# color_diff_xgb = '#878787'\n",
    "color_diff_xgb = '#4d4d4d'\n",
    "\n",
    "colors = get_cmap_hex(cm.batlow, 10)\n",
    "color_xgb = colors[0]\n",
    "color_xgb_winter = colors[1]\n",
    "\n",
    "color_tim = '#c51b7d'\n",
    "\n",
    "# Violin and boxplots:\n",
    "colors_temp_freq = sns.color_palette(get_cmap_hex(cm.devon, 8))\n",
    "boxplot_style = {\n",
    "    \"width\": .6,\n",
    "    \"showcaps\": False,\n",
    "    \"palette\": colors_temp_freq,\n",
    "    \"flierprops\": {\n",
    "        \"marker\": \"x\"\n",
    "    },\n",
    "    \"showmeans\": True,\n",
    "    \"meanprops\": {\n",
    "        \"markerfacecolor\": \"white\"\n",
    "    }\n",
    "}\n",
    "\n",
    "marker_tim = 's'\n",
    "marker_xgb = 'o'\n",
    "marker_std = '_'\n",
    "\n",
    "custom_working_dir = '../../../data/OGGM/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGI Ids:\n",
    "# Read rgi ids:\n",
    "path_rgi = '../../../data/GLAMOS/CH_glacier_ids_long.csv'\n",
    "rgi_df = pd.read_csv(path_rgi, sep=',')\n",
    "rgi_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "rgi_df.sort_values(by='short_name', inplace=True)\n",
    "rgi_df.set_index('short_name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the short names of the climate variables available in the dataset\n",
    "vois_climate = [\n",
    "    't2m', 'tp', 'slhf', 'sshf', 'ssrd', 'fal', 'str', 'u10', 'v10'\n",
    "]\n",
    "vois_topographical = [\n",
    "    \"aspect\", \"slope\", \"dis_from_border\", \"hugonnet_dhdt\",\n",
    "    \"consensus_ice_thickness\", \"millan_ice_thickness\", \"millan_v\", \"millan_vx\",\n",
    "    \"millan_vy\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All glaciers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read stakes data over all glaciers:\n",
    "data_glamos = pd.read_csv(path_PMB_GLAMOS_csv + 'CH_wgms_dataset.csv')\n",
    "\n",
    "print('Number of glaciers:', len(data_glamos['GLACIER'].unique()))\n",
    "data_glamos.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of mean mass balance per glacier:\n",
    "# Get the mean mass balance per glacier\n",
    "mean_mb_per_glacier = data_glamos.groupby(\n",
    "    ['GLACIER', 'YEAR', 'PERIOD'])['POINT_BALANCE'].mean().reset_index()\n",
    "mean_mb_per_glacier = mean_mb_per_glacier[mean_mb_per_glacier['PERIOD'] ==\n",
    "                                          'annual']\n",
    "\n",
    "matrix = mean_mb_per_glacier.pivot(\n",
    "    index='GLACIER', columns='YEAR',\n",
    "    values='POINT_BALANCE').sort_values(by='GLACIER')\n",
    "\n",
    "# get elevation of glaciers:\n",
    "gl_per_el = data_glamos.groupby(['GLACIER'])['POINT_ELEVATION'].mean()\n",
    "\n",
    "matrix = matrix.loc[gl_per_el.sort_values(ascending=True).index]\n",
    "\n",
    "# make index categorical\n",
    "matrix.index = pd.Categorical(matrix.index,\n",
    "                              categories=matrix.index,\n",
    "                              ordered=True)\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "sns.heatmap(data=matrix,\n",
    "            center=0,\n",
    "            cmap=cm.vik_r,\n",
    "            cbar_kws={'label': '[m w.e. $a^{-1}$]'},\n",
    "            ax=ax)\n",
    "\n",
    "# Plot elevation:\n",
    "fig = plt.figure(figsize=(10, 2))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "sns.lineplot(gl_per_el.sort_values(ascending=True),\n",
    "             ax=ax,\n",
    "             color='gray',\n",
    "             marker='v')\n",
    "ax.set_xticklabels('', rotation=90)\n",
    "ax.set_ylabel('')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gl = data_glamos.groupby(['GLACIER']).size().sort_values()\n",
    "num_gl.plot(kind='bar', figsize=(15, 5), cmap=cmap)\n",
    "plt.title('Number of total measurements per glacier since 1961')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glaciers with potential radiadation data from GLAMOS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glaciers with data of potential clear sky radiation\n",
    "# Format to same names as stakes:\n",
    "glDirect = [\n",
    "    re.search(r'xr_direct_(.*?)\\.nc', f).group(1)\n",
    "    for f in os.listdir(path_direct_save)\n",
    "]\n",
    "glDirect.sort()\n",
    "\n",
    "restgl = Diff(list(glDirect), list(data_glamos.GLACIER.unique()))\n",
    "restgl.sort()\n",
    "print('Glaciers with potential clear sky radiation data:\\n', glDirect)\n",
    "print('Glaciers without potential clear sky radiation data:\\n', restgl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.open_dataset(path_ERA5_raw + 'era5_monthly_averaged_data.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data:\n",
    "### Input dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN = False\n",
    "if RUN:\n",
    "    # Filter data_glamos\n",
    "    data_glamos = data_glamos[data_glamos.GLACIER.isin(glDirect)]\n",
    "    print('Running on {} glaciers:\\n {}'.format(\n",
    "        len(data_glamos.GLACIER.unique()), data_glamos.GLACIER.unique()))\n",
    "    # Create dataloader:\n",
    "    dataset_gl = mbm.Dataset(data=data_glamos,\n",
    "                             region_name='CH',\n",
    "                             data_path=path_PMB_GLAMOS_csv)\n",
    "    print('Number of winter and annual samples:', len(data_glamos))\n",
    "    print('Number of annual samples:',\n",
    "          len(data_glamos[data_glamos.PERIOD == 'annual']))\n",
    "    print('Number of winter samples:',\n",
    "          len(data_glamos[data_glamos.PERIOD == 'winter']))\n",
    "\n",
    "    # Add climate data:\n",
    "    # Specify the files of the climate data, that will be matched with the coordinates of the stake data\n",
    "    era5_climate_data = path_ERA5_raw + 'era5_monthly_averaged_data.nc'\n",
    "    geopotential_data = path_ERA5_raw + 'era5_geopotential_pressure.nc'\n",
    "\n",
    "    # Match the climate features, from the ERA5Land netCDF file, for each of the stake measurement dataset\n",
    "    dataset_gl.get_climate_features(climate_data=era5_climate_data,\n",
    "                                    geopotential_data=geopotential_data,\n",
    "                                    change_units=True)\n",
    "\n",
    "    # Add potential clear sky radiation:\n",
    "    print('----------------------\\nAdding potential clear sky radiation:')\n",
    "    print('Shape before pot rad:', dataset_gl.data.shape)\n",
    "    dataset_gl.get_potential_rad(path_direct_save)\n",
    "    print('Shape after pot rad:', dataset_gl.data.shape)\n",
    "\n",
    "    print('----------------------\\nConverting to monthly resolution:')\n",
    "    # For each record, convert to a monthly time resolution\n",
    "    dataset_gl.convert_to_monthly(meta_data_columns=config.META_DATA,\n",
    "                                  vois_climate=vois_climate + ['pcsr'],\n",
    "                                  vois_topographical=vois_topographical)\n",
    "\n",
    "    # Create a new DataLoader object with the monthly stake data measurements.\n",
    "    dataloader_gl = mbm.DataLoader(data=dataset_gl.data,\n",
    "                                   random_seed=config.SEED,\n",
    "                                   meta_data_columns=config.META_DATA)\n",
    "\n",
    "    print('Number of monthly rows:', len(dataloader_gl.data))\n",
    "    print('Columns in the dataset:', dataloader_gl.data.columns)\n",
    "\n",
    "    # save the data\n",
    "    dataloader_gl.data.to_csv(path_PMB_GLAMOS_csv +\n",
    "                              'CH_wgms_dataset_monthly.csv',\n",
    "                              index=False)\n",
    "else:\n",
    "    # read data\n",
    "    data_monthly = pd.read_csv(path_PMB_GLAMOS_csv +\n",
    "                               'CH_wgms_dataset_monthly.csv')\n",
    "    dataloader_gl = mbm.DataLoader(data=data_monthly,\n",
    "                                   random_seed=config.SEED,\n",
    "                                   meta_data_columns=config.META_DATA)\n",
    "    print('Number of monthly rows:', len(dataloader_gl.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intercorrelation between features:\n",
    "df = dataloader_gl.data.copy()\n",
    "df = df.dropna()\n",
    "df = df.drop(columns=[\n",
    "    'GLACIER',\n",
    "    'PERIOD',\n",
    "    'YEAR',\n",
    "    'POINT_LON',\n",
    "    'POINT_LAT',\n",
    "    'POINT_BALANCE',\n",
    "    'ALTITUDE_CLIMATE',\n",
    "    'ELEVATION_DIFFERENCE',\n",
    "    'POINT_ELEVATION',\n",
    "    'RGIId',\n",
    "    'POINT_ID',\n",
    "    'ID',\n",
    "    'N_MONTHS',\n",
    "    'MONTHS',\n",
    "])\n",
    "# rename voi climate to long name\n",
    "df.rename(columns=vois_climate_long_name,\n",
    "          inplace=True)\n",
    "\n",
    "corr = df.corr()\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "# plot\n",
    "sns.heatmap(corr,\n",
    "            mask=mask,\n",
    "            cmap='coolwarm',\n",
    "            vmax=1,\n",
    "            vmin=-1,\n",
    "            center=0,\n",
    "            square=True,\n",
    "            linewidths=.5,\n",
    "            cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check of variables:\n",
    "df = dataloader_gl.data\n",
    "var_to_plot = ['POINT_BALANCE'] + vois_climate + ['pcsr']\n",
    "df = df[(df.GLACIER == 'corvatsch') & (df.YEAR == 2015)].groupby(\n",
    "    ['MONTHS'])[var_to_plot].mean().reset_index()\n",
    "df['month_nb'] = df.MONTHS.apply(\n",
    "    lambda x: list(month_abbr).index(x.capitalize()))\n",
    "df.sort_values(by='month_nb', inplace=True)\n",
    "fig, ax = plt.subplots(3, 4, figsize=(10, 8))\n",
    "\n",
    "for i, var in enumerate(var_to_plot):\n",
    "    df.plot(x='MONTHS', y=var, marker='o', ax=ax.flatten()[i], legend=False)\n",
    "    if var in vois_climate_long_name.keys():\n",
    "        ax.flatten()[i].set_title(vois_climate_long_name[var], fontsize=12)\n",
    "    else:\n",
    "        ax.flatten()[i].set_title(var, fontsize=12)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the topo variables:\n",
    "df = dataloader_gl.data\n",
    "fig, axs = plt.subplots(3, 3, figsize=(10, 6))\n",
    "for i, var in enumerate(vois_topographical):\n",
    "    ax = axs.flatten()[i]\n",
    "    sns.histplot(df[var], ax=ax, kde=True)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_title(var)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking on glaciers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_glaciers = [\n",
    "#     'tortin', 'plattalva', 'sanktanna', 'schwarzberg', 'hohlaub', 'rhone'\n",
    "# ]\n",
    "test_glaciers = [\n",
    "    'tortin', 'plattalva', 'sanktanna', 'schwarzberg', 'hohlaub', 'pizol',\n",
    "    'joeri', 'corvatsch', 'tsanfleuron'\n",
    "]\n",
    "train_glaciers = [\n",
    "    i for i in data_glamos.GLACIER.unique() if i not in test_glaciers\n",
    "]\n",
    "\n",
    "data_test = data_glamos[data_glamos.GLACIER.isin(test_glaciers)]\n",
    "print('Size of test data:', len(data_test))\n",
    "data_train = data_glamos[data_glamos.GLACIER.isin(train_glaciers)]\n",
    "print('Size of train data:', len(data_train))\n",
    "\n",
    "test_perc = (len(data_test) / len(data_train)) * 100\n",
    "print('Percentage of test size: {:.2f}%'.format(test_perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of annual versus winter measurements:\n",
    "print('Train:')\n",
    "print('Number of winter and annual samples:', len(data_train))\n",
    "print('Number of annual samples:',\n",
    "      len(data_train[data_train.PERIOD == 'annual']))\n",
    "print('Number of winter samples:',\n",
    "      len(data_train[data_train.PERIOD == 'winter']))\n",
    "\n",
    "# Same for test\n",
    "print('Test:')\n",
    "print('Number of winter and annual samples:', len(data_test))\n",
    "print('Number of annual samples:',\n",
    "      len(data_test[data_test.PERIOD == 'annual']))\n",
    "print('Number of winter samples:',\n",
    "      len(data_test[data_test.PERIOD == 'winter']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap annual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHeatmap(test_glaciers, data_glamos, glDirect, period='annual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap winter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHeatmap(test_glaciers, data_glamos, glDirect, period='winter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits, test_set, train_set = getCVSplits(dataloader_gl,\n",
    "                                          test_split_on='GLACIER',\n",
    "                                          test_splits=test_glaciers)\n",
    "\n",
    "print('Test glaciers: ({}) {}'.format(len(test_set['splits_vals']),\n",
    "                                      test_set['splits_vals']))\n",
    "test_perc = (len(test_set['df_X']) / len(train_set['df_X'])) * 100\n",
    "print('Percentage of test size: {:.2f}%'.format(test_perc))\n",
    "print('Size of test set:', len(test_set['df_X']))\n",
    "print('Train glaciers: ({}) {}'.format(len(train_set['splits_vals']),\n",
    "                                       train_set['splits_vals']))\n",
    "print('Size of train set:', len(train_set['df_X']))\n",
    "visualiseSplits(test_set['y'], train_set['y'], splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualiseInputs(train_set, test_set, vois_climate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distributions of test glaciers:\n",
    "f, ax = plt.subplots(len(test_glaciers),\n",
    "                     len(vois_climate) + 3,\n",
    "                     figsize=(16, 10),\n",
    "                     sharey='row',\n",
    "                     sharex='col')\n",
    "\n",
    "for i, test_gl in enumerate(test_glaciers):\n",
    "    test_df_gl = test_set['df_X'][test_set['df_X'].GLACIER == test_gl]\n",
    "    test_df_gl['POINT_BALANCE'].plot.hist(ax=ax[i, 0],\n",
    "                                          color=color_xgb,\n",
    "                                          alpha=0.6,\n",
    "                                          density=False)\n",
    "    ax[i, 0].set_title('PMB')\n",
    "    ax[i, 0].set_ylabel(test_gl)\n",
    "    ax[i, 0].set_xlabel('[m w.e.]')\n",
    "    test_df_gl['ELEVATION_DIFFERENCE'].plot.hist(ax=ax[i, 1],\n",
    "                                                 color=color_xgb,\n",
    "                                                 alpha=0.6,\n",
    "                                                 density=False)\n",
    "    ax[i, 1].set_title('ELV_DIFF]')\n",
    "    ax[i, 1].set_xlabel('[m]')\n",
    "\n",
    "    for j, voi_clim in enumerate(vois_climate + ['pcsr']):\n",
    "        ax[i, 2 + j].set_title(voi_clim)\n",
    "        test_df_gl[voi_clim].plot.hist(ax=ax[i, 2 + j],\n",
    "                                       color=color_xgb,\n",
    "                                       alpha=0.6,\n",
    "                                       density=False)\n",
    "        ax[i, 2 + j].set_xlabel(vois_units[voi_clim])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,\n",
    "                     len(test_glaciers),\n",
    "                     figsize=(20, 5),\n",
    "                     sharey='row',\n",
    "                     sharex='row')\n",
    "\n",
    "for i, test_gl in enumerate(test_glaciers):\n",
    "    test_df_gl = test_set['df_X'][test_set['df_X'].GLACIER == test_gl]\n",
    "    test_df_gl.POINT_ELEVATION.plot.hist(color=color_xgb,\n",
    "                                         alpha=0.5,\n",
    "                                         density=False,\n",
    "                                         ax=ax[i])\n",
    "    # add vertical line for altitude climate\n",
    "    alt_climate = test_df_gl.ALTITUDE_CLIMATE.mean()\n",
    "    ax[i].axvline(x=alt_climate,\n",
    "                  color='red',\n",
    "                  linestyle='--',\n",
    "                  label='Altitude climate')\n",
    "    ax[i].set_xlabel('Elevation [m]')\n",
    "    ax[i].legend()\n",
    "    ax[i].set_title(test_gl)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of measurements per year:\n",
    "data_glamos.groupby(['YEAR', 'PERIOD'\n",
    "                     ]).size().unstack().plot(kind='bar',\n",
    "                                              stacked=True,\n",
    "                                              figsize=(20, 5),\n",
    "                                              color=[color_xgb, color_tim])\n",
    "plt.title('Number of measurements per year for all glaciers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of measurements per year:\n",
    "fig, ax = plt.subplots(2, 1, figsize=(15, 10))\n",
    "data_test.groupby(['YEAR', 'PERIOD'\n",
    "                   ]).size().unstack().plot(kind='bar',\n",
    "                                            stacked=True,\n",
    "                                            color=[color_xgb, color_tim],\n",
    "                                            ax=ax[0])\n",
    "ax[0].set_title('Number of measurements per year for test glaciers')\n",
    "\n",
    "# Number of measurements per year:\n",
    "data_train.groupby(['YEAR', 'PERIOD'\n",
    "                    ]).size().unstack().plot(kind='bar',\n",
    "                                             stacked=True,\n",
    "                                             color=[color_xgb, color_tim],\n",
    "                                             ax=ax[1])\n",
    "ax[1].set_title('Number of measurements per year for train glaciers')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search\n",
    "# For each of the XGBoost parameter, define the grid range\n",
    "# param_grid = {\n",
    "#     'max_depth': [\n",
    "#         3,\n",
    "#         4,\n",
    "#         5,\n",
    "#         6,\n",
    "#     ],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'gamma': [0, 1]\n",
    "# }\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5, 6, 7, 8],\n",
    "    'n_estimators':\n",
    "    [50, 100, 200, 300, 400, 500, 600,\n",
    "     700],  # number of trees (too many = overfitting, too few = underfitting)\n",
    "    'learning_rate': [0.01, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "}\n",
    "\n",
    "param_init = {}\n",
    "param_init['device'] = 'cuda:0'\n",
    "param_init['tree_method'] = 'hist'\n",
    "param_init[\"random_state\"] = config.SEED\n",
    "param_init[\"n_jobs\"] = config.NUM_JOBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Feature columns:\n",
    "feature_columns = [\n",
    "    'ELEVATION_DIFFERENCE'\n",
    "] + list(vois_climate) + list(vois_topographical) + ['pcsr']\n",
    "all_columns = feature_columns + config.META_DATA + config.NOT_METADATA_NOT_FEATURES\n",
    "df_X_train_subset = train_set['df_X'][all_columns]\n",
    "print('Shape of training dataset:', df_X_train_subset.shape)\n",
    "print('Shape of testing dataset:', test_set['df_X'][all_columns].shape)\n",
    "print('Running with features:', feature_columns)\n",
    "\n",
    "RUN = True\n",
    "if RUN:\n",
    "    # Create a CustomXGBoostRegressor instance\n",
    "    custom_xgboost = mbm.models.CustomXGBoostRegressor(**param_init)\n",
    "    custom_xgboost.randomsearch(\n",
    "        parameters=param_grid,\n",
    "        n_iter=45,\n",
    "        splits=splits,\n",
    "        features=df_X_train_subset,\n",
    "        targets=train_set['y'],\n",
    "    )\n",
    "\n",
    "    # custom_xgboost.gridsearch(\n",
    "    #     parameters=param_grid,\n",
    "    #     splits=splits,\n",
    "    #     features=df_X_train_subset,\n",
    "    #     targets=train_set['y'],\n",
    "    # )\n",
    "\n",
    "    # save best model\n",
    "    custom_xgboost.save_model(f'xgb_gl_split_pcsr_gs_full.pkl')\n",
    "else:\n",
    "    # read model\n",
    "    custom_xgboost = mbm.models.CustomXGBoostRegressor()\n",
    "    custom_xgboost.load_model(f'xgb_gl_split_pcsr_gs_full.pkl')\n",
    "\n",
    "# Get best parameters and estimator\n",
    "best_params = custom_xgboost.param_search.best_params_\n",
    "best_estimator = custom_xgboost.param_search.best_estimator_\n",
    "print(\"Best parameters:\\n\", best_params)\n",
    "print(\"Best score:\\n\", custom_xgboost.param_search.best_score_)\n",
    "\n",
    "# Make predictions on test:\n",
    "# Set to CPU for predictions:\n",
    "best_estimator_cpu = best_estimator.set_params(device='cpu')\n",
    "\n",
    "# Make predictions on test\n",
    "features_test, metadata_test = best_estimator_cpu._create_features_metadata(\n",
    "    test_set['df_X'][all_columns], config.META_DATA)\n",
    "y_pred = best_estimator_cpu.predict(features_test)\n",
    "print('Shape of the test:', features_test.shape)\n",
    "\n",
    "# Make predictions aggr to meas ID:\n",
    "y_pred_agg = best_estimator_cpu.aggrPredict(metadata_test, config.META_DATA,\n",
    "                                            features_test)\n",
    "\n",
    "# Calculate scores\n",
    "score = best_estimator_cpu.score(test_set['df_X'][all_columns],\n",
    "                                 test_set['y'])  # negative\n",
    "print('Overall score:', np.abs(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiseValPreds(best_estimator, splits, train_set, feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotGridSearchScore(cv_results_=custom_xgboost.param_search.cv_results_)\n",
    "plotGridSearchParams(custom_xgboost.param_search.cv_results_, param_grid)\n",
    "plotGridSearchParams(custom_xgboost.param_search.cv_results_, param_grid, N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIPlot(best_estimator, feature_columns, vois_climate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions of best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test:\n",
    "# Set to CPU for predictions:\n",
    "best_estimator_cpu = best_estimator.set_params(device='cpu')\n",
    "\n",
    "features_test, metadata_test = best_estimator_cpu._create_features_metadata(\n",
    "    test_set['df_X'][all_columns], config.META_DATA)\n",
    "y_pred = best_estimator_cpu.predict(features_test)\n",
    "print('Shape of the test:', features_test.shape)\n",
    "\n",
    "y_pred_agg = best_estimator_cpu.aggrPredict(metadata_test, config.META_DATA,\n",
    "                                            features_test)\n",
    "grouped_ids = getDfAggregatePred(test_set, y_pred_agg, all_columns)\n",
    "PlotPredictions(grouped_ids, y_pred, metadata_test, test_set,\n",
    "                best_estimator_cpu)\n",
    "plt.suptitle(f'XGBoost tested on {test_glaciers}', fontsize=20)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions of custom parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_params = {'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 800}\n",
    "\n",
    "# Feature columns:\n",
    "feature_columns = [\n",
    "    'ELEVATION_DIFFERENCE'\n",
    "] + list(vois_climate) + list(vois_topographical) + ['pcsr']\n",
    "all_columns = feature_columns + config.META_DATA + config.NOT_METADATA_NOT_FEATURES\n",
    "df_X_train_subset = train_set['df_X'][all_columns]\n",
    "print('Shape of training dataset:', df_X_train_subset.shape)\n",
    "print('Shape of testing dataset:', test_set['df_X'][all_columns].shape)\n",
    "print('Running with features:', feature_columns)\n",
    "\n",
    "params = {**param_init, **custom_params}\n",
    "print(params)\n",
    "custom_model = mbm.models.CustomXGBoostRegressor(**params)\n",
    "\n",
    "# Fit on train data:\n",
    "custom_model.fit(train_set['df_X'][all_columns], train_set['y'])\n",
    "custom_model = custom_model.set_params(device='cpu')\n",
    "\n",
    "# Make predictions on test\n",
    "features_test, metadata_test = custom_model._create_features_metadata(\n",
    "    test_set['df_X'][all_columns], config.META_DATA)\n",
    "y_pred = custom_model.predict(features_test)\n",
    "print('Shape of the test:', features_test.shape)\n",
    "\n",
    "# Make predictions aggr to meas ID:\n",
    "y_pred_agg = custom_model.aggrPredict(metadata_test, config.META_DATA,\n",
    "                                      features_test)\n",
    "\n",
    "# Calculate scores\n",
    "score = custom_model.score(test_set['df_X'][all_columns],\n",
    "                           test_set['y'])  # negative\n",
    "print('Overall score:', np.abs(score))\n",
    "\n",
    "grouped_ids = getDfAggregatePred(test_set, y_pred_agg, all_columns)\n",
    "PlotPredictions(grouped_ids, y_pred, metadata_test, test_set, custom_model)\n",
    "plt.suptitle(f'XGBoost tested on {test_glaciers}', fontsize=20)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate predictions to annual or winter:\n",
    "PlotIndividualGlacierPred(grouped_ids, figsize=(15, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIPlot(custom_model, feature_columns, vois_climate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-checks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata = pd.DataFrame(metadata_test, columns=config.META_DATA)\n",
    "df_metadata = df_metadata.assign(y_pred=y_pred)\n",
    "\n",
    "# separate into annual and winter\n",
    "dfpred_annual = df_metadata[df_metadata['PERIOD'] == 'annual']\n",
    "dfpred_winter = df_metadata[df_metadata['PERIOD'] == 'winter']\n",
    "\n",
    "# plot distribution of predictions per month, one plot per month\n",
    "f, ax = plt.subplots(3, 4, figsize=(20, 10), sharex=True)\n",
    "for i, month in enumerate(month_abbr[1:]):\n",
    "    dfpred_annual[dfpred_annual['MONTHS'] == month.lower()].y_pred.plot.hist(\n",
    "        ax=ax.flatten()[i],\n",
    "        color=color_xgb,\n",
    "        alpha=0.6,\n",
    "        density=False,\n",
    "        label='annual')\n",
    "    if month.lower() in dfpred_winter.MONTHS.unique():\n",
    "        dfpred_winter[dfpred_winter['MONTHS'] ==\n",
    "                      month.lower()].y_pred.plot.hist(ax=ax.flatten()[i],\n",
    "                                                      color=color_tim,\n",
    "                                                      alpha=0.6,\n",
    "                                                      density=False,\n",
    "                                                      label='winter')\n",
    "    ax.flatten()[i].set_title(month, fontsize=24)\n",
    "    ax.flatten()[i].set_xlabel('[m w.e.]', fontsize=20)\n",
    "    ax.flatten()[i].legend(fontsize=16)\n",
    "    # add vertical line for 0 balance\n",
    "    ax.flatten()[i].axvline(x=0, color='black', linestyle='--')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D fields:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corvatsch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make glacier wide predictions for one test glacier:\n",
    "glacierName = 'corvatsch'\n",
    "\n",
    "rgi_gl = rgi_df.loc[glacierName]['rgi_id.v6']\n",
    "data_gl = data_glamos[data_glamos.RGIId == rgi_gl]\n",
    "dataset_gl = mbm.Dataset(data=data_gl,\n",
    "                         region_name='CH',\n",
    "                         data_path=path_PMB_GLAMOS_csv)\n",
    "ds, glacier_indices, gdir = dataset_gl.get_glacier_mask(custom_working_dir)\n",
    "\n",
    "# Create pandas dataframe of glacier grid\n",
    "years = data_gl['YEAR'].unique()\n",
    "df_grid_annual = dataset_gl.create_glacier_grid(custom_working_dir)\n",
    "# Add metadata that is not in WGMS dataset\n",
    "df_grid_annual[\"PERIOD\"] = \"annual\"\n",
    "df_grid_annual['GLACIER'] = glacierName\n",
    "\n",
    "# Load monthly glacier grid (preprocessed in other notebooks)\n",
    "df_grid_monthly = pd.read_csv(path_glacier_grid + f'{glacierName}_grid.csv')\n",
    "dataloader = mbm.DataLoader(data=df_grid_monthly,\n",
    "                            meta_data_columns=config.META_DATA)\n",
    "print('\\nNumber of years: {}, from {} to {}'.format(len(years), years[0],\n",
    "                                                    years[-1]))\n",
    "print('\\nNumber of total (yearly) measurements:', len(df_grid_annual))\n",
    "\n",
    "# get years with stake measurements:\n",
    "years_stakes = data_gl['YEAR'].unique()\n",
    "print('Years with stake measurements:', years_stakes)\n",
    "\n",
    "# Plot glacier attributes of oggm:\n",
    "plotGlAttr(ds, cmap=cm.devon)\n",
    "\n",
    "# Plot glacier grid with stakes:\n",
    "plotGlGrid(df_grid_annual, data_gl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Annual and winter predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_ids_annual = GlacierWidePred(custom_model,\n",
    "                                     glacierName,\n",
    "                                     vois_climate,\n",
    "                                     vois_topographical,\n",
    "                                     type_pred='annual')\n",
    "grouped_ids_winter = GlacierWidePred(custom_model,\n",
    "                                     glacierName,\n",
    "                                     vois_climate,\n",
    "                                     vois_topographical,\n",
    "                                     type_pred='winter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum over all points of a glacier to get glacier wide SMB\n",
    "grouped_ids_annual_glw = grouped_ids_annual.groupby('YEAR').mean()\n",
    "\n",
    "# Compare to GLAMOS data:\n",
    "df_glamos = pd.read_csv(path_SMB_GLAMOS_csv + 'fix/' +\n",
    "                        f'{glacierName}_fix.csv')\n",
    "df_glamos = transformDates(df_glamos)\n",
    "\n",
    "# Remove obvious duplicates:\n",
    "df_glamos = df_glamos.drop_duplicates()\n",
    "df_glamos['YEAR'] = df_glamos['date1'].apply(lambda x: pd.to_datetime(x).year)\n",
    "df_glamos['Annual Balance'] = df_glamos['Annual Balance'] / (1000)\n",
    "df_glamos = df_glamos[['YEAR', 'Annual Balance']].set_index('YEAR')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "grouped_ids_annual_glw.plot(y='pred',\n",
    "                            label='Predicted SMB',\n",
    "                            ax=ax,\n",
    "                            color=color_xgb)\n",
    "df_glamos[df_glamos.index > 1960].plot(y='Annual Balance',\n",
    "                                       label='GLAMOS SMB',\n",
    "                                       ax=ax,\n",
    "                                       color=color_tim)\n",
    "\n",
    "ax.set_title(f'{glacierName.title()} SMB')\n",
    "ax.set_ylabel('SMB (m w.e.)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TwoDPlotsAllYears(grouped_ids_annual,\n",
    "                  grouped_ids_winter,\n",
    "                  years_stakes,\n",
    "                  figsize=(10, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "TwoDPlots(glacierName, grouped_ids_annual, grouped_ids_winter,\n",
    "          years_stakes[-1], axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All test glaciers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(test_glaciers), 2, figsize=(10, 25))\n",
    "axes = axes.flatten()\n",
    "for i, glacierName in enumerate(test_glaciers):\n",
    "    rgi_gl = rgi_df.loc[glacierName]['rgi_id.v6']\n",
    "    data_gl = data_glamos[data_glamos.RGIId == rgi_gl]\n",
    "    dataset_gl = mbm.Dataset(data=data_gl,\n",
    "                             region_name='CH',\n",
    "                             data_path=path_PMB_GLAMOS_csv)\n",
    "    ds, glacier_indices, gdir = dataset_gl.get_glacier_mask(custom_working_dir)\n",
    "\n",
    "    # Create pandas dataframe of glacier grid\n",
    "    years = data_gl['YEAR'].unique()\n",
    "    df_grid_annual = dataset_gl.create_glacier_grid(custom_working_dir)\n",
    "    # Add metadata that is not in WGMS dataset\n",
    "    df_grid_annual[\"PERIOD\"] = \"annual\"\n",
    "    df_grid_annual['GLACIER'] = glacierName\n",
    "\n",
    "    # Load monthly glacier grid (preprocessed in other notebooks)\n",
    "    df_grid_monthly = pd.read_csv(path_glacier_grid +\n",
    "                                  f'{glacierName}_grid.csv')\n",
    "    dataloader = mbm.DataLoader(data=df_grid_monthly,\n",
    "                                meta_data_columns=config.META_DATA)\n",
    "    # get years with stake measurements:\n",
    "    years_stakes = data_gl['YEAR'].unique()\n",
    "\n",
    "    grouped_ids_annual = GlacierWidePred(custom_model,\n",
    "                                         glacierName,\n",
    "                                         vois_climate,\n",
    "                                         vois_topographical,\n",
    "                                         type_pred='annual')\n",
    "    grouped_ids_winter = GlacierWidePred(custom_model,\n",
    "                                         glacierName,\n",
    "                                         vois_climate,\n",
    "                                         vois_topographical,\n",
    "                                         type_pred='winter')\n",
    "\n",
    "    axs = axes[i * 2:i * 2 + 2]\n",
    "    TwoDPlots(\n",
    "        glacierName,\n",
    "        grouped_ids_annual,\n",
    "        grouped_ids_winter,\n",
    "        # take middle of array\n",
    "        years_stakes[len(years_stakes) // 2],\n",
    "        axs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
