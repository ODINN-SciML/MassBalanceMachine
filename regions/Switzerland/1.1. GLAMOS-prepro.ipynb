{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing of GLAMOS MB data:\n",
    "\n",
    "Does the pre-processing of the point MB measurements from GLAMOS (winter and summer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Mass Balance data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import massbalancemachine as mbm\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import pyproj\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "from cmcrameri import cm\n",
    "from calendar import monthrange\n",
    "\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "from scripts.plots import *\n",
    "from scripts.config_CH import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)\n",
    "free_up_cuda()\n",
    "\n",
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "\n",
    "cmap = cm.devon\n",
    "\n",
    "# For bars and lines:\n",
    "color_diff_xgb = '#4d4d4d'\n",
    "\n",
    "colors = get_cmap_hex(cm.batlow, 10)\n",
    "color_1 = colors[0]\n",
    "color_2 = '#c51b7d'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform .dat files to .csv:\n",
    "\n",
    "Transform the seasonal and winter PMB .dat files to .csv for simplicity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_pmb_dat_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Assemble measurement periods:\n",
    "### Annual measurements: \n",
    "Process annual measurements and put all stakes into one csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>POINT_ID</th>\n",
       "      <th>GLACIER</th>\n",
       "      <th>FROM_DATE</th>\n",
       "      <th>TO_DATE</th>\n",
       "      <th>POINT_LAT</th>\n",
       "      <th>POINT_LON</th>\n",
       "      <th>POINT_ELEVATION</th>\n",
       "      <th>POINT_BALANCE</th>\n",
       "      <th>PERIOD</th>\n",
       "      <th>...</th>\n",
       "      <th>mb_raw</th>\n",
       "      <th>density</th>\n",
       "      <th>density_quality</th>\n",
       "      <th>measurement_quality</th>\n",
       "      <th>measurement_type</th>\n",
       "      <th>mb_error</th>\n",
       "      <th>reading_error</th>\n",
       "      <th>density_error</th>\n",
       "      <th>error_evaluation_method</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>01</td>\n",
       "      <td>oberaar</td>\n",
       "      <td>20021006</td>\n",
       "      <td>20031011</td>\n",
       "      <td>46.538806</td>\n",
       "      <td>8.233237</td>\n",
       "      <td>2389.812633</td>\n",
       "      <td>-6174</td>\n",
       "      <td>annual</td>\n",
       "      <td>...</td>\n",
       "      <td>-686</td>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>45</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>hm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>02</td>\n",
       "      <td>oberaar</td>\n",
       "      <td>20021006</td>\n",
       "      <td>20031011</td>\n",
       "      <td>46.536611</td>\n",
       "      <td>8.225514</td>\n",
       "      <td>2499.825727</td>\n",
       "      <td>-5310</td>\n",
       "      <td>annual</td>\n",
       "      <td>...</td>\n",
       "      <td>-590</td>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>45</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>hm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR POINT_ID  GLACIER FROM_DATE   TO_DATE  POINT_LAT  POINT_LON  \\\n",
       "0  2003       01  oberaar  20021006  20031011  46.538806   8.233237   \n",
       "1  2003       02  oberaar  20021006  20031011  46.536611   8.225514   \n",
       "\n",
       "   POINT_ELEVATION  POINT_BALANCE  PERIOD  ... mb_raw density  \\\n",
       "0      2389.812633          -6174  annual  ...   -686     900   \n",
       "1      2499.825727          -5310  annual  ...   -590     900   \n",
       "\n",
       "   density_quality  measurement_quality  measurement_type  mb_error  \\\n",
       "0                1                    1                 1       102   \n",
       "1                1                    1                 1        91   \n",
       "\n",
       "   reading_error  density_error  error_evaluation_method  source  \n",
       "0             45             92                        0      hm  \n",
       "1             45             79                        0      hm  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first two rows\n",
    "df_annual_raw = process_annual_stake_data(path_PMB_GLAMOS_csv_a)\n",
    "df_annual_raw.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winter measurements:\n",
    "For each point in annual meas., take winter meas that was taken closest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_winter_stake_data(df_annual_raw, path_PMB_GLAMOS_csv_w,\n",
    "                          path_PMB_GLAMOS_csv_w_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble both periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_raw = assemble_all_stake_data(df_annual_raw,\n",
    "                                     path_PMB_GLAMOS_csv_w_clean,\n",
    "                                     path_PMB_GLAMOS_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Number of measurements per year\n",
    "df_measurements_per_year = df_all_raw.groupby(['YEAR',\n",
    "                                               'PERIOD']).size().unstack()\n",
    "df_measurements_per_year.plot(kind='bar',\n",
    "                              stacked=True,\n",
    "                              figsize=(20, 5),\n",
    "                              color=[color_1, color_2])\n",
    "plt.title('Number of measurements per year for all glaciers')\n",
    "plt.ylabel('Number of Measurements')\n",
    "plt.xlabel('Year')\n",
    "plt.legend(title='Period')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add RGIs Ids:\n",
    "\n",
    "For each PMB measurement, we want to add the RGI ID (v6) of the shapefile it belongs to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_outline_fname = '../../../data/GLAMOS/RGI/nsidc0770_11.rgi60.CentralEurope/11_rgi60_CentralEurope.shp'\n",
    "df_pmb = add_rgi_ids_to_df(df_all_raw, glacier_outline_fname)\n",
    "\n",
    "rgiids6 = df_pmb[['GLACIER', 'RGIId']].drop_duplicates()\n",
    "if check_multiple_rgi_ids(rgiids6):\n",
    "    print(\n",
    "        \"-- Alert: The following glaciers have more than one RGIId. Cleaning up.\"\n",
    "    )\n",
    "    df_pmb_clean = clean_rgi_ids(df_pmb.copy())\n",
    "    df_pmb_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    rgiids6_clean = df_pmb_clean[['GLACIER', 'RGIId']].drop_duplicates()\n",
    "    if check_multiple_rgi_ids(rgiids6_clean):\n",
    "        print(\"-- Error: Some glaciers still have more than one RGIId.\")\n",
    "    else:\n",
    "        print(\"-- All glaciers are correctly associated with a single RGIId.\")\n",
    "else:\n",
    "    print(\"-- All glaciers are correctly associated with a single RGIId.\")\n",
    "    df_pmb_clean = df_pmb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut from 1951:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to start of MS data (1951) or ERA5-Land data (1950):\n",
    "df_pmb_50s = df_pmb_clean[df_pmb_clean.YEAR > 1950].sort_values(\n",
    "    by=['GLACIER', 'YEAR'], ascending=[True, True])\n",
    "\n",
    "# Change from mm w.e. to m w.e.\n",
    "df_pmb_50s['POINT_BALANCE'] = df_pmb_50s['POINT_BALANCE'] / 1000\n",
    "\n",
    "# merge ClaridenL and ClaridenU into one glacier:\n",
    "df_pmb_50s.loc[df_pmb_50s.GLACIER == 'claridenU', 'GLACIER'] = 'clariden'\n",
    "df_pmb_50s.loc[df_pmb_50s.GLACIER == 'claridenL', 'GLACIER'] = 'clariden'\n",
    "\n",
    "print('Number of winter and annual samples:', len(df_pmb_50s))\n",
    "print('Number of annual samples:',\n",
    "      len(df_pmb_50s[df_pmb_50s.PERIOD == 'annual']))\n",
    "print('Number of winter samples:',\n",
    "      len(df_pmb_50s[df_pmb_50s.PERIOD == 'winter']))\n",
    "\n",
    "# Number of measurements per year:\n",
    "fig, axs = plt.subplots(2, 1, figsize=(20, 15))\n",
    "ax = axs.flatten()[0]\n",
    "df_pmb_50s.groupby(['YEAR',\n",
    "                    'PERIOD']).size().unstack().plot(kind='bar',\n",
    "                                                     stacked=True,\n",
    "                                                     color=[color_1, color_2],\n",
    "                                                     ax=ax)\n",
    "ax.set_title('Number of measurements per year for all glaciers')\n",
    "\n",
    "ax = axs.flatten()[1]\n",
    "num_gl = df_pmb_50s.groupby(['GLACIER']).size().sort_values()\n",
    "num_gl.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Number of total measurements per glacier since 1951')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge stakes that are close: \n",
    "Especially with winter probes, a lot of measurements were done at the same place in the raw data and this leads to noise. We merge the stakes that are very close and keep the mean of the measurement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pmb_50s_clean = pd.DataFrame()\n",
    "for gl in tqdm(df_pmb_50s.GLACIER.unique(), desc='Merging stakes'):\n",
    "    print(f'-- {gl.capitalize()}:')\n",
    "    df_gl = df_pmb_50s[df_pmb_50s.GLACIER == gl]\n",
    "    df_gl_cleaned = remove_close_points(df_gl)\n",
    "    df_pmb_50s_clean = pd.concat([df_pmb_50s_clean, df_gl_cleaned])\n",
    "\n",
    "df_pmb_50s_clean.drop(['x', 'y'], axis=1, inplace=True)\n",
    "\n",
    "# Save intermediate output\n",
    "print('Saving intermediate output df_pmb_50s.csv to {path_PMB_GLAMOS_csv}')\n",
    "df_pmb_50s_clean.to_csv(os.path.join(path_PMB_GLAMOS_csv, 'df_pmb_50s.csv'),\n",
    "                        index=False)\n",
    "df_pmb_50s_clean[['GLACIER', 'POINT_ID', 'POINT_LAT', 'POINT_LON',\n",
    "                  'PERIOD']].to_csv(os.path.join(path_PMB_GLAMOS_csv,\n",
    "                                                 'coordinate_50s.csv'),\n",
    "                                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of measurements per year:\n",
    "fig, axs = plt.subplots(2, 1, figsize=(20, 15))\n",
    "ax = axs.flatten()[0]\n",
    "df_pmb_50s_clean.groupby(['YEAR', 'PERIOD'\n",
    "                          ]).size().unstack().plot(kind='bar',\n",
    "                                                   stacked=True,\n",
    "                                                   color=[color_1, color_2],\n",
    "                                                   ax=ax)\n",
    "ax.set_title('Number of measurements per year for all glaciers')\n",
    "\n",
    "ax = axs.flatten()[1]\n",
    "num_gl = df_pmb_50s_clean.groupby(['GLACIER']).size().sort_values()\n",
    "num_gl.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Number of total measurements per glacier since 1951')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_list = list(df_pmb_50s_clean.GLACIER.unique())\n",
    "print('Number of glaciers:', len(glacier_list))\n",
    "glacier_list.sort()\n",
    "glacier_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of measurements per glacier per year:\n",
    "num_gl_yr = df_pmb_50s_clean.groupby(['GLACIER', 'YEAR', 'PERIOD'\n",
    "                                      ]).size().unstack().reset_index()\n",
    "\n",
    "num_gl_annual = df_pmb_50s_clean[df_pmb_50s_clean.PERIOD == 'annual'].groupby(\n",
    "    ['GLACIER']).size().sort_values()\n",
    "\n",
    "# Plot one glacier per column:\n",
    "big_gl = num_gl_annual[num_gl_annual > 250].index.sort_values()\n",
    "num_glaciers = len(big_gl)\n",
    "fig, ax = plt.subplots(num_glaciers, 1, figsize=(15, 5 * num_glaciers))\n",
    "for i, gl in enumerate(big_gl):\n",
    "    num_gl_yr[num_gl_yr.GLACIER == gl].plot(x='YEAR',\n",
    "                                            kind='bar',\n",
    "                                            stacked=True,\n",
    "                                            ax=ax[i],\n",
    "                                            title=gl)\n",
    "    ax[i].set_ylabel('Number of measurements')\n",
    "    ax[i].set_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of winter and annual samples:', len(df_pmb_50s_clean))\n",
    "print('Number of annual samples:',\n",
    "      len(df_pmb_50s_clean[df_pmb_50s_clean.PERIOD == 'annual']))\n",
    "print('Number of winter samples:',\n",
    "      len(df_pmb_50s_clean[df_pmb_50s_clean.PERIOD == 'winter']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add topographical information from OGGM & SGI:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OGGM data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize OGGM glacier directories\n",
    "df_pmb_50s_clean = pd.read_csv(path_PMB_GLAMOS_csv + 'df_pmb_50s.csv')\n",
    "gdirs, rgidf = initialize_oggm_glacier_directories(\n",
    "    working_dir='../../../data/OGGM/',\n",
    "    rgi_region=\"11\",\n",
    "    rgi_version=\"6\",\n",
    "    base_url=\n",
    "    \"https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.1/elev_bands/W5E5_w_data/\",\n",
    "    log_level='WARNING',\n",
    "    task_list=None,\n",
    ")\n",
    "\n",
    "export_oggm_grids(df_pmb_50s_clean, gdirs, output_path=path_OGGM_xrgrids)\n",
    "\n",
    "df_pmb_topo = merge_pmb_with_oggm_data(df_pmb=df_pmb_50s_clean,\n",
    "                                       gdirs=gdirs,\n",
    "                                       rgi_region=\"11\",\n",
    "                                       rgi_version=\"6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGI data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "path_SGI_topo = '../../../data/GLAMOS/topo/SGI2020/'\n",
    "i = 0\n",
    "GlacierName = 'clariden'\n",
    "df_pmb_gl = df_pmb_50s_clean[df_pmb_50s_clean.GLACIER == GlacierName]\n",
    "\n",
    "stake_coordinates = df_pmb_gl[['POINT_LON', 'POINT_LAT']].values\n",
    "# Open SGI grid:\n",
    "ds_sgi = xr.open_dataset(path_SGI_topo + 'xr_masked_grids/' +\n",
    "                         f'{GlacierName}.zarr')\n",
    "\n",
    "# Plot the masked data\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 6))\n",
    "ds_sgi.masked_aspect.plot(ax=axs[0], cmap='twilight_shifted')\n",
    "ds_sgi.masked_slope.plot(ax=axs[1], cmap='cividis')\n",
    "ds_sgi.masked_elev.plot(ax=axs[2], cmap='terrain')\n",
    "ds_sgi.glacier_mask.plot(ax=axs[3], cmap='binary')\n",
    "axs[3].scatter(stake_coordinates[:, 0], stake_coordinates[:, 1], c='r', s=10)\n",
    "axs[0].set_title(\"Aspect\")\n",
    "axs[1].set_title(\"Slope\")\n",
    "axs[2].set_title(\"DEM\")\n",
    "axs[3].set_title(\"Glacier mask\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_masked_grids = os.path.join(path_SGI_topo, 'xr_masked_grids/')\n",
    "\n",
    "# Merge PMB with SGI data\n",
    "df_pmb_sgi = merge_pmb_with_sgi_data(\n",
    "    df_pmb_topo,  # cleaned PMB DataFrame\n",
    "    path_masked_grids,  # path to SGI grids\n",
    "    voi=[\"masked_aspect\", \"masked_slope\", \"masked_elev\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count and display the number of samples\n",
    "print(f\"Total number of winter and annual samples: {len(df_pmb_sgi)}\")\n",
    "\n",
    "# Count occurrences of 'PERIOD' values\n",
    "period_counts = df_pmb_sgi['PERIOD'].value_counts()\n",
    "print(f\"Number of annual samples: {period_counts.get('annual', 0)}\")\n",
    "print(f\"Number of winter samples: {period_counts.get('winter', 0)}\")\n",
    "\n",
    "# Unique years, sorted\n",
    "unique_years = np.sort(df_pmb_sgi.YEAR.unique())\n",
    "print(f\"Unique years: {unique_years}\")\n",
    "\n",
    "# Unique glaciers, sorted\n",
    "glacier_list = sorted(df_pmb_sgi.GLACIER.unique())\n",
    "print(f\"Number of glaciers: {len(glacier_list)}\")\n",
    "print(f\"Glaciers: {glacier_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "glacierName = 'aletsch'\n",
    "# stakes\n",
    "df_stakes = df_pmb_topo.copy()\n",
    "df_stakes = df_stakes[(df_stakes['GLACIER'] == glacierName)]\n",
    "RGIId = df_stakes.RGIId.unique()[0]\n",
    "print(RGIId)\n",
    "# open OGGM xr for glacier\n",
    "# Get oggm data for that RGI grid\n",
    "ds_oggm = xr.open_dataset(f'../../../data/OGGM/xr_grids/{RGIId}.nc')\n",
    "\n",
    "# Define the coordinate transformation\n",
    "transf = pyproj.Transformer.from_proj(\n",
    "    pyproj.CRS.from_user_input(\"EPSG:4326\"),  # Input CRS (WGS84)\n",
    "    pyproj.CRS.from_user_input(ds_oggm.pyproj_srs),  # Output CRS from dataset\n",
    "    always_xy=True)\n",
    "\n",
    "# Transform all coordinates in the group\n",
    "lon, lat = df_stakes[\"POINT_LON\"].values, df_stakes[\"POINT_LAT\"].values\n",
    "x_stake, y_stake = transf.transform(lon, lat)\n",
    "df_stakes['x'] = x_stake\n",
    "df_stakes['y'] = y_stake\n",
    "\n",
    "# plot stakes\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = plt.subplot(121)\n",
    "ds_oggm.glacier_mask.plot(cmap='binary', ax=ax)\n",
    "sns.scatterplot(df_stakes,\n",
    "                x='x',\n",
    "                y='y',\n",
    "                hue='within_glacier_shape',\n",
    "                ax=ax,\n",
    "                palette=['r', 'b'])\n",
    "ax.set_title('Stakes on glacier OGGM')\n",
    "\n",
    "ax = plt.subplot(122)\n",
    "path_SGI_topo = '../../../data/GLAMOS/topo/SGI2020/'\n",
    "sgi_grid = xr.open_dataset(path_SGI_topo +\n",
    "                           f'xr_masked_grids/{glacierName}.zarr')\n",
    "sgi_grid.glacier_mask.plot(cmap='binary', ax=ax)\n",
    "sns.scatterplot(df_stakes,\n",
    "                x='POINT_LON',\n",
    "                y='POINT_LAT',\n",
    "                hue='within_glacier_shape',\n",
    "                ax=ax,\n",
    "                palette=['r', 'b'])\n",
    "ax.set_title('Stakes on glacier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacierName = 'aletsch'\n",
    "df_pmb_gl = df_pmb_sgi[(df_pmb_sgi.GLACIER == glacierName)]\n",
    "\n",
    "# Plot aspect and sgi aspect\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 6))\n",
    "axs[0].scatter(df_pmb_gl.aspect, df_pmb_gl.aspect_sgi)\n",
    "axs[0].set_xlabel('aspect oggm')\n",
    "axs[0].set_ylabel('aspect sgi')\n",
    "axs[0].set_title('Aspect')\n",
    "\n",
    "axs[1].scatter(df_pmb_gl.slope, df_pmb_gl.slope_sgi)\n",
    "axs[1].set_xlabel('slope oggm')\n",
    "axs[1].set_ylabel('slope sgi')\n",
    "axs[1].set_title('Slope')\n",
    "\n",
    "# same for topo\n",
    "axs[2].scatter(df_pmb_gl.topo, df_pmb_gl.topo_sgi)\n",
    "axs[2].set_xlabel('topo oggm')\n",
    "axs[2].set_ylabel('topo sgi')\n",
    "axs[2].set_title('Topo')\n",
    "# add 1:1 line\n",
    "for ax in axs:\n",
    "    ax.plot(ax.get_xlim(), ax.get_xlim(), ls=\"--\", c=\".3\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give new stake IDs:\n",
    "Give new stake IDs with glacier name and then a number according to the elevation. This is because accross glaciers some stakes have the same ID which is not practical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pmb_sgi = rename_stakes_by_elevation(df_pmb_sgi)\n",
    "\n",
    "# Check the condition\n",
    "check_point_ids_contain_glacier(df_pmb_sgi)\n",
    "\n",
    "# Save to CSV\n",
    "fname = 'CH_wgms_dataset_all.csv'\n",
    "df_pmb_sgi.to_csv(os.path.join(path_PMB_GLAMOS_csv, fname),\n",
    "            index=False)\n",
    "log.info(f\"-- Saved pmb & oggm dataset {fname} to: {path_PMB_GLAMOS_csv}\")\n",
    "\n",
    "print('Number of winter and annual samples:', len(df_pmb_sgi))\n",
    "print('Number of annual samples:',\n",
    "      len(df_pmb_sgi[df_pmb_sgi.PERIOD == 'annual']))\n",
    "print('Number of winter samples:',\n",
    "      len(df_pmb_sgi[df_pmb_sgi.PERIOD == 'winter']))\n",
    "\n",
    "# Save to csv:\n",
    "df_pmb_sgi.to_csv(path_PMB_GLAMOS_csv + f'CH_wgms_dataset_all.csv',\n",
    "                   index=False)\n",
    "\n",
    "# Histogram of mass balance\n",
    "df_pmb_sgi['POINT_BALANCE'].hist(bins=20)\n",
    "plt.xlabel('Mass balance [m w.e.]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glacier wide MB:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obs: no fixed dates, but using observed periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all files with pmb (for winter and annual mb):\n",
    "glamosfiles_smb = []\n",
    "for file in os.listdir(path_SMB_GLAMOS_raw):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(path_SMB_GLAMOS_raw,\n",
    "                                   file)) and 'obs' in file:\n",
    "        glamosfiles_smb.append(file)\n",
    "print('Examples of index stake raw files:\\n', glamosfiles_smb[:5])\n",
    "\n",
    "# Transform all files to csv\n",
    "emptyfolder(path_SMB_GLAMOS_csv + 'obs/')\n",
    "for file in glamosfiles_smb:\n",
    "    fileName = re.split('.dat', file)[0]\n",
    "    processDatFileGLWMB(fileName, path_SMB_GLAMOS_raw,\n",
    "                        path_SMB_GLAMOS_csv + 'obs/')\n",
    "\n",
    "# Example:\n",
    "fileName = 'aletsch_obs.csv'\n",
    "aletsch_csv = pd.read_csv(path_SMB_GLAMOS_csv + 'obs/' + fileName,\n",
    "                          sep=',',\n",
    "                          header=0,\n",
    "                          encoding='latin-1')\n",
    "aletsch_csv.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix: with fixed periods (hydrological year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all files with pmb (for winter and annual mb):\n",
    "glamosfiles_smb = []\n",
    "for file in os.listdir(path_SMB_GLAMOS_raw):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(path_SMB_GLAMOS_raw,\n",
    "                                   file)) and 'fix' in file:\n",
    "        glamosfiles_smb.append(file)\n",
    "print('Examples of index stake raw files:\\n', glamosfiles_smb[:5])\n",
    "# Transform all files to csv\n",
    "emptyfolder(path_SMB_GLAMOS_csv + 'fix/')\n",
    "for file in glamosfiles_smb:\n",
    "    fileName = re.split('.dat', file)[0]\n",
    "    processDatFileGLWMB(fileName, path_SMB_GLAMOS_raw,\n",
    "                        path_SMB_GLAMOS_csv + 'fix/')\n",
    "\n",
    "# Example:\n",
    "fileName = 'aletsch_fix.csv'\n",
    "aletsch_csv = pd.read_csv(path_SMB_GLAMOS_csv + 'fix/' + fileName,\n",
    "                          sep=',',\n",
    "                          header=0,\n",
    "                          encoding='latin-1')\n",
    "aletsch_csv.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potential incoming clear sky solar radiation:\n",
    "\n",
    "Pre-process glamos data of Potential incoming clear sky solar radiation (pcsr) used as a topographical variable. One per day grid per glacier for one year only, depends on the glacier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read stakes data over all glaciers:\n",
    "data_glamos = pd.read_csv(path_PMB_GLAMOS_csv + f'CH_wgms_dataset_all.csv')\n",
    "\n",
    "glDirect = np.sort(os.listdir(path_pcsr + 'raw/'))  # Glaciers with data\n",
    "\n",
    "print('Number of glacier with clear sky radiation data:', len(glDirect))\n",
    "print('Glaciers with clear sky radiation data:', glDirect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pcsr_save = path_pcsr + 'csv/'\n",
    "empty = False\n",
    "if empty:\n",
    "    emptyfolder(path_pcsr_save)\n",
    "else:\n",
    "    glProcessed = [\n",
    "        re.search(r\"xr_direct_(.*)\\.nc\", f).group(1)\n",
    "        for f in os.listdir(path_pcsr_save)\n",
    "    ]\n",
    "    glDirect = list(set(glDirect) - set(glProcessed))\n",
    "\n",
    "for glacierName in tqdm(glDirect, desc='glaciers', position=0):\n",
    "    print(glacierName)\n",
    "    grid = os.listdir(path_pcsr + 'raw/' + glacierName)\n",
    "    grid_year = int(re.findall(r'\\d+', grid[0])[0])\n",
    "    daily_grids = os.listdir(path_pcsr + 'raw/' + glacierName + '/' + grid[0])\n",
    "    # Sort by day number from 001 to 365\n",
    "    daily_grids.sort()\n",
    "    grids = []\n",
    "    for fileName in daily_grids:\n",
    "        if 'grid' not in fileName:\n",
    "            continue\n",
    "\n",
    "        # Load daily grid file\n",
    "        file_path = path_pcsr + 'raw/' + glacierName + '/' + grid[\n",
    "            0] + '/' + fileName\n",
    "        metadata, grid_data = load_grid_file(file_path)\n",
    "        grids.append(grid_data)\n",
    "\n",
    "    # Take monthly means:\n",
    "    monthly_grids = []\n",
    "    for i in range(12):\n",
    "        num_days_month = monthrange(grid_year, i + 1)[1]\n",
    "        monthly_grids.append(\n",
    "            np.mean(np.stack(grids[i * num_days_month:(i + 1) *\n",
    "                                   num_days_month],\n",
    "                             axis=0),\n",
    "                    axis=0))\n",
    "\n",
    "    monthly_grids = np.array(monthly_grids)\n",
    "    num_months = monthly_grids.shape[0]\n",
    "\n",
    "    # Convert to xarray (CH coordinates)\n",
    "    data_array = convert_to_xarray(monthly_grids, metadata, num_months)\n",
    "\n",
    "    # Convert to WGS84 (lat/lon) coordinates\n",
    "    data_array_transf = transform_xarray_coords_lv03_to_wgs84(data_array)\n",
    "\n",
    "    # Save xarray\n",
    "    if glacierName == 'findelen':\n",
    "        data_array_transf.to_netcdf(path_pcsr_save +\n",
    "                                    f'xr_direct_{glacierName}.nc')\n",
    "        data_array_transf.to_netcdf(path_pcsr_save + f'xr_direct_adler.nc')\n",
    "    elif glacierName == 'stanna':\n",
    "        data_array_transf.to_netcdf(path_pcsr_save + f'xr_direct_sanktanna.nc')\n",
    "    else:\n",
    "        data_array_transf.to_netcdf(path_pcsr_save +\n",
    "                                    f'xr_direct_{glacierName}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of processed glaciers:\n",
    "print('Number of processed glaciers:', len(os.listdir(path_pcsr_save)))\n",
    "\n",
    "# read an plot one file\n",
    "xr_file = xr.open_dataset(path_pcsr_save + 'xr_direct_clariden.nc')\n",
    "xr_file['grid_data'].plot(x='x', y='y', col='time', col_wrap=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MassBalanceMachine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
