{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing of GLAMOS MB data:\n",
    "\n",
    "Does the pre-processing of the point MB measurements from GLAMOS (winter and summer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Mass Balance data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../')) # Add root of repo to import MBM\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import massbalancemachine as mbm\n",
    "from shapely.geometry import Point\n",
    "import pyproj\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "from cmcrameri import cm\n",
    "\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "from scripts.plots import *\n",
    "from scripts.config_CH import *\n",
    "from scripts.geodata import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)\n",
    "free_up_cuda()\n",
    "\n",
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "\n",
    "cmap = cm.devon\n",
    "\n",
    "# For bars and lines:\n",
    "color_diff_xgb = '#4d4d4d'\n",
    "\n",
    "colors = get_cmap_hex(cm.batlow, 10)\n",
    "color_1 = colors[0]\n",
    "color_2 = '#c51b7d'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform .dat files to .csv:\n",
    "\n",
    "Transform the seasonal and winter PMB .dat files to .csv for simplicity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_pmb_dat_files(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Assemble measurement periods:\n",
    "### Annual measurements: \n",
    "Process annual measurements and put all stakes into one csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first two rows\n",
    "df_annual_raw = process_annual_stake_data(cfg.dataPath + path_PMB_GLAMOS_csv_a)\n",
    "df_annual_raw.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winter measurements:\n",
    "For each point in annual meas., take winter meas that was taken closest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_winter_stake_data(df_annual_raw, cfg.dataPath + path_PMB_GLAMOS_csv_w,\n",
    "                          cfg.dataPath + path_PMB_GLAMOS_csv_w_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble both periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_raw = assemble_all_stake_data(\n",
    "    df_annual_raw, cfg.dataPath + path_PMB_GLAMOS_csv_w_clean,\n",
    "    cfg.dataPath + path_PMB_GLAMOS_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Number of measurements per year\n",
    "df_measurements_per_year = df_all_raw.groupby(['YEAR',\n",
    "                                               'PERIOD']).size().unstack()\n",
    "df_measurements_per_year.plot(kind='bar',\n",
    "                              stacked=True,\n",
    "                              figsize=(20, 5),\n",
    "                              color=[color_1, color_2])\n",
    "plt.title('Number of measurements per year for all glaciers')\n",
    "plt.ylabel('Number of Measurements')\n",
    "plt.xlabel('Year')\n",
    "plt.legend(title='Period')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add RGIs Ids:\n",
    "\n",
    "For each PMB measurement, we want to add the RGI ID (v6) of the shapefile it belongs to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pmb = add_rgi_ids_to_df(df_all_raw, cfg.dataPath + path_rgi_outlines)\n",
    "\n",
    "rgiids6 = df_pmb[['GLACIER', 'RGIId']].drop_duplicates()\n",
    "if check_multiple_rgi_ids(rgiids6):\n",
    "    print(\n",
    "        \"-- Alert: The following glaciers have more than one RGIId. Cleaning up.\"\n",
    "    )\n",
    "    df_pmb_clean = clean_rgi_ids(df_pmb.copy())\n",
    "    df_pmb_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    rgiids6_clean = df_pmb_clean[['GLACIER', 'RGIId']].drop_duplicates()\n",
    "    if check_multiple_rgi_ids(rgiids6_clean):\n",
    "        print(\"-- Error: Some glaciers still have more than one RGIId.\")\n",
    "    else:\n",
    "        print(\"-- All glaciers are correctly associated with a single RGIId.\")\n",
    "else:\n",
    "    print(\"-- All glaciers are correctly associated with a single RGIId.\")\n",
    "    df_pmb_clean = df_pmb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut from 1951:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to start of MS data (1951) or ERA5-Land data (1950):\n",
    "df_pmb_50s = df_pmb_clean[df_pmb_clean.YEAR > 1950].sort_values(\n",
    "    by=['GLACIER', 'YEAR'], ascending=[True, True])\n",
    "\n",
    "# Change from mm w.e. to m w.e.\n",
    "df_pmb_50s['POINT_BALANCE'] = df_pmb_50s['POINT_BALANCE'] / 1000\n",
    "\n",
    "# merge ClaridenL and ClaridenU into one glacier:\n",
    "df_pmb_50s.loc[df_pmb_50s.GLACIER == 'claridenU', 'GLACIER'] = 'clariden'\n",
    "df_pmb_50s.loc[df_pmb_50s.GLACIER == 'claridenL', 'GLACIER'] = 'clariden'\n",
    "\n",
    "print('Number of winter and annual samples:', len(df_pmb_50s))\n",
    "print('Number of annual samples:',\n",
    "      len(df_pmb_50s[df_pmb_50s.PERIOD == 'annual']))\n",
    "print('Number of winter samples:',\n",
    "      len(df_pmb_50s[df_pmb_50s.PERIOD == 'winter']))\n",
    "\n",
    "# Number of measurements per year:\n",
    "fig, axs = plt.subplots(2, 1, figsize=(20, 15))\n",
    "ax = axs.flatten()[0]\n",
    "df_pmb_50s.groupby(['YEAR',\n",
    "                    'PERIOD']).size().unstack().plot(kind='bar',\n",
    "                                                     stacked=True,\n",
    "                                                     color=[color_1, color_2],\n",
    "                                                     ax=ax)\n",
    "ax.set_title('Number of measurements per year for all glaciers')\n",
    "\n",
    "ax = axs.flatten()[1]\n",
    "num_gl = df_pmb_50s.groupby(['GLACIER']).size().sort_values()\n",
    "num_gl.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Number of total measurements per glacier since 1951')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge stakes that are close: \n",
    "Especially with winter probes, a lot of measurements were done at the same place in the raw data and this leads to noise. We merge the stakes that are very close and keep the mean of the measurement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pmb_50s_clean = pd.DataFrame()\n",
    "for gl in tqdm(df_pmb_50s.GLACIER.unique(), desc='Merging stakes'):\n",
    "    print(f'-- {gl.capitalize()}:')\n",
    "    df_gl = df_pmb_50s[df_pmb_50s.GLACIER == gl]\n",
    "    df_gl_cleaned = remove_close_points(df_gl)\n",
    "    df_pmb_50s_clean = pd.concat([df_pmb_50s_clean, df_gl_cleaned])\n",
    "\n",
    "df_pmb_50s_clean.drop(['x', 'y'], axis=1, inplace=True)\n",
    "\n",
    "# Save intermediate output\n",
    "print('Saving intermediate output df_pmb_50s.csv to {path_PMB_GLAMOS_csv}')\n",
    "df_pmb_50s_clean.to_csv(os.path.join(cfg.dataPath, path_PMB_GLAMOS_csv,\n",
    "                                     'df_pmb_50s.csv'),\n",
    "                        index=False)\n",
    "df_pmb_50s_clean[['GLACIER', 'POINT_ID', 'POINT_LAT', 'POINT_LON',\n",
    "                  'PERIOD']].to_csv(os.path.join(cfg.dataPath,\n",
    "                                                 path_PMB_GLAMOS_csv,\n",
    "                                                 'coordinate_50s.csv'),\n",
    "                                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of measurements per year:\n",
    "fig, axs = plt.subplots(2, 1, figsize=(20, 15))\n",
    "ax = axs.flatten()[0]\n",
    "df_pmb_50s_clean.groupby(['YEAR', 'PERIOD'\n",
    "                          ]).size().unstack().plot(kind='bar',\n",
    "                                                   stacked=True,\n",
    "                                                   color=[color_1, color_2],\n",
    "                                                   ax=ax)\n",
    "ax.set_title('Number of measurements per year for all glaciers')\n",
    "\n",
    "ax = axs.flatten()[1]\n",
    "num_gl = df_pmb_50s_clean.groupby(['GLACIER']).size().sort_values()\n",
    "num_gl.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Number of total measurements per glacier since 1951')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_list = list(df_pmb_50s_clean.GLACIER.unique())\n",
    "print('Number of glaciers:', len(glacier_list))\n",
    "glacier_list.sort()\n",
    "glacier_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of measurements per glacier per year:\n",
    "num_gl_yr = df_pmb_50s_clean.groupby(['GLACIER', 'YEAR', 'PERIOD'\n",
    "                                      ]).size().unstack().reset_index()\n",
    "\n",
    "num_gl_annual = df_pmb_50s_clean[df_pmb_50s_clean.PERIOD == 'annual'].groupby(\n",
    "    ['GLACIER']).size().sort_values()\n",
    "\n",
    "# Plot one glacier per column:\n",
    "big_gl = num_gl_annual[num_gl_annual > 250].index.sort_values()\n",
    "num_glaciers = len(big_gl)\n",
    "fig, ax = plt.subplots(num_glaciers, 1, figsize=(15, 5 * num_glaciers))\n",
    "for i, gl in enumerate(big_gl):\n",
    "    num_gl_yr[num_gl_yr.GLACIER == gl].plot(x='YEAR',\n",
    "                                            kind='bar',\n",
    "                                            stacked=True,\n",
    "                                            ax=ax[i],\n",
    "                                            title=gl)\n",
    "    ax[i].set_ylabel('Number of measurements')\n",
    "    ax[i].set_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of winter and annual samples:', len(df_pmb_50s_clean))\n",
    "print('Number of annual samples:',\n",
    "      len(df_pmb_50s_clean[df_pmb_50s_clean.PERIOD == 'annual']))\n",
    "print('Number of winter samples:',\n",
    "      len(df_pmb_50s_clean[df_pmb_50s_clean.PERIOD == 'winter']))\n",
    "# Unique glaciers, sorted\n",
    "glacier_list = sorted(df_pmb_50s_clean.GLACIER.unique())\n",
    "print(f\"Number of glaciers: {len(glacier_list)}\")\n",
    "print(f\"Glaciers: {glacier_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add topographical information from OGGM & SGI:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OGGM data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize OGGM glacier directories\n",
    "df_pmb_50s_clean = pd.read_csv(cfg.dataPath + path_PMB_GLAMOS_csv +\n",
    "                               'df_pmb_50s.csv')\n",
    "gdirs, rgidf = initialize_oggm_glacier_directories(\n",
    "    cfg,\n",
    "    rgi_region=\"11\",\n",
    "    rgi_version=\"6\",\n",
    "    base_url=\n",
    "    \"https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.1/elev_bands/W5E5_w_data/\",\n",
    "    log_level='WARNING',\n",
    "    task_list=None,\n",
    ")\n",
    "unique_rgis = df_pmb_50s_clean['RGIId'].unique()\n",
    "\n",
    "export_oggm_grids(cfg, gdirs)\n",
    "\n",
    "df_pmb_topo = merge_pmb_with_oggm_data(df_pmb=df_pmb_50s_clean,\n",
    "                                       gdirs=gdirs,\n",
    "                                       rgi_region=\"11\",\n",
    "                                       rgi_version=\"6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict to within glacier shape\n",
    "df_pmb_topo = df_pmb_topo[df_pmb_topo['within_glacier_shape']]\n",
    "df_pmb_topo = df_pmb_topo.drop(columns=['within_glacier_shape'])\n",
    "\n",
    "print('Number of winter and annual samples:', len(df_pmb_topo))\n",
    "print('Number of annual samples:',\n",
    "      len(df_pmb_topo[df_pmb_topo.PERIOD == 'annual']))\n",
    "print('Number of winter samples:',\n",
    "      len(df_pmb_topo[df_pmb_topo.PERIOD == 'winter']))\n",
    "# Unique glaciers, sorted\n",
    "glacier_list = sorted(df_pmb_topo.GLACIER.unique())\n",
    "print(f\"Number of glaciers: {len(glacier_list)}\")\n",
    "print(f\"Glaciers: {glacier_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGI data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the masked topographical arrays per glacier:\n",
    "glacier_list = sorted(df_pmb_topo.GLACIER.unique())\n",
    "create_sgi_topo_masks(cfg,\n",
    "                      glacier_list,\n",
    "                      type='glacier_name',\n",
    "                      path_save=os.path.join(cfg.dataPath, path_SGI_topo,\n",
    "                                             'xr_masked_grids/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "i = 0\n",
    "glacier_name = 'clariden'\n",
    "df_pmb_gl = df_pmb_50s_clean[df_pmb_50s_clean.GLACIER == glacier_name]\n",
    "\n",
    "stake_coordinates = df_pmb_gl[['POINT_LON', 'POINT_LAT']].values\n",
    "\n",
    "# Open SGI grid:\n",
    "ds_sgi = xr.open_dataset(cfg.dataPath + path_SGI_topo + 'xr_masked_grids/' +\n",
    "                         f'{glacier_name}.zarr')\n",
    "\n",
    "# Plot the masked data\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 6))\n",
    "ds_sgi.masked_aspect.plot(ax=axs[0], cmap='twilight_shifted')\n",
    "ds_sgi.masked_slope.plot(ax=axs[1], cmap='cividis')\n",
    "ds_sgi.masked_elev.plot(ax=axs[2], cmap='terrain')\n",
    "ds_sgi.glacier_mask.plot(ax=axs[3], cmap='binary')\n",
    "axs[3].scatter(stake_coordinates[:, 0], stake_coordinates[:, 1], c='r', s=10)\n",
    "axs[0].set_title(\"Aspect\")\n",
    "axs[1].set_title(\"Slope\")\n",
    "axs[2].set_title(\"DEM\")\n",
    "axs[3].set_title(\"Glacier mask\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_masked_grids = os.path.join(cfg.dataPath, path_SGI_topo,\n",
    "                                 'xr_masked_grids/')\n",
    "\n",
    "# Merge PMB with SGI data\n",
    "df_pmb_sgi = merge_pmb_with_sgi_data(\n",
    "    df_pmb_topo,  # cleaned PMB DataFrame\n",
    "    path_masked_grids,  # path to SGI grids\n",
    "    voi=[\"masked_aspect\", \"masked_slope\", \"masked_elev\"])\n",
    "\n",
    "# Drop points that have no intersection with SGI mask: (have NaN values)\n",
    "df_pmb_sgi = df_pmb_sgi.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count and display the number of samples\n",
    "print(f\"Total number of winter and annual samples: {len(df_pmb_sgi)}\")\n",
    "\n",
    "# Count occurrences of 'PERIOD' values\n",
    "period_counts = df_pmb_sgi['PERIOD'].value_counts()\n",
    "print(f\"Number of annual samples: {period_counts.get('annual', 0)}\")\n",
    "print(f\"Number of winter samples: {period_counts.get('winter', 0)}\")\n",
    "\n",
    "# Unique years, sorted\n",
    "unique_years = np.sort(df_pmb_sgi.YEAR.unique())\n",
    "print(f\"Unique years: {unique_years}\")\n",
    "\n",
    "# Unique glaciers, sorted\n",
    "glacier_list = sorted(df_pmb_sgi.GLACIER.unique())\n",
    "print(f\"Number of glaciers: {len(glacier_list)}\")\n",
    "print(f\"Glaciers: {glacier_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "glacierName = 'clariden'\n",
    "# stakes\n",
    "df_stakes = df_pmb_topo.copy()\n",
    "df_stakes = df_stakes[(df_stakes['GLACIER'] == glacierName)]\n",
    "RGIId = df_stakes.RGIId.unique()[0]\n",
    "print(RGIId)\n",
    "# open OGGM xr for glacier\n",
    "# Get oggm data for that RGI grid\n",
    "ds_oggm = xr.open_dataset(f'{cfg.dataPath}/OGGM/xr_grids/{RGIId}.zarr')\n",
    "\n",
    "# Define the coordinate transformation\n",
    "transf = pyproj.Transformer.from_proj(\n",
    "    pyproj.CRS.from_user_input(\"EPSG:4326\"),  # Input CRS (WGS84)\n",
    "    pyproj.CRS.from_user_input(ds_oggm.pyproj_srs),  # Output CRS from dataset\n",
    "    always_xy=True)\n",
    "\n",
    "# Transform all coordinates in the group\n",
    "lon, lat = df_stakes[\"POINT_LON\"].values, df_stakes[\"POINT_LAT\"].values\n",
    "x_stake, y_stake = transf.transform(lon, lat)\n",
    "df_stakes['x'] = x_stake\n",
    "df_stakes['y'] = y_stake\n",
    "\n",
    "# plot stakes\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = plt.subplot(121)\n",
    "ds_oggm.glacier_mask.plot(cmap='binary', ax=ax)\n",
    "sns.scatterplot(\n",
    "    df_stakes,\n",
    "    x='x',\n",
    "    y='y',\n",
    "    # hue='within_glacier_shape',\n",
    "    ax=ax,\n",
    "    palette=['r', 'b'])\n",
    "ax.set_title('Stakes on glacier OGGM')\n",
    "\n",
    "ax = plt.subplot(122)\n",
    "path_SGI_topo = f'{cfg.dataPath}/GLAMOS/topo/SGI2020/'\n",
    "sgi_grid = xr.open_dataset(path_SGI_topo +\n",
    "                           f'xr_masked_grids/{glacierName}.zarr')\n",
    "sgi_grid.glacier_mask.plot(cmap='binary', ax=ax)\n",
    "sns.scatterplot(\n",
    "    df_stakes,\n",
    "    x='POINT_LON',\n",
    "    y='POINT_LAT',\n",
    "    # hue='within_glacier_shape',\n",
    "    ax=ax,\n",
    "    palette=['r', 'b'])\n",
    "ax.set_title('Stakes on glacier SGI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of measurements per year:\n",
    "fig, axs = plt.subplots(2, 1, figsize=(20, 15))\n",
    "ax = axs.flatten()[0]\n",
    "df_pmb_sgi.groupby(['YEAR',\n",
    "                    'PERIOD']).size().unstack().plot(kind='bar',\n",
    "                                                     stacked=True,\n",
    "                                                     color=[color_1, color_2],\n",
    "                                                     ax=ax)\n",
    "ax.set_title('Number of measurements per year for all glaciers')\n",
    "\n",
    "ax = axs.flatten()[1]\n",
    "num_gl = df_pmb_sgi.groupby(['GLACIER']).size().sort_values()\n",
    "num_gl.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Number of total measurements per glacier since 1951')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacierName = 'clariden'\n",
    "df_pmb_gl = df_pmb_sgi[(df_pmb_sgi.GLACIER == glacierName)]\n",
    "\n",
    "# Plot aspect and sgi aspect\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 6))\n",
    "axs[0].scatter(df_pmb_gl.aspect, df_pmb_gl.aspect_sgi)\n",
    "axs[0].set_xlabel('aspect oggm')\n",
    "axs[0].set_ylabel('aspect sgi')\n",
    "axs[0].set_title('Aspect')\n",
    "\n",
    "axs[1].scatter(df_pmb_gl.slope, df_pmb_gl.slope_sgi)\n",
    "axs[1].set_xlabel('slope oggm')\n",
    "axs[1].set_ylabel('slope sgi')\n",
    "axs[1].set_title('Slope')\n",
    "\n",
    "# same for topo\n",
    "axs[2].scatter(df_pmb_gl.topo, df_pmb_gl.topo_sgi)\n",
    "axs[2].set_xlabel('topo oggm')\n",
    "axs[2].set_ylabel('topo sgi')\n",
    "axs[2].set_title('Topo')\n",
    "# add 1:1 line\n",
    "for ax in axs:\n",
    "    ax.plot(ax.get_xlim(), ax.get_xlim(), ls=\"--\", c=\".3\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give new stake IDs:\n",
    "Give new stake IDs with glacier name and then a number according to the elevation. This is because accross glaciers some stakes have the same ID which is not practical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop taelliboden (only one measurement)\n",
    "df_pmb_sgi = df_pmb_sgi[df_pmb_sgi.GLACIER != 'taelliboden']\n",
    "\n",
    "df_pmb_sgi = rename_stakes_by_elevation(df_pmb_sgi)\n",
    "\n",
    "# Check the condition\n",
    "check_point_ids_contain_glacier(df_pmb_sgi)\n",
    "\n",
    "# Save to CSV\n",
    "fname = 'CH_wgms_dataset_all.csv'\n",
    "df_pmb_sgi.to_csv(os.path.join(cfg.dataPath, path_PMB_GLAMOS_csv, fname),\n",
    "                  index=False)\n",
    "log.info(f\"-- Saved pmb & oggm dataset {fname} to: {path_PMB_GLAMOS_csv}\")\n",
    "\n",
    "print('Number of winter and annual samples:', len(df_pmb_sgi))\n",
    "print('Number of annual samples:',\n",
    "      len(df_pmb_sgi[df_pmb_sgi.PERIOD == 'annual']))\n",
    "print('Number of winter samples:',\n",
    "      len(df_pmb_sgi[df_pmb_sgi.PERIOD == 'winter']))\n",
    "\n",
    "# Save to csv:\n",
    "df_pmb_sgi.to_csv(cfg.dataPath + path_PMB_GLAMOS_csv +\n",
    "                  f'CH_wgms_dataset_all.csv',\n",
    "                  index=False)\n",
    "\n",
    "# Histogram of mass balance\n",
    "df_pmb_sgi['POINT_BALANCE'].hist(bins=20)\n",
    "plt.xlabel('Mass balance [m w.e.]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glacier wide MB:\n",
    "Pre-processing of glacier wide SMB data from GLAMOS. Transform .dat files to .csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_SMB_GLAMOS(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obs: no fixed dates, but using observed periods.\n",
    "# Example:\n",
    "fileName = 'aletsch_obs.csv'\n",
    "aletsch_csv = pd.read_csv(cfg.dataPath + path_SMB_GLAMOS_csv + 'obs/' +\n",
    "                          fileName,\n",
    "                          sep=',',\n",
    "                          header=0,\n",
    "                          encoding='latin-1')\n",
    "aletsch_csv.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix: with fixed periods (hydrological year).\n",
    "# # Example:\n",
    "fileName = 'aletsch_fix.csv'\n",
    "aletsch_csv = pd.read_csv(cfg.dataPath + path_SMB_GLAMOS_csv + 'fix/' +\n",
    "                          fileName,\n",
    "                          sep=',',\n",
    "                          header=0,\n",
    "                          encoding='latin-1')\n",
    "aletsch_csv.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potential incoming clear sky solar radiation:\n",
    "\n",
    "Pre-process glamos data of \"potential incoming clear sky solar radiation (pcsr)\" used as a topographical variable. One per day grid per glacier for one year only, depends on the glacier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN = False\n",
    "if RUN:\n",
    "    glDirect = np.sort(os.listdir(cfg.dataPath + path_pcsr +\n",
    "                                  'raw/'))  # Glaciers with data\n",
    "\n",
    "    print('Number of glacier with clear sky radiation data:', len(glDirect))\n",
    "    print('Glaciers with clear sky radiation data:', glDirect)\n",
    "\n",
    "    process_pcsr(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read an plot one file\n",
    "xr_file = xr.open_dataset(cfg.dataPath + path_pcsr + 'zarr/' +\n",
    "                          'xr_direct_clariden.zarr')\n",
    "xr_file['grid_data'].plot(x='x', y='y', col='time', col_wrap=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MassBalanceMachine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
