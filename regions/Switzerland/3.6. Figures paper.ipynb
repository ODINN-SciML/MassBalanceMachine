{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "from calendar import month_abbr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from cmcrameri import cm\n",
    "import xarray as xr\n",
    "import massbalancemachine as mbm\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "from cartopy import crs as ccrs, feature as cfeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import geopandas as gpd\n",
    "from matplotlib.patches import Wedge, Patch\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "from scripts.plots import *\n",
    "from scripts.config_CH import *\n",
    "from scripts.xgb_helpers import *\n",
    "from scripts.geodata import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)\n",
    "free_up_cuda()\n",
    "\n",
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "colors = get_cmap_hex(cm.batlow, 10)\n",
    "color_dark_blue = colors[0]\n",
    "color_pink = '#c51b7d'\n",
    "\n",
    "# RGI Ids:\n",
    "# Read rgi ids:\n",
    "rgi_df = pd.read_csv(path_glacier_ids, sep=',')\n",
    "rgi_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "rgi_df.sort_values(by='short_name', inplace=True)\n",
    "rgi_df.set_index('short_name', inplace=True)\n",
    "\n",
    "vois_climate = [\n",
    "    't2m', 'tp', 'slhf', 'sshf', 'ssrd', 'fal', 'str', 'u10', 'v10'\n",
    "]\n",
    "\n",
    "vois_topographical = [\n",
    "    # \"aspect\", # OGGM\n",
    "    # \"slope\", # OGGM\n",
    "    \"aspect_sgi\",  # SGI\n",
    "    \"slope_sgi\",  # SGI\n",
    "    \"hugonnet_dhdt\",  # OGGM\n",
    "    \"consensus_ice_thickness\",  # OGGM\n",
    "    \"millan_v\",  # OGGM\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read GL data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_glamos = pd.read_csv(path_PMB_GLAMOS_csv + 'CH_wgms_dataset_all.csv')\n",
    "\n",
    "print('Number of glaciers:', len(data_glamos['GLACIER'].unique()))\n",
    "print('Number of winter and annual samples:', len(data_glamos))\n",
    "print('Number of annual samples:',\n",
    "      len(data_glamos[data_glamos.PERIOD == 'annual']))\n",
    "print('Number of winter samples:',\n",
    "      len(data_glamos[data_glamos.PERIOD == 'winter']))\n",
    "\n",
    "# Capitalize glacier names:\n",
    "glacierCap = {}\n",
    "for gl in data_glamos['GLACIER'].unique():\n",
    "    if isinstance(gl, str):  # Ensure the glacier name is a string\n",
    "        if gl.lower() == 'claridenu':\n",
    "            glacierCap[gl] = 'Clariden_U'\n",
    "        elif gl.lower() == 'claridenl':\n",
    "            glacierCap[gl] = 'Clariden_L'\n",
    "        else:\n",
    "            glacierCap[gl] = gl.capitalize()\n",
    "    else:\n",
    "        print(f\"Warning: Non-string glacier name encountered: {gl}\")\n",
    "\n",
    "data_glamos.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glaciers with pot. radiadation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glaciers with data of potential clear sky radiation\n",
    "# Format to same names as stakes:\n",
    "glDirect = np.sort([\n",
    "    re.search(r'xr_direct_(.*?)\\.zarr', f).group(1)\n",
    "    for f in os.listdir(path_pcsr + 'zarr/')\n",
    "])\n",
    "\n",
    "restgl = np.sort(Diff(list(glDirect), list(data_glamos.GLACIER.unique())))\n",
    "\n",
    "print('Glaciers with potential clear sky radiation data:\\n', glDirect)\n",
    "print('Number of glaciers:', len(glDirect))\n",
    "print('Glaciers without potential clear sky radiation data:\\n', restgl)\n",
    "\n",
    "# Filter out glaciers without data:\n",
    "data_glamos = data_glamos[data_glamos.GLACIER.isin(glDirect)]\n",
    "\n",
    "# Look at the data of the ERA5 dataset:\n",
    "xr.open_dataset(path_ERA5_raw + 'era5_monthly_averaged_data.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glacier outlines:\n",
    "glacier_outline_sgi = gpd.read_file(\n",
    "    os.path.join(path_SGI_topo, 'inventory_sgi2016_r2020',\n",
    "                 'SGI_2016_glaciers_copy.shp'))  # Load the shapefile\n",
    "glacier_outline_rgi = gpd.read_file(path_rgi_outlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of measurements per glacier:\n",
    "glacier_info = data_glamos.groupby('GLACIER').size().sort_values(\n",
    "    ascending=False).reset_index()\n",
    "glacier_info.rename(columns={0: 'Nb. measurements'}, inplace=True)\n",
    "glacier_info.set_index('GLACIER', inplace=True)\n",
    "\n",
    "glacier_loc = data_glamos.groupby('GLACIER')[['POINT_LAT', 'POINT_LON']].mean()\n",
    "\n",
    "glacier_info = glacier_loc.merge(glacier_info, on='GLACIER')\n",
    "\n",
    "glacier_period = data_glamos.groupby(['GLACIER', 'PERIOD']).size().unstack().fillna(0).astype(int)\n",
    "\n",
    "glacier_info = glacier_info.merge(glacier_period, on='GLACIER')\n",
    "\n",
    "test_glaciers = [\n",
    "    'tortin', 'plattalva', 'sanktanna', 'schwarzberg', 'hohlaub', 'pizol',\n",
    "    'corvatsch', 'tsanfleuron', 'forno'\n",
    "]\n",
    "\n",
    "glacier_info['Train/Test glacier'] = glacier_info.apply(\n",
    "    lambda x: 'Test' if x.name in test_glaciers else 'Train', axis=1)\n",
    "glacier_info.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign glaciers to river basin names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load RGI glacier IDs ===\n",
    "rgi_df = pd.read_csv(path_glacier_ids)\n",
    "rgi_df.columns = rgi_df.columns.str.strip()\n",
    "rgi_df = rgi_df.sort_values(by='short_name').set_index('short_name')\n",
    "\n",
    "# === Load SGI region geometries ===\n",
    "SGI_regions = gpd.read_file(os.path.join(\n",
    "    path_SGI_topo, 'inventory_sgi2016_r2020', 'sgi_regions.geojson'))\n",
    "\n",
    "# Clean object columns\n",
    "SGI_regions[SGI_regions.select_dtypes(include='object').columns] = \\\n",
    "    SGI_regions.select_dtypes(include='object').apply(lambda col: col.str.strip())\n",
    "\n",
    "SGI_regions = SGI_regions.drop_duplicates().dropna()\n",
    "SGI_regions = SGI_regions.set_index('pk_sgi_region')\n",
    "\n",
    "# === Map to Level 0 river basins ===\n",
    "catchment_lv0 = {\n",
    "    'A': 'Rhine',\n",
    "    'B': 'Rhone',\n",
    "    'C': 'Po',\n",
    "    'D': 'Adige',\n",
    "    'E': 'Danube'\n",
    "}\n",
    "rgi_df['rvr_lv0'] = rgi_df['sgi-id'].str[0].map(catchment_lv0)\n",
    "\n",
    "# === Map to Level 1 river basins using SGI regions ===\n",
    "def get_river_basin(sgi_id):\n",
    "    key = sgi_id.split('-')[0]\n",
    "    if key not in SGI_regions.index:\n",
    "        return None\n",
    "    basin = SGI_regions.loc[key, 'river_basin_name']\n",
    "    if isinstance(basin, pd.Series):\n",
    "        return basin.dropna().unique()[0] if not basin.dropna().empty else None\n",
    "    return basin if pd.notna(basin) else None\n",
    "\n",
    "rgi_df['rvr_lv1'] = rgi_df['sgi-id'].apply(get_river_basin)\n",
    "\n",
    "# Final formatting\n",
    "rgi_df = rgi_df.reset_index().rename(columns={'short_name': 'GLACIER'}).set_index('GLACIER')\n",
    "rgi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_info = glacier_info.merge(rgi_df[['rvr_lv0', 'rvr_lv1']], on='GLACIER', how='left')\n",
    "glacier_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geoplots:\n",
    "### Per glacier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure object\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Set map domain\n",
    "latN = 48\n",
    "latS = 45.8\n",
    "lonW = 5.8\n",
    "lonE = 10.5\n",
    "projPC = ccrs.PlateCarree()\n",
    "\n",
    "# Create map axes\n",
    "ax2 = plt.axes(projection=projPC)\n",
    "ax2.set_extent([lonW, lonE, latS, latN], crs=ccrs.Geodetic())\n",
    "\n",
    "# Add base features\n",
    "ax2.add_feature(cfeature.COASTLINE)\n",
    "ax2.add_feature(cfeature.LAKES)\n",
    "ax2.add_feature(cfeature.RIVERS)\n",
    "ax2.add_feature(cfeature.BORDERS, linestyle='-', linewidth=1)\n",
    "\n",
    "# ==== SGI REGION COLORING ====\n",
    "sgi_colors = [\n",
    "    '#e7e1ef', '#d4b9da', '#c994c7', '#df65b0', '#e7298a', '#ce1256',\n",
    "    '#980043', '#67001f'\n",
    "]\n",
    "\n",
    "unique_regions = SGI_regions['river_basin_name'].unique()\n",
    "unique_regions.sort()\n",
    "color_map = dict(zip(unique_regions, sgi_colors[:len(unique_regions)]))\n",
    "\n",
    "SGI_regions['color'] = SGI_regions['river_basin_name'].map(color_map)\n",
    "# SGI_regions.plot(ax=ax2,\n",
    "#                  transform=projPC,\n",
    "#                  color=SGI_regions['color'],\n",
    "#                  alpha=0.6)\n",
    "\n",
    "# Glacier outlines\n",
    "glacier_outline_sgi.plot(ax=ax2, transform=projPC, color='black')\n",
    "\n",
    "# Scatterplot: glacier points\n",
    "custom_palette = {'Train': color_dark_blue, 'Test': '#b2182b'}\n",
    "g = sns.scatterplot(data=glacier_info,\n",
    "                    x='POINT_LON',\n",
    "                    y='POINT_LAT',\n",
    "                    size='Nb. measurements',\n",
    "                    hue='Train/Test glacier',\n",
    "                    # hue = 'rvr_lv1',\n",
    "                    sizes=(100, 2000),\n",
    "                    alpha=0.6,\n",
    "                    palette=custom_palette,\n",
    "                    # palette = color_map,\n",
    "                    transform=projPC,\n",
    "                    ax=ax2,\n",
    "                    zorder=10)\n",
    "\n",
    "# Gridlines\n",
    "gl = ax2.gridlines(draw_labels=True,\n",
    "                   linewidth=1,\n",
    "                   color='gray',\n",
    "                   alpha=0.5,\n",
    "                   linestyle='--')\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.xlabel_style = {'size': 16, 'color': 'black'}\n",
    "gl.ylabel_style = {'size': 16, 'color': 'black'}\n",
    "gl.top_labels = gl.right_labels = False\n",
    "\n",
    "# ==== LEGEND SETUP ====\n",
    "\n",
    "# 1. SGI region legend handles\n",
    "sgi_handles = [\n",
    "    Patch(facecolor=color_map[region], label=region)\n",
    "    for region in unique_regions\n",
    "]\n",
    "\n",
    "# 2. Seaborn scatterplot legend handles\n",
    "scatter_handles, scatter_labels = g.get_legend_handles_labels()\n",
    "print(scatter_labels)\n",
    "# 3. Combine and show all legends\n",
    "# all_handles = sgi_handles + scatter_handles\n",
    "all_handles = scatter_handles\n",
    "#all_labels = list(color_map.keys()) + scatter_labels\n",
    "all_labels = scatter_labels\n",
    "\n",
    "ax2.legend(handles=all_handles,\n",
    "           labels=all_labels,\n",
    "           #bbox_to_anchor=(1.05, 1),\n",
    "           loc='upper right',\n",
    "           frameon=True,\n",
    "           fontsize=18,\n",
    "           title='',\n",
    "           title_fontsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sqrt scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.enums import Resampling as RResampling\n",
    "import numpy as np\n",
    "\n",
    "# Open the original raster\n",
    "tif_path = \"landesforstinventar-vegetationshoehenmodell_relief_sentinel_2024_2056.tif\"\n",
    "\n",
    "# Desired output resolution (in degrees)\n",
    "# Approx. 100 m in degrees: ~0.0009 deg\n",
    "target_res = 0.0009\n",
    "output_crs = \"EPSG:4326\"  # WGS84\n",
    "\n",
    "with rasterio.open(tif_path) as src:\n",
    "    # Calculate transform and shape with coarser resolution\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        src.crs, output_crs, src.width, src.height, *src.bounds,\n",
    "        resolution=target_res\n",
    "    )\n",
    "\n",
    "    # Set up destination array and metadata\n",
    "    kwargs = src.meta.copy()\n",
    "    kwargs.update({\n",
    "        'crs': output_crs,\n",
    "        'transform': transform,\n",
    "        'width': width,\n",
    "        'height': height\n",
    "    })\n",
    "\n",
    "    # Prepare empty destination array\n",
    "    destination = np.empty((height, width), dtype=src.dtypes[0])\n",
    "\n",
    "    # Reproject with coarsening\n",
    "    reproject(\n",
    "        source=rasterio.band(src, 1),\n",
    "        destination=destination,\n",
    "        src_transform=src.transform,\n",
    "        src_crs=src.crs,\n",
    "        dst_transform=transform,\n",
    "        dst_crs=output_crs,\n",
    "        resampling=Resampling.average  # average to reduce noise when downsampling\n",
    "    )\n",
    "\n",
    "    extent = [transform[2], transform[2] + transform[0] * width,\n",
    "              transform[5] + transform[4] * height, transform[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# ---- 1. Preprocessing ----\n",
    "# Square-root scaling of number of measurements\n",
    "glacier_info['sqrt_size'] = np.sqrt(glacier_info['Nb. measurements'])\n",
    "\n",
    "# Cache dataset-wide min and max\n",
    "sqrt_min = glacier_info['sqrt_size'].min()\n",
    "sqrt_max = glacier_info['sqrt_size'].max()\n",
    "\n",
    "# Define the desired marker size range in points^2\n",
    "sizes = (30, 1500)  # min and max scatter size\n",
    "\n",
    "# Function to scale individual values consistently\n",
    "def scaled_size(val, min_out=sizes[0], max_out=sizes[1]):\n",
    "    sqrt_val = np.sqrt(val)\n",
    "    if sqrt_max == sqrt_min:\n",
    "        return (min_out + max_out) / 2\n",
    "    return min_out + (max_out - min_out) * ((sqrt_val - sqrt_min) / (sqrt_max - sqrt_min))\n",
    "\n",
    "# Apply scaling to full dataset for the actual plot\n",
    "glacier_info['scaled_size'] = glacier_info['Nb. measurements'].apply(scaled_size)\n",
    "\n",
    "# ---- 2. Create figure and base map ----\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "\n",
    "#latN, latS = 48, 45.8\n",
    "latN, latS = 47.1, 45.8\n",
    "lonW, lonE = 5.8, 10.5\n",
    "projPC = ccrs.PlateCarree()\n",
    "ax2 = plt.axes(projection=projPC)\n",
    "ax2.set_extent([lonW, lonE, latS, latN], crs=ccrs.Geodetic())\n",
    "\n",
    "ax2.add_feature(cfeature.COASTLINE)\n",
    "ax2.add_feature(cfeature.LAKES)\n",
    "ax2.add_feature(cfeature.RIVERS)\n",
    "ax2.add_feature(cfeature.BORDERS, linestyle='-', linewidth=1)\n",
    "\n",
    "# Add the image to the cartopy map\n",
    "ax2.imshow(\n",
    "    destination,\n",
    "    origin='upper',\n",
    "    extent=extent,\n",
    "    transform=ccrs.PlateCarree(),  # Assuming raster is in WGS84\n",
    "    cmap='gray',  # or any other colormap\n",
    "    alpha=0.6,    # transparency\n",
    "    zorder=0\n",
    ")\n",
    "\n",
    "# Glacier outlines\n",
    "glacier_outline_sgi.plot(ax=ax2, transform=projPC, color='black')\n",
    "\n",
    "# ---- 3. Scatterplot ----\n",
    "custom_palette = {'Train': color_dark_blue, 'Test': '#b2182b'}\n",
    "\n",
    "g = sns.scatterplot(\n",
    "    data=glacier_info,\n",
    "    x='POINT_LON',\n",
    "    y='POINT_LAT',\n",
    "    size='scaled_size',\n",
    "    hue='Train/Test glacier',\n",
    "    sizes=sizes,\n",
    "    alpha=0.6,\n",
    "    palette=custom_palette,\n",
    "    transform=projPC,\n",
    "    ax=ax2,\n",
    "    zorder=10,\n",
    "    legend=True  # custom legend added below\n",
    ")\n",
    "\n",
    "# ---- 4. Gridlines ----\n",
    "gl = ax2.gridlines(draw_labels=True,\n",
    "                   linewidth=1,\n",
    "                   color='gray',\n",
    "                   alpha=0.5,\n",
    "                   linestyle='--')\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.xlabel_style = {'size': 16, 'color': 'black'}\n",
    "gl.ylabel_style = {'size': 16, 'color': 'black'}\n",
    "gl.top_labels = gl.right_labels = False\n",
    "\n",
    "# ---- 5. Custom Combined Legend ----\n",
    "\n",
    "# Hue legend handles\n",
    "handles, labels = g.get_legend_handles_labels()\n",
    "expected_labels = list(custom_palette.keys())\n",
    "hue_entries = [(h, l) for h, l in zip(handles, labels) if l in expected_labels]\n",
    "\n",
    "# Size legend values and handles\n",
    "size_values = [30, 100, 1000, 6000]\n",
    "size_handles = [\n",
    "    Line2D([], [], marker='o', linestyle='None',\n",
    "           markersize=np.sqrt(scaled_size(val)),  # matplotlib uses radius\n",
    "           markerfacecolor='gray', alpha=0.6,\n",
    "           label=f'{val}')\n",
    "    for val in size_values\n",
    "]\n",
    "\n",
    "# Separator label\n",
    "separator_handle = Patch(facecolor='none', edgecolor='none', label='Nb. measurements')\n",
    "\n",
    "# Combine all legend entries\n",
    "# combined_handles = [h for h, _ in hue_entries] + [separator_handle] + size_handles\n",
    "# combined_labels = [l for _, l in hue_entries] + ['Nb. measurements'] + [str(v) for v in size_values]\n",
    "\n",
    "# same but without separator\n",
    "combined_handles = [h for h, _ in hue_entries] + size_handles\n",
    "combined_labels = [l for _, l in hue_entries] + [str(v) for v in size_values]\n",
    "\n",
    "# Final legend\n",
    "ax2.legend(combined_handles,\n",
    "           combined_labels,\n",
    "           title='Nb. measurements',\n",
    "           loc='lower right',\n",
    "           frameon=True,\n",
    "           fontsize=14,\n",
    "           title_fontsize=15,\n",
    "           borderpad=1.2,\n",
    "           labelspacing=1.2, \n",
    "           ncol = 3)\n",
    "# ax2.set_title('Glacier measurement locations', fontsize = 25)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Transform data to monthly format (run or load data):\n",
    "paths = {\n",
    "    'csv_path': path_PMB_GLAMOS_csv,\n",
    "    'era5_climate_data': path_ERA5_raw + 'era5_monthly_averaged_data.nc',\n",
    "    'geopotential_data': path_ERA5_raw + 'era5_geopotential_pressure.nc',\n",
    "    'radiation_save_path': path_pcsr + 'zarr/'\n",
    "}\n",
    "RUN = False\n",
    "dataloader_gl = process_or_load_data(run_flag=RUN,\n",
    "                                     data_glamos=data_glamos,\n",
    "                                     paths=paths,\n",
    "                                     cfg=cfg,\n",
    "                                     vois_climate=vois_climate,\n",
    "                                     vois_topographical=vois_topographical)\n",
    "data_monthly = dataloader_gl.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_glaciers = [\n",
    "    'tortin', 'plattalva', 'sanktanna', 'schwarzberg', 'hohlaub', 'pizol',\n",
    "    'corvatsch', 'tsanfleuron', 'forno'\n",
    "]\n",
    "\n",
    "# Ensure all test glaciers exist in the dataset\n",
    "existing_glaciers = set(dataloader_gl.data.GLACIER.unique())\n",
    "missing_glaciers = [g for g in test_glaciers if g not in existing_glaciers]\n",
    "\n",
    "if missing_glaciers:\n",
    "    print(\n",
    "        f\"Warning: The following test glaciers are not in the dataset: {missing_glaciers}\"\n",
    "    )\n",
    "\n",
    "# Define training glaciers correctly\n",
    "train_glaciers = [i for i in existing_glaciers if i not in test_glaciers]\n",
    "\n",
    "data_test = dataloader_gl.data[dataloader_gl.data.GLACIER.isin(test_glaciers)]\n",
    "print('Size of test data:', len(data_test))\n",
    "\n",
    "data_train = dataloader_gl.data[dataloader_gl.data.GLACIER.isin(\n",
    "    train_glaciers)]\n",
    "print('Size of train data:', len(data_train))\n",
    "\n",
    "if len(data_train) == 0:\n",
    "    print(\"Warning: No training data available!\")\n",
    "else:\n",
    "    test_perc = (len(data_test) / len(data_train)) * 100\n",
    "    print('Percentage of test size: {:.2f}%'.format(test_perc))\n",
    "\n",
    "# Number of annual versus winter measurements:\n",
    "print('Train:')\n",
    "print('Number of winter and annual samples:', len(data_train))\n",
    "print('Number of annual samples:',\n",
    "      len(data_train[data_train.PERIOD == 'annual']))\n",
    "print('Number of winter samples:',\n",
    "      len(data_train[data_train.PERIOD == 'winter']))\n",
    "\n",
    "# Same for test\n",
    "data_test_annual = data_test[data_test.PERIOD == 'annual']\n",
    "data_test_winter = data_test[data_test.PERIOD == 'winter']\n",
    "\n",
    "print('Test:')\n",
    "print('Number of winter and annual samples:', len(data_test))\n",
    "print('Number of annual samples:', len(data_test_annual))\n",
    "print('Number of winter samples:', len(data_test_winter))\n",
    "\n",
    "print('Total:')\n",
    "print('Number of monthly rows:', len(dataloader_gl.data))\n",
    "print('Number of annual rows:',\n",
    "      len(dataloader_gl.data[dataloader_gl.data.PERIOD == 'annual']))\n",
    "print('Number of winter rows:',\n",
    "      len(dataloader_gl.data[dataloader_gl.data.PERIOD == 'winter']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap annual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHeatmap(test_glaciers, data_glamos, glacierCap, period='annual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap winter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHeatmap(test_glaciers, data_glamos, glacierCap, period='winter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits, test_set, train_set = get_CV_splits(dataloader_gl,\n",
    "                                            test_split_on='GLACIER',\n",
    "                                            test_splits=test_glaciers,\n",
    "                                            random_state=cfg.seed)\n",
    "\n",
    "print('Test glaciers: ({}) {}'.format(len(test_set['splits_vals']),\n",
    "                                      test_set['splits_vals']))\n",
    "test_perc = (len(test_set['df_X']) / len(train_set['df_X'])) * 100\n",
    "print('Percentage of test size: {:.2f}%'.format(test_perc))\n",
    "print('Size of test set:', len(test_set['df_X']))\n",
    "print('Train glaciers: ({}) {}'.format(len(train_set['splits_vals']),\n",
    "                                       train_set['splits_vals']))\n",
    "print('Size of train set:', len(train_set['df_X']))\n",
    "\n",
    "visualiseSplits(test_set['y'], train_set['y'], splits)\n",
    "visualiseInputs(train_set, test_set, vois_climate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of measurements per year:\n",
    "dataloader_gl.data.groupby(['YEAR', 'PERIOD']).size().unstack().plot(\n",
    "    kind='bar',\n",
    "    stacked=True,\n",
    "    figsize=(20, 5),\n",
    "    color=[color_dark_blue, '#abd9e9'])\n",
    "# plt.title('Number of measurements per year for all glaciers', fontsize = 25)\n",
    "# get legend \n",
    "plt.legend(title='Period', fontsize=18, title_fontsize=20, ncol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search\n",
    "# For each of the XGBoost parameter, define the grid range\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5, 6, 7, 8],\n",
    "    'n_estimators':\n",
    "    [50, 100, 200, 300, 400, 500, 600,\n",
    "     700],  # number of trees (too many = overfitting, too few = underfitting)\n",
    "    'learning_rate': [0.01, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "}\n",
    "\n",
    "param_init = {}\n",
    "param_init['device'] = 'cuda:0'\n",
    "param_init['tree_method'] = 'hist'\n",
    "param_init[\"random_state\"] = cfg.seed\n",
    "param_init[\"n_jobs\"] = cfg.numJobs\n",
    "\n",
    "vois_climate = [\n",
    "    't2m', 'tp', 'slhf', 'sshf', 'ssrd', 'fal', 'str', 'u10', 'v10'\n",
    "]\n",
    "\n",
    "vois_topographical = [\n",
    "    \"aspect_sgi\",\n",
    "    \"slope_sgi\",\n",
    "    \"hugonnet_dhdt\",\n",
    "    \"consensus_ice_thickness\",\n",
    "    \"millan_v\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions of custom parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_params = {'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 800}\n",
    "\n",
    "# Feature columns:\n",
    "feature_columns = [\n",
    "    'ELEVATION_DIFFERENCE'\n",
    "] + list(vois_climate) + list(vois_topographical) + ['pcsr']\n",
    "# feature_columns = ['ELEVATION_DIFFERENCE'\n",
    "#                    ] + list(vois_climate) + list(vois_topographical)\n",
    "all_columns = feature_columns + cfg.fieldsNotFeatures\n",
    "df_X_train_subset = train_set['df_X'][all_columns]\n",
    "print('Shape of training dataset:', df_X_train_subset.shape)\n",
    "print('Shape of testing dataset:', test_set['df_X'][all_columns].shape)\n",
    "print('Running with features:', feature_columns)\n",
    "\n",
    "params = {**param_init, **custom_params}\n",
    "print(params)\n",
    "custom_model = mbm.models.CustomXGBoostRegressor(cfg, **params)\n",
    "\n",
    "# Fit on train data:\n",
    "custom_model.fit(train_set['df_X'][all_columns], train_set['y'])\n",
    "\n",
    "# Make predictions on test\n",
    "custom_model = custom_model.set_params(device='cpu')\n",
    "features_test, metadata_test = custom_model._create_features_metadata(\n",
    "    test_set['df_X'][all_columns])\n",
    "y_pred = custom_model.predict(features_test)\n",
    "print('Shape of the test:', features_test.shape)\n",
    "\n",
    "# Make predictions aggr to meas ID:\n",
    "y_pred_agg = custom_model.aggrPredict(metadata_test, features_test)\n",
    "\n",
    "# Calculate scores\n",
    "score = custom_model.score(test_set['df_X'][all_columns],\n",
    "                           test_set['y'])  # negative\n",
    "print('Overall score:', np.abs(score))\n",
    "\n",
    "grouped_ids = getDfAggregatePred(test_set, y_pred_agg, all_columns)\n",
    "PlotPredictions(grouped_ids, y_pred, metadata_test, test_set, custom_model)\n",
    "plt.suptitle(f'MBM tested on {test_glaciers}', fontsize=20)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate predictions to annual or winter:\n",
    "PlotIndividualGlacierPredVsTruth(grouped_ids, figsize=(20, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIPlot(custom_model, feature_columns, vois_climate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
