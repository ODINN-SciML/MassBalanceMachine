{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glacier grids from RGI:\n",
    "\n",
    "Creates monthly grid files for the MBM to make PMB predictions over the whole glacier grid. The files come from the RGI grid and use OGGM topography. Computing takes a long time because of the conversion to monthly format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../')) # Add root of repo to import MBM\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import massbalancemachine as mbm\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import geopandas as gpd\n",
    "\n",
    "# scripts\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "from scripts.plots import *\n",
    "from scripts.geodata import *\n",
    "from scripts.xgb_helpers import *\n",
    "from scripts.config_CH import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)\n",
    "free_up_cuda()  # in case no memory\n",
    "\n",
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "\n",
    "# Climate columns\n",
    "vois_climate = [\n",
    "    't2m', 'tp', 'slhf', 'sshf', 'ssrd', 'fal', 'str', 'u10', 'v10'\n",
    "]\n",
    "# Topographical columns\n",
    "voi_topographical = [\n",
    "    \"aspect\",\n",
    "    \"slope\",\n",
    "    \"hugonnet_dhdt\",\n",
    "    \"consensus_ice_thickness\",\n",
    "    \"millan_v\",\n",
    "    \"topo\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read PMB data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodetic_mb = get_geodetic_MB(cfg)\n",
    "data_glamos = getStakesData(cfg)\n",
    "\n",
    "# get years per glacier\n",
    "years_start_per_gl = geodetic_mb.groupby(\n",
    "    'glacier_name')['Astart'].unique().apply(list).to_dict()\n",
    "years_end_per_gl = geodetic_mb.groupby('glacier_name')['Aend'].unique().apply(\n",
    "    list).to_dict()\n",
    "\n",
    "periods_per_glacier, geoMB_per_glacier = build_periods_per_glacier(geodetic_mb)\n",
    "\n",
    "# Sort glaciers by area\n",
    "gl_area = get_gl_area(cfg)\n",
    "gl_area['clariden'] = gl_area['claridenL']\n",
    "\n",
    "glacier_outline_rgi = gpd.read_file(cfg.dataPath + path_rgi_outlines)\n",
    "\n",
    "glacier_list = [f for f in list(periods_per_glacier.keys())]\n",
    "\n",
    "# Sort the lists by area if available in gl_area\n",
    "def sort_by_area(glacier_list, gl_area):\n",
    "    return sorted(glacier_list, key=lambda g: gl_area.get(g, 0), reverse=False)\n",
    "\n",
    "\n",
    "glacier_list = sort_by_area(glacier_list, gl_area)\n",
    "# print len and list\n",
    "print('Number of glaciers:', len(glacier_list))\n",
    "print('Glaciers:', glacier_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGI Ids:\n",
    "# Read glacier ids:\n",
    "rgi_df = pd.read_csv(cfg.dataPath+path_glacier_ids, sep=',')\n",
    "rgi_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "rgi_df.sort_values(by='short_name', inplace=True)\n",
    "rgi_df.set_index('short_name', inplace=True)\n",
    "rgi_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdirs, rgidf = initialize_oggm_glacier_directories(\n",
    "    cfg,\n",
    "    rgi_region=\"11\",\n",
    "    rgi_version=\"6\",\n",
    "    base_url=\n",
    "    \"https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.1/elev_bands/W5E5_w_data/\",\n",
    "    log_level='WARNING',\n",
    "    task_list=None,\n",
    ")\n",
    "export_oggm_grids(cfg, gdirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute glacier grids:\n",
    "Add topo, climate variables and convert to monthly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only for years with geodetic MB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "# Set this flag to enable/disable the script execution\n",
    "RUN = True\n",
    "\n",
    "# Manual RGI ID overrides\n",
    "RGI_OVERRIDES = {'morteratsch': 'RGI60-11.01946', 'pers': 'RGI60-11.01946'}\n",
    "\n",
    "if RUN:\n",
    "    try:\n",
    "        emptyfolder(cfg.dataPath+path_glacier_grid_rgi)\n",
    "    except Exception as e:\n",
    "        print(f\"Error clearing folder '{cfg.dataPath+path_glacier_grid_rgi}': {e}\")\n",
    "\n",
    "    for glacier_name in tqdm(glacier_list, desc='Processing glaciers'):\n",
    "        try:\n",
    "            folder_path = os.path.join(cfg.dataPath, path_glacier_grid_rgi, glacier_name)\n",
    "            os.makedirs(folder_path, exist_ok=True)  # Ensure folder exists\n",
    "            print(f'\\n{\"-\" * 35}\\nProcessing: {glacier_name}')\n",
    "\n",
    "            # Retrieve RGI ID with manual overrides if applicable\n",
    "            if glacier_name == 'clariden':\n",
    "                rgi_id_v6 = rgi_df.at['claridenU', 'rgi_id.v6']\n",
    "            else:\n",
    "                rgi_id_v6 = rgi_df.at[glacier_name, 'rgi_id.v6']\n",
    "            rgi_gl = RGI_OVERRIDES.get(glacier_name, rgi_id_v6)\n",
    "\n",
    "            # Load stake data for the glacier\n",
    "            data_gl = data_glamos[data_glamos.RGIId == rgi_gl]\n",
    "            if data_gl.empty:\n",
    "                raise ValueError(\n",
    "                    f\"No stake data found for glacier '{glacier_name}' (RGI ID: {rgi_gl})\"\n",
    "                )\n",
    "\n",
    "            dataset_gl = mbm.data_processing.Dataset(cfg=cfg,\n",
    "                                     data=data_gl,\n",
    "                                     region_name='CH',\n",
    "                                     region_id=11,\n",
    "                                     data_path=cfg.dataPath+path_PMB_GLAMOS_csv)\n",
    "\n",
    "            # Create gridded glacier dataset from OGGM\n",
    "            df_grid = dataset_gl.create_glacier_grid_RGI(cfg.dataPath+path_OGGM)\n",
    "            if df_grid.empty:\n",
    "                raise ValueError(\n",
    "                    f\"Failed to generate gridded dataset for glacier '{glacier_name}'\"\n",
    "                )\n",
    "\n",
    "            df_grid[\"GLACIER\"] = glacier_name\n",
    "            df_grid.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            dataset_grid = mbm.data_processing.Dataset(cfg=cfg,\n",
    "                                       data=df_grid,\n",
    "                                       region_name='CH',\n",
    "                                       region_id=11,\n",
    "                                       data_path=cfg.dataPath+path_PMB_GLAMOS_csv)\n",
    "\n",
    "            # Paths to climate data\n",
    "            era5_climate_data = os.path.join(cfg.dataPath, path_ERA5_raw,\n",
    "                                             'era5_monthly_averaged_data.nc')\n",
    "            geopotential_data = os.path.join(cfg.dataPath, path_ERA5_raw,\n",
    "                                             'era5_geopotential_pressure.nc')\n",
    "\n",
    "            # Add climate data\n",
    "            print('Adding climate data...')\n",
    "            dataset_grid.get_climate_features(\n",
    "                climate_data=era5_climate_data,\n",
    "                geopotential_data=geopotential_data,\n",
    "                change_units=True,\n",
    "                smoothing_vois={\n",
    "                    'vois_climate': vois_climate,\n",
    "                    'vois_other': ['ALTITUDE_CLIMATE']\n",
    "                })\n",
    "\n",
    "            # Add potential clear sky radiation\n",
    "            print('Adding potential clear sky radiation...')\n",
    "            dataset_grid.get_potential_rad(os.path.join(cfg.dataPath, path_pcsr, 'zarr/'))\n",
    "\n",
    "            # Get longest geodetic period for that glacier\n",
    "            # Get the longest period dynamically for the current glacier\n",
    "            if glacier_name in years_start_per_gl and glacier_name in years_end_per_gl:\n",
    "                longest_period = (years_start_per_gl[glacier_name][0],\n",
    "                                  years_end_per_gl[glacier_name][-1])\n",
    "            else:\n",
    "                print(f\"Skipping {glacier_name}: missing start/end years\")\n",
    "                continue\n",
    "\n",
    "            # Process each year separately\n",
    "            for year in range(longest_period[0], longest_period[1] + 1):\n",
    "                try:\n",
    "                    print(\n",
    "                        f'Converting to monthly time resolution for {year}...')\n",
    "                    df_grid_y = dataset_grid.data[dataset_grid.data.YEAR ==\n",
    "                                                  year].copy()\n",
    "                    # Add GLWD_ID\n",
    "                    df_grid_y['GLWD_ID'] = df_grid_y.apply(\n",
    "                        lambda x: mbm.data_processing.utils.get_hash(f\"{x.GLACIER}_{x.YEAR}\"), axis=1)\n",
    "                    df_grid_y['GLWD_ID'] = df_grid_y['GLWD_ID'].astype(str)\n",
    "\n",
    "                    dataset_grid_oggm = mbm.data_processing.Dataset(\n",
    "                        cfg=cfg,\n",
    "                        data=df_grid_y,\n",
    "                        region_name='CH',\n",
    "                        region_id=11,\n",
    "                        data_path=cfg.dataPath+path_PMB_GLAMOS_csv)\n",
    "\n",
    "                    dataset_grid_yearly = mbm.data_processing.Dataset(\n",
    "                        cfg=cfg,\n",
    "                        data=df_grid_y,\n",
    "                        region_name='CH',\n",
    "                        region_id=11,\n",
    "                        data_path=cfg.dataPath+path_PMB_GLAMOS_csv)\n",
    "\n",
    "                    # Convert to monthly time resolution\n",
    "                    dataset_grid_yearly.convert_to_monthly(\n",
    "                        meta_data_columns=cfg.metaData,\n",
    "                        vois_climate=vois_climate + ['pcsr'],\n",
    "                        vois_topographical=voi_topographical,\n",
    "                    )\n",
    "\n",
    "                    # Ensure 'pcsr' column exists before saving\n",
    "                    if 'pcsr' not in dataset_grid_yearly.data.columns:\n",
    "                        raise ValueError(\n",
    "                            f\"'pcsr' column not found in dataset for glacier '{glacier_name}' in year {year}\"\n",
    "                        )\n",
    "\n",
    "                    # Save the dataset for the specific year\n",
    "                    save_path = os.path.join(\n",
    "                        folder_path, f\"{glacier_name}_grid_{year}.parquet\")\n",
    "                    print(f'Saving gridded dataset to: {save_path}')\n",
    "                    dataset_grid_yearly.data.to_parquet(save_path,\n",
    "                                                        engine=\"pyarrow\",\n",
    "                                                        compression=\"snappy\")\n",
    "\n",
    "                except Exception as year_error:\n",
    "                    print(\n",
    "                        f\"⚠️ Error processing glacier '{glacier_name}' for year {year}: {year_error}\"\n",
    "                    )\n",
    "                    traceback.print_exc()\n",
    "                    continue  # Continue with the next year\n",
    "\n",
    "        except Exception as glacier_error:\n",
    "            print(\n",
    "                f\"Error processing glacier '{glacier_name}': {glacier_error}\")\n",
    "            traceback.print_exc()\n",
    "            continue  # Continue processing the next glacier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check grids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_name = 'schwarzbach'\n",
    "rgi_gl = RGI_OVERRIDES.get(glacier_name, rgi_df.at[glacier_name, 'rgi_id.v6'])\n",
    "\n",
    "# Load stake data for that glacier\n",
    "data_gl = data_glamos[data_glamos.RGIId == rgi_gl]\n",
    "dataset_gl = mbm.data_processing.Dataset(cfg=cfg,\n",
    "                         data=data_gl,\n",
    "                         region_name='CH',\n",
    "                         region_id=11,\n",
    "                         data_path=cfg.dataPath+path_PMB_GLAMOS_csv)\n",
    "\n",
    "ds, glacier_indices, gdir = dataset_gl.get_glacier_mask(cfg.dataPath+path_OGGM)\n",
    "# Plot glacier attributes of oggm:\n",
    "plotGlAttr(ds, cmap=cm.devon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
