{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glacier grids from RGI:\n",
    "\n",
    "Creates monthly grid files for the MBM to make PMB predictions over the whole glacier grid. The files come from the RGI grid and use OGGM topography. Computing takes a long time because of the conversion to monthly format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import massbalancemachine as mbm\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from cmcrameri import cm\n",
    "from oggm import utils, workflow\n",
    "from oggm import cfg as oggmCfg\n",
    "import geopandas as gpd\n",
    "import geopandas as gpd\n",
    "import traceback\n",
    "\n",
    "# scripts\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "from scripts.plots import *\n",
    "from scripts.geodata import *\n",
    "from scripts.xgb_helpers import *\n",
    "from scripts.config_CH import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)\n",
    "free_up_cuda()  # in case no memory\n",
    "\n",
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "\n",
    "# Climate columns\n",
    "vois_climate = [\n",
    "    't2m', 'tp', 'slhf', 'sshf', 'ssrd', 'fal', 'str', 'u10', 'v10'\n",
    "]\n",
    "# Topographical columns\n",
    "voi_topographical = [\n",
    "    \"aspect\",\n",
    "    \"slope\",\n",
    "    \"hugonnet_dhdt\",\n",
    "    \"consensus_ice_thickness\",\n",
    "    \"millan_v\",\n",
    "    \"topo\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read PMB data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGI Ids:\n",
    "# Read glacier ids:\n",
    "rgi_df = pd.read_csv(path_glacier_ids, sep=',')\n",
    "rgi_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "rgi_df.sort_values(by='short_name', inplace=True)\n",
    "rgi_df.set_index('short_name', inplace=True)\n",
    "rgi_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PMB data:\n",
    "data_glamos = pd.read_csv(path_PMB_GLAMOS_csv + 'CH_wgms_dataset_all.csv')\n",
    "\n",
    "# Glaciers with data of potential clear sky radiation\n",
    "# Format to same names as stakes:\n",
    "glDirect = np.sort([\n",
    "    re.search(r'xr_direct_(.*?)\\.zarr', f).group(1)\n",
    "    for f in os.listdir(path_pcsr + 'zarr/')\n",
    "])\n",
    "\n",
    "geodetic_mb = get_geodetic_MB()\n",
    "\n",
    "# filter to glaciers with potential clear sky radiation data\n",
    "geodetic_mb = geodetic_mb[geodetic_mb.glacier_name.isin(glDirect)]\n",
    "\n",
    "# get years per glacier\n",
    "years_start_per_gl = geodetic_mb.groupby(\n",
    "    'glacier_name')['Astart'].unique().apply(list).to_dict()\n",
    "years_end_per_gl = geodetic_mb.groupby('glacier_name')['Aend'].unique().apply(\n",
    "    list).to_dict()\n",
    "\n",
    "periods_per_glacier = defaultdict(list)\n",
    "geoMB_per_glacier = defaultdict(list)\n",
    "\n",
    "# Iterate through the DataFrame rows\n",
    "for _, row in geodetic_mb.iterrows():\n",
    "    glacier_name = row['glacier_name']\n",
    "    start_year = row['Astart']\n",
    "    end_year = row['Aend']\n",
    "    geoMB = row['Bgeod']\n",
    "\n",
    "    # Append the (start, end) tuple to the glacier's list\n",
    "    # Only if period is longer than 5 years\n",
    "    if end_year - start_year >= 5:\n",
    "        periods_per_glacier[glacier_name].append((start_year, end_year))\n",
    "        geoMB_per_glacier[glacier_name].append(geoMB)\n",
    "\n",
    "# sort by glacier_list\n",
    "periods_per_glacier = dict(sorted(periods_per_glacier.items()))\n",
    "geoMB_per_glacier = dict(sorted(geoMB_per_glacier.items()))\n",
    "\n",
    "glacier_list = [f for f in list(periods_per_glacier.keys())]\n",
    "\n",
    "# Sort glaciers by area\n",
    "gl_area = get_gl_area()\n",
    "gl_area['clariden'] = gl_area['claridenL']\n",
    "\n",
    "# Sort the lists by area if available in gl_area\n",
    "def sort_by_area(glacier_list, gl_area):\n",
    "    return sorted(glacier_list, key=lambda g: gl_area.get(g, 0), reverse=False)\n",
    "\n",
    "glacier_list = sort_by_area(glacier_list, gl_area)\n",
    "# print len and list\n",
    "print('Number of glaciers:', len(glacier_list))\n",
    "print('Glaciers:', glacier_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which rgis are in the OGGM directory:\n",
    "oggmCfg.initialize(logging_level=\"WARNING\")\n",
    "oggmCfg.PARAMS[\"border\"] = 10\n",
    "oggmCfg.PARAMS[\"use_multiprocessing\"] = True\n",
    "oggmCfg.PARAMS[\"continue_on_error\"] = True\n",
    "custom_working_dir = '../../../data/OGGM/'\n",
    "oggmCfg.PATHS[\"working_dir\"] = custom_working_dir\n",
    "\n",
    "# Intersect dataframe with list of available glaciers in GLAMOS\n",
    "# to reduce computation load in OGGM\n",
    "rgidf = gpd.read_file(utils.get_rgi_region_file(region=\"11\", version=\"6\"))\n",
    "rgidf = rgidf.loc[rgidf['RGIId'].isin(data_glamos.RGIId.unique())]\n",
    "\n",
    "# We use the directories with the shop data in it: \"W5E5_w_data\"\n",
    "base_url = \"https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.1/elev_bands/W5E5_w_data/\"\n",
    "gdirs = workflow.init_glacier_directories(\n",
    "    rgidf,\n",
    "    from_prepro_level=3,\n",
    "    prepro_base_url=base_url,\n",
    "    prepro_border=10,\n",
    "    reset=True,\n",
    "    force=True,\n",
    ")\n",
    "rgis = list(\n",
    "    set(data_glamos.RGIId.unique()) & set(gdir.rgi_id for gdir in gdirs))\n",
    "print('Number of rgis:', len(rgis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute glacier grids:\n",
    "Add topo, climate variables and convert to monthly (takes a long time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only for years with geodetic MB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this flag to enable/disable the script execution\n",
    "RUN = True\n",
    "\n",
    "# Manual RGI ID overrides\n",
    "RGI_OVERRIDES = {'morteratsch': 'RGI60-11.01946', 'pers': 'RGI60-11.01946'}\n",
    "\n",
    "if RUN:\n",
    "    try:\n",
    "        emptyfolder(path_glacier_grid_rgi)\n",
    "    except Exception as e:\n",
    "        print(f\"Error clearing folder '{path_glacier_grid_rgi}': {e}\")\n",
    "\n",
    "    for glacier_name in tqdm(glacier_list, desc='Processing glaciers'):\n",
    "        try:\n",
    "            folder_path = os.path.join(path_glacier_grid_rgi, glacier_name)\n",
    "            os.makedirs(folder_path, exist_ok=True)  # Ensure folder exists\n",
    "            print(f'\\n{\"-\" * 35}\\nProcessing: {glacier_name}')\n",
    "\n",
    "            # Retrieve RGI ID with manual overrides if applicable\n",
    "            if glacier_name=='clariden':\n",
    "                rgi_id_v6 = rgi_df.at['claridenU','rgi_id.v6']\n",
    "            else:\n",
    "                rgi_id_v6 = rgi_df.at[glacier_name,'rgi_id.v6']\n",
    "            rgi_gl = RGI_OVERRIDES.get(glacier_name, rgi_id_v6)\n",
    "\n",
    "            # Load stake data for the glacier\n",
    "            data_gl = data_glamos[data_glamos.RGIId == rgi_gl]\n",
    "            if data_gl.empty:\n",
    "                raise ValueError(\n",
    "                    f\"No stake data found for glacier '{glacier_name}' (RGI ID: {rgi_gl})\"\n",
    "                )\n",
    "\n",
    "            dataset_gl = mbm.Dataset(cfg=cfg,\n",
    "                                     data=data_gl,\n",
    "                                     region_name='CH',\n",
    "                                     data_path=path_PMB_GLAMOS_csv)\n",
    "\n",
    "            # Create gridded glacier dataset from OGGM\n",
    "            df_grid = dataset_gl.create_glacier_grid_RGI(custom_working_dir)\n",
    "            if df_grid.empty:\n",
    "                raise ValueError(\n",
    "                    f\"Failed to generate gridded dataset for glacier '{glacier_name}'\"\n",
    "                )\n",
    "\n",
    "            df_grid[\"GLACIER\"] = glacier_name\n",
    "            df_grid.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            dataset_grid = mbm.Dataset(cfg=cfg,\n",
    "                                       data=df_grid,\n",
    "                                       region_name='CH',\n",
    "                                       data_path=path_PMB_GLAMOS_csv)\n",
    "\n",
    "            # Paths to climate data\n",
    "            era5_climate_data = os.path.join(path_ERA5_raw,\n",
    "                                             'era5_monthly_averaged_data.nc')\n",
    "            geopotential_data = os.path.join(path_ERA5_raw,\n",
    "                                             'era5_geopotential_pressure.nc')\n",
    "            \n",
    "            # Add climate data\n",
    "            print('Adding climate data...')\n",
    "            dataset_grid.get_climate_features(\n",
    "                climate_data=era5_climate_data,\n",
    "                geopotential_data=geopotential_data,\n",
    "                change_units=True)\n",
    "            \n",
    "            # Remove climate artifacts\n",
    "            dataset_grid.remove_climate_artifacts(vois_climate+['ALTITUDE_CLIMATE'])\n",
    "\n",
    "            # Add potential clear sky radiation\n",
    "            print('Adding potential clear sky radiation...')\n",
    "            dataset_grid.get_potential_rad(os.path.join(path_pcsr, 'zarr/'))\n",
    "\n",
    "            \n",
    "            # Get longest geodetic period for that glacier\n",
    "            # Get the longest period dynamically for the current glacier\n",
    "            if glacier_name in years_start_per_gl and glacier_name in years_end_per_gl:\n",
    "                longest_period = (years_start_per_gl[glacier_name][0],\n",
    "                                years_end_per_gl[glacier_name][-1])\n",
    "            else:\n",
    "                print(f\"Skipping {glacier_name}: missing start/end years\")\n",
    "                continue\n",
    "\n",
    "            # Process each year separately\n",
    "            for year in range(longest_period[0], longest_period[1] + 1):\n",
    "                try:\n",
    "                    print(\n",
    "                        f'Converting to monthly time resolution for {year}...')\n",
    "                    df_grid_y = dataset_grid.data[dataset_grid.data.YEAR ==\n",
    "                                                  year].copy()\n",
    "                    # Add GLWD_ID\n",
    "                    df_grid_y['GLWD_ID'] = df_grid_y.apply(\n",
    "                        lambda x: get_hash(f\"{x.GLACIER}_{x.YEAR}\"), axis=1)\n",
    "                    df_grid_y['GLWD_ID'] = df_grid_y['GLWD_ID'].astype(str)\n",
    "\n",
    "                    dataset_grid_oggm = mbm.Dataset(cfg=cfg,\n",
    "                                                    data=df_grid_y,\n",
    "                                                    region_name='CH',\n",
    "                                                    data_path=path_PMB_GLAMOS_csv)\n",
    "                    \n",
    "                    dataset_grid_yearly = mbm.Dataset(\n",
    "                        cfg=cfg,\n",
    "                        data=df_grid_y,\n",
    "                        region_name='CH',\n",
    "                        data_path=path_PMB_GLAMOS_csv)\n",
    "                    \n",
    "                    # Convert to monthly time resolution\n",
    "                    dataset_grid_yearly.convert_to_monthly(\n",
    "                        meta_data_columns=cfg.metaData,\n",
    "                        vois_climate=vois_climate + ['pcsr'],\n",
    "                        vois_topographical=voi_topographical,\n",
    "                    )\n",
    "\n",
    "                    # Ensure 'pcsr' column exists before saving\n",
    "                    if 'pcsr' not in dataset_grid_yearly.data.columns:\n",
    "                        raise ValueError(\n",
    "                            f\"'pcsr' column not found in dataset for glacier '{glacier_name}' in year {year}\"\n",
    "                        )\n",
    "\n",
    "                    # Save the dataset for the specific year\n",
    "                    save_path = os.path.join(\n",
    "                        folder_path, f\"{glacier_name}_grid_{year}.parquet\")\n",
    "                    print(f'Saving gridded dataset to: {save_path}')\n",
    "                    dataset_grid_yearly.data.to_parquet(save_path,\n",
    "                                                        engine=\"pyarrow\",\n",
    "                                                        compression=\"snappy\")\n",
    "\n",
    "                except Exception as year_error:\n",
    "                    print(\n",
    "                        f\"⚠️ Error processing glacier '{glacier_name}' for year {year}: {year_error}\"\n",
    "                    )\n",
    "                    traceback.print_exc()\n",
    "                    continue  # Continue with the next year\n",
    "\n",
    "        except Exception as glacier_error:\n",
    "            print(\n",
    "                f\"Error processing glacier '{glacier_name}': {glacier_error}\")\n",
    "            traceback.print_exc()\n",
    "            continue  # Continue processing the next glacier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check grids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_name = 'rhone'\n",
    "rgi_gl = RGI_OVERRIDES.get(glacier_name, rgi_df.at[glacier_name, 'rgi_id.v6'])\n",
    "\n",
    "# Load stake data for that glacier\n",
    "data_gl = data_glamos[data_glamos.RGIId == rgi_gl]\n",
    "dataset_gl = mbm.Dataset(cfg=cfg,\n",
    "                         data=data_gl,\n",
    "                         region_name='CH',\n",
    "                         data_path=path_PMB_GLAMOS_csv)\n",
    "\n",
    "ds, glacier_indices, gdir = dataset_gl.get_glacier_mask(custom_working_dir)\n",
    "# Plot glacier attributes of oggm:\n",
    "plotGlAttr(ds, cmap=cm.devon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MassBalanceMachine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
