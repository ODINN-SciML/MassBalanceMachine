{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glacier grids from SGI or GLAMOS:\n",
    "\n",
    "Creates monthly grid files for the MBM to make PMB predictions over the whole glacier grid. The files come from the SGI grid and use OGGM topography. Computing takes a long time because of the conversion to monthly format.\n",
    "## Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import massbalancemachine as mbm\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import geopandas as gpd\n",
    "\n",
    "# scripts\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "from scripts.plots import *\n",
    "from scripts.geodata import *\n",
    "from scripts.xgb_helpers import *\n",
    "from scripts.config_CH import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)\n",
    "free_up_cuda()  # in case no memory\n",
    "\n",
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "\n",
    "# Climate columns\n",
    "vois_climate = [\n",
    "    't2m', 'tp', 'slhf', 'sshf', 'ssrd', 'fal', 'str', 'u10', 'v10'\n",
    "]\n",
    "# Topographical columns\n",
    "voi_topographical = [\n",
    "    \"aspect\",\n",
    "    \"slope\",\n",
    "    \"hugonnet_dhdt\",\n",
    "    \"consensus_ice_thickness\",\n",
    "    \"millan_v\",\n",
    "    \"topo\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glaciers_glamos_dem = os.listdir(os.path.join(path_GLAMOS_topo, 'lv95/'))\n",
    "\n",
    "# Glacier outlines:\n",
    "glacier_outline_sgi = gpd.read_file(\n",
    "    os.path.join(path_SGI_topo, 'inventory_sgi2016_r2020',\n",
    "                 'SGI_2016_glaciers_copy.shp'))  # Load the shapefile\n",
    "glacier_outline_rgi = gpd.read_file(path_rgi_outlines)\n",
    "\n",
    "# Sort glaciers by area\n",
    "gl_area = get_gl_area()\n",
    "gl_area['clariden'] = gl_area['claridenL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load RGI data\n",
    "rgi_df = pd.read_csv(path_glacier_ids,\n",
    "                     sep=',').rename(columns=lambda x: x.strip())\n",
    "\n",
    "# Sort and set index for easier lookup\n",
    "rgi_df.sort_values(by='short_name', inplace=True)\n",
    "rgi_df.set_index('short_name', inplace=True)\n",
    "\n",
    "# Load geodetic mass balance data\n",
    "geodeticMB = pd.read_csv(f\"{path_geodetic_MB_glamos}dV_DOI2024_allcomb.csv\")\n",
    "\n",
    "# # Extract relevant RGI IDs for glaciers in glacier_list\n",
    "# rgi_gl = data_glamos.loc[data_glamos.GLACIER.isin(glacier_list),\n",
    "#                          'RGIId'].unique()\n",
    "\n",
    "# # Map RGI IDs to SGI IDs\n",
    "# sgi_gl = rgi_df[rgi_df['rgi_id.v6'].isin(\n",
    "#     rgi_gl)]['sgi-id'].drop_duplicates().values\n",
    "\n",
    "rgi_df.reset_index(inplace=True)\n",
    "sgi_gl = rgi_df.loc[rgi_df.short_name.isin(\n",
    "    glaciers_glamos_dem)]['sgi-id'].unique()\n",
    "\n",
    "# add clariden\n",
    "clariden_L_sgi_id = rgi_df[rgi_df.short_name == 'claridenL']['sgi-id'].unique()\n",
    "\n",
    "# add to sgi_gl\n",
    "sgi_gl = np.concatenate((sgi_gl, clariden_L_sgi_id))\n",
    "\n",
    "# Filter geodeticMB for relevant SGI IDs\n",
    "geodeticMB = geodeticMB[geodeticMB['SGI-ID'].isin(sgi_gl)]\n",
    "\n",
    "# Create a mapping dictionary for glacier names\n",
    "sgi_to_glacier_name = rgi_df[[\n",
    "    'sgi-id', 'short_name'\n",
    "]].drop_duplicates().set_index('sgi-id')['short_name'].to_dict()\n",
    "\n",
    "# Add glacier names based on SGI-ID mapping\n",
    "geodeticMB['glacier_name'] = geodeticMB['SGI-ID'].map(sgi_to_glacier_name)\n",
    "\n",
    "# Standardize naming convention\n",
    "geodeticMB['glacier_name'].replace({'claridenU': 'clariden'}, inplace=True)\n",
    "\n",
    "# filter to glacier_list\n",
    "geodeticMB = geodeticMB[geodeticMB.glacier_name.isin(glaciers_glamos_dem)]\n",
    "\n",
    "# Extract unique start and end years per glacier\n",
    "years_start_per_gl = geodeticMB.groupby(\n",
    "    'glacier_name')['Astart'].unique().apply(list).to_dict()\n",
    "years_end_per_gl = geodeticMB.groupby('glacier_name')['A_end'].unique().apply(\n",
    "    list).to_dict()\n",
    "\n",
    "glacier_list_geod = years_start_per_gl.keys()\n",
    "years_start_per_gl, years_end_per_gl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regional predictions (all CH glaciers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgi_list = [\n",
    "    re.split('_',\n",
    "             re.split('.grid', f)[0])[1]\n",
    "    for f in os.listdir(os.path.join(path_SGI_topo, 'aspect'))\n",
    "]\n",
    "\n",
    "# unique SGI IDs\n",
    "sgi_list = list(set(sgi_list))\n",
    "print('Number of unique SGI IDs:', len(sgi_list))\n",
    "\n",
    "glaciers_glamos_dems = os.listdir(os.path.join(path_GLAMOS_topo, 'lv95'))\n",
    "\n",
    "RUN = False\n",
    "if RUN:\n",
    "    # Create SGI topographical masks\n",
    "    # Note: This function will take a while to run\n",
    "    # It creates a mask for each glacier in the SGI list\n",
    "    # and saves them in the specified directory.\n",
    "    create_sgi_topo_masks(sgi_list,\n",
    "                          type='sgi_id',\n",
    "                          path_save=os.path.join(path_SGI_topo,\n",
    "                                                 'xr_masked_grids_sgi/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2016\n",
    "path_save_monthly = '../../../data/GLAMOS/topo/gridded_topo_inputs/SGI_regional_preds/2016/'\n",
    "\n",
    "RUN = True\n",
    "if RUN:\n",
    "    for sgi_id in tqdm(sgi_list, desc='Processing glaciers'):\n",
    "        print(f\"\\n-----------------------------------\\nProcessing {sgi_id}\")\n",
    "\n",
    "        # Load SGI masked grid (previously resampled)\n",
    "        try:\n",
    "            path_save = os.path.join(path_SGI_topo, 'xr_masked_grids_sgi/')\n",
    "            path = os.path.join(path_save, f\"{sgi_id}.zarr\")\n",
    "            ds_coarsened = xr.open_dataset(path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading dataset for {sgi_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Create glacier grid\n",
    "        try:\n",
    "            rgi_id = None\n",
    "            df_grid = create_glacier_grid_SGI(sgi_id, year, rgi_id,\n",
    "                                              ds_coarsened)\n",
    "            df_grid.reset_index(drop=True, inplace=True)\n",
    "            dataset_grid = mbm.Dataset(cfg=cfg,\n",
    "                                       data=df_grid,\n",
    "                                       region_name='CH',\n",
    "                                       data_path=path_PMB_GLAMOS_csv)\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating glacier grid for {sgi_id} in {year}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Add climate data\n",
    "        try:\n",
    "            era5_climate_data = os.path.join(path_ERA5_raw,\n",
    "                                             'era5_monthly_averaged_data.nc')\n",
    "            geopotential_data = os.path.join(path_ERA5_raw,\n",
    "                                             'era5_geopotential_pressure.nc')\n",
    "            dataset_grid.get_climate_features(\n",
    "                climate_data=era5_climate_data,\n",
    "                geopotential_data=geopotential_data,\n",
    "                change_units=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding climate data for {sgi_id} in {year}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Add OGGM topographic data\n",
    "        try:\n",
    "            df_y_gl = dataset_grid.data\n",
    "            df_y_gl.rename(columns={'RGIId': 'RGIId_old'}, inplace=True)\n",
    "\n",
    "            # Add RGI IDs for OGGM data through intersection with shapefiles\n",
    "            df_y_gl = mbm.data_processing.utils.get_rgi(\n",
    "                data=df_y_gl, glacier_outlines=glacier_outline_rgi)\n",
    "\n",
    "            # Drop points without RGI ID (outside of RGI outlines)\n",
    "            df_y_gl = df_y_gl.dropna(subset=['RGIId'])\n",
    "\n",
    "            # Variables of interest\n",
    "            voi = [\"hugonnet_dhdt\", \"consensus_ice_thickness\", \"millan_v\"]\n",
    "\n",
    "            df_y_gl = add_OGGM_features(df_y_gl, voi, path_OGGM)\n",
    "\n",
    "            # Add GLWD_ID\n",
    "            # print('  - Adding GLWD ID...')\n",
    "            df_y_gl['GLWD_ID'] = df_y_gl.apply(\n",
    "                lambda x: get_hash(f\"{x.GLACIER}_{x.YEAR}\"), axis=1)\n",
    "            df_y_gl['GLWD_ID'] = df_y_gl['GLWD_ID'].astype(str)\n",
    "\n",
    "            dataset_grid = mbm.Dataset(cfg=cfg,\n",
    "                                       data=df_y_gl,\n",
    "                                       region_name='CH',\n",
    "                                       data_path=path_PMB_GLAMOS_csv)\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding OGGM data for {sgi_id} in {year}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Convert to monthly time resolution\n",
    "        # print('  - Converting to monthly time resolution...')\n",
    "        try:\n",
    "            dataset_grid.convert_to_monthly(\n",
    "                meta_data_columns=cfg.metaData,\n",
    "                vois_climate=vois_climate,\n",
    "                vois_topographical=voi_topographical)\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Error converting to monthly resolution for {sgi_id} in {year}: {e}\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # print(\n",
    "        #     f\"  - DF grid shape after conversion: {dataset_grid.data.shape}\"\n",
    "        # )\n",
    "\n",
    "        # Save gridded dataset\n",
    "        save_path = os.path.join(path_save_monthly,\n",
    "                                 f\"{sgi_id}_grid_{year}.parquet\")\n",
    "        try:\n",
    "            dataset_grid.data.to_parquet(save_path,\n",
    "                                         engine=\"pyarrow\",\n",
    "                                         compression=\"snappy\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving dataset for {sgi_id} in {year}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgi_id = 'A50i-16'\n",
    "# Plot all OGGM variables\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "df = pd.read_parquet(\n",
    "    os.path.join(path_save_monthly, f\"{sgi_id}_grid_{year}.parquet\"))\n",
    "df = df[df.MONTHS == 'sep']\n",
    "voi = ['hugonnet_dhdt', 'consensus_ice_thickness', 'millan_v']\n",
    "for i, var in enumerate(voi):\n",
    "    sns.scatterplot(df,\n",
    "                    x='POINT_LON',\n",
    "                    y='POINT_LAT',\n",
    "                    hue=var,\n",
    "                    s=5,\n",
    "                    alpha=0.5,\n",
    "                    palette='twilight_shifted',\n",
    "                    ax=axs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
