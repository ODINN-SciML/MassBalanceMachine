{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa88805730566c5",
   "metadata": {},
   "source": [
    "# MassBalanceMachine Data Processing - Example for Retrieving Training Features for the Norway Region (WGMS)\n",
    "\n",
    "In this notebook, we will demonstrate the data processing workflow of the MassBalanceMachine using an example with glaciological data from Norwegian glaciers. This example will guide you through the data processing pipeline, which retrieves topographical and meteorological features for all points with glaciological surface mass balance observations.\n",
    "\n",
    "We begin by importing some basic libraries along with the ```massbalancemachine``` library. Next, we specify the location where we will store the files for the region of interest (in this case, Norway). The data used in this example is from the [WGMS database](https://wgms.ch/data_databaseversions/), and we will utilize the specified columns.\n",
    "\n",
    "**Note:** It's important to note that WGMS data can contain errors, please check the data for correctness before using it.    \n",
    "\n",
    "**Note:** All data, stake measurements and glaciers outlines, are expected to have the WGS84 CRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f184536",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T15:44:46.294405Z",
     "start_time": "2024-07-12T15:44:46.236846Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import massbalancemachine as mbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77de54d4",
   "metadata": {},
   "source": [
    "## 1. Load your Target Surface Mass Balance Dataset and Retrieve RGI ID per Stake\n",
    "\n",
    "In this step, we define and load our glaciological data from a region of interest. The WGMS dataset does not include RGI IDs by default, so we need to retrieve them from a glacier outline shapefile provided by the Randolph Glacier Inventory (v6). Each stake is then matched with an RGI ID. The RGI ID is necessary for the MassBalanceMachine to add additional topographical and meteorological features for training stage.\n",
    "\n",
    "**How to Retrieve the Glacier Outlines:** Download the shapefiles for the region of interest from this [link](https://daacdata.apps.nsidc.org/pub/DATASETS/nsidc0770_rgi_v6/). Extract the files and copy the .shp, .prj, .shx, and .dbf files in the correct directory so that you can use it with the Jupyter Notebook. Also, make sure you point to the correct directory and files in the next code cell.\n",
    "\n",
    "**Note:** Data records that have an invalid FROM_DATE or TO_DATE, where the day is indicated as 99, are deleted from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b852c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename of the input file with the raw data\n",
    "target_data_fname = './example_data/norway/files/norway_wgms_dataset.csv'\n",
    "# Specify the shape filename of the glaciers outline obtained from RGIv6\n",
    "glacier_outline_fname = './example_data/norway/glacier_outlines/08_rgi60_Scandinavia.shp'\n",
    "\n",
    "# Load the target data and the glacier outlines\n",
    "data = pd.read_csv(target_data_fname)\n",
    "glacier_outline = gpd.read_file(glacier_outline_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8327db51d203f25f",
   "metadata": {},
   "source": [
    "### 1.1 Match the Stake Measurements with a RGI ID\n",
    "\n",
    "Based on the location of the stake measurement given by POINT_LAT and POINT_LON, each data record is matched with the RGI ID for the glacier where the stake is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "173deb09497efa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the RGI ID for each stake measurement for the region of interest\n",
    "data = mbm.utils.get_rgi(data, glacier_outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541a28b3c26caa3",
   "metadata": {},
   "source": [
    "Then, we can create a MassBalanceMachine `Dataset`, by using the loaded dataframe for Norway stake data together with the matched RGI IDs, as such: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe9f70525056f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the column name for the column that has the RGI IDs for each of the stakes\n",
    "dataset = mbm.Dataset(data=data, data_path='./example_data/norway/files/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045122a5",
   "metadata": {},
   "source": [
    "## 2. Get Topographical Features per Stake Measurement\n",
    "\n",
    "Once we have created a `Dataset`, the first thing we can do is to add topographical data in our dataset. This can be done automatically with the MassBalanceMachine (which calls OGGM) by doing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ab47703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 17:57:48: oggm.cfg: Reading default parameters from the OGGM `params.cfg` configuration file.\n",
      "2024-07-12 17:57:48: oggm.cfg: Multiprocessing switched OFF according to the parameter file.\n",
      "2024-07-12 17:57:48: oggm.cfg: Multiprocessing: using all available processors (N=12)\n",
      "2024-07-12 17:57:50: oggm.cfg: PARAMS['border'] changed from `80` to `10`.\n",
      "2024-07-12 17:57:50: oggm.cfg: Multiprocessing switched ON after user settings.\n",
      "2024-07-12 17:57:50: oggm.cfg: PARAMS['continue_on_error'] changed from `False` to `True`.\n",
      "2024-07-12 17:57:51: oggm.workflow: init_glacier_directories from prepro level 3 on 4 glaciers.\n",
      "2024-07-12 17:57:51: oggm.workflow: Execute entity tasks [gdir_from_prepro] on 4 glaciers\n",
      "\u001b[38;2;0;255;0m100%\u001b[39m of 116.4 MiB |######################| Elapsed Time: 0:00:18 Time:  0:00:1801\n",
      "2024-07-12 17:58:11: oggm.workflow: Execute entity tasks [gridded_attributes] on 4 glaciers\n",
      "/mnt/c/Users/Jbies/OneDrive/AES/MSc Thesis/MassBalanceMachine/massbalancemachine/data_processing/get_topo_data.py:73: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  rgi_records = df[rgi_ids == rgi_id]\n",
      "/mnt/c/Users/Jbies/OneDrive/AES/MSc Thesis/MassBalanceMachine/massbalancemachine/data_processing/get_topo_data.py:73: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  rgi_records = df[rgi_ids == rgi_id]\n",
      "/mnt/c/Users/Jbies/OneDrive/AES/MSc Thesis/MassBalanceMachine/massbalancemachine/data_processing/get_topo_data.py:73: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  rgi_records = df[rgi_ids == rgi_id]\n",
      "/mnt/c/Users/Jbies/OneDrive/AES/MSc Thesis/MassBalanceMachine/massbalancemachine/data_processing/get_topo_data.py:73: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  rgi_records = df[rgi_ids == rgi_id]\n"
     ]
    }
   ],
   "source": [
    "# Specify the topographical features of interest \n",
    "# Please see the OGGM documentation what variables are available: https://oggm.org/tutorials/stable/notebooks/10minutes/machine_learning.html ('topo', 'slope_factor', 'dis_from_border')\n",
    "voi_topographical = ['aspect', 'slope']\n",
    "\n",
    "# Retrieve the topographical features for each of the stake measurement and add them to the dataset\n",
    "dataset.get_topo_features(voi_topographical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9430dbbd531b138",
   "metadata": {},
   "source": [
    "## 3. Get Meteorological Features per Stake Measurement\n",
    "\n",
    "Once we have the topographical data, we can add the necessary climate data for the dataset. This is done by pulling that from ERA5-Land database for the region of interest. Before the climate data is matched with the stake measurements, we need to manually download the climate data for the region of interest from [climate Copernicus website](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land-monthly-means?tab=form). Check the following options:\n",
    "\n",
    "- **Product type:** _Monthly averaged reanalysis_\n",
    "- **Variable**:\n",
    "    - _2m temperature_ (t2m)\n",
    "    - _total precipitation_ (tp)\n",
    "    - _surface latent heat flux_ (slhf)  \n",
    "    - _surface sensible heat flux_ (sshf)\n",
    "    - _surface solar radiation downwards_ (ssrd)\n",
    "    - _forecast albedo_ (fal)\n",
    "    - _surface net thermal radiation_ (str)\n",
    "    - You can explore additional options as you prefer. In this example, we use the variables listed above.\n",
    "- **Year**: _Select all_\n",
    "- **Month**: _Select all_\n",
    "- **Time**: _Select all_\n",
    "- **Geographical area**: \n",
    "- **Format:** _NetCDF-3_\n",
    "\n",
    "Then click _Submit Request_ (after you have registered or logged into your account). Please be aware that downloading this data can take up to several hours, depending on the number of variables, timescales, and the area selected. Once the download is complete, place the netCDF file in the correct directory and rename it accordingly.\n",
    "\n",
    "Additionally, we need the _geopotential height_ as an extra variable in our dataset. We will calculate a new variable by determining the difference between the geopotential height and the elevation at the stake measurement. The purpose of this height difference is to encourage the model to use it for downscaling the ERA5Land climate data, rather than relying on the lapse rate. The geopotential is downloaded from [here](https://confluence.ecmwf.int/display/CKB/ERA5-Land%3A+data+documentation#ERA5Land:datadocumentation-parameterlistingParameterlistings), and is already included in this example.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b20c314b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'scipy', 'rasterio']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\nhttps://docs.xarray.dev/en/stable/user-guide/io.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m geopotential_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./example_data/norway/climate/era5_geopotential_pressure.nc\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Match the climate features, from the ERA5Land netCDF file, for each of the stake measurement dataset\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_climate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mera5_climate_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeopotential_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/Jbies/OneDrive/AES/MSc Thesis/MassBalanceMachine/massbalancemachine/data_processing/Dataset.py:83\u001b[0m, in \u001b[0;36mDataset.get_climate_features\u001b[0;34m(self, climate_data, geopotential_data)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03mBy specifying which source of reanalysis to use (e.g. ERA5, W5E5, MeteoSwissâ€¦) it fetches all the climate\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03mdata, for a list of variables of interest, for the specified RGI IDs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    geopotential_data (netCDF4): A netCDF4 file containing the geopotential data\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m output_fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregion_climate_features.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mget_climate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_fname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclimate_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeopotential_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/Jbies/OneDrive/AES/MSc Thesis/MassBalanceMachine/massbalancemachine/data_processing/get_climate_data.py:32\u001b[0m, in \u001b[0;36mget_climate_features\u001b[0;34m(df, output_fname, climate_data, geopotential_data)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEither climate data or geopotential data, or both, do not exist\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Open climate datasets\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclimate_data\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m ds_c, \\\n\u001b[1;32m     33\u001b[0m         xr\u001b[38;5;241m.\u001b[39mopen_dataset(geopotential_data) \u001b[38;5;28;01mas\u001b[39;00m ds_g:\n\u001b[1;32m     35\u001b[0m     ds_climate \u001b[38;5;241m=\u001b[39m ds_c\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m     36\u001b[0m     ds_geopotential \u001b[38;5;241m=\u001b[39m ds_g\u001b[38;5;241m.\u001b[39mload()\n",
      "File \u001b[0;32m~/anaconda3/envs/mbm_env/lib/python3.12/site-packages/xarray/backends/api.py:552\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(backend_kwargs)\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 552\u001b[0m     engine \u001b[38;5;241m=\u001b[39m \u001b[43mplugins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguess_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_array_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    555\u001b[0m     from_array_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/mbm_env/lib/python3.12/site-packages/xarray/backends/plugins.py:197\u001b[0m, in \u001b[0;36mguess_engine\u001b[0;34m(store_spec)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound the following matches with the input file in xarray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms IO \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackends: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompatible_engines\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. But their dependencies may not be installed, see:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.xarray.dev/en/stable/user-guide/io.html \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    195\u001b[0m     )\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n",
      "\u001b[0;31mValueError\u001b[0m: did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'scipy', 'rasterio']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\nhttps://docs.xarray.dev/en/stable/user-guide/io.html"
     ]
    }
   ],
   "source": [
    "# Specify the files of the climate data, that will be matched with the coordinates of the stake data\n",
    "era5_climate_data = './example_data/norway/climate/era5_monthly_averaged_data.nc'\n",
    "geopotential_data = './example_data/norway/climate/era5_geopotential_pressure.nc'\n",
    "\n",
    "# Match the climate features, from the ERA5Land netCDF file, for each of the stake measurement dataset\n",
    "dataset.get_climate_features(era5_climate_data, geopotential_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe4fa9fa2ff6c55",
   "metadata": {},
   "source": [
    "## 4. Transform Data to Monthly Resolution\n",
    "\n",
    "Finally, we need to transform the dataset into a monthly resolution, accounting for a variable period for the SMB target data. This will be done in order to perform SMB predictions at a monthly time step, which then will be integrated both in time and space to match the available glaciological and geodetic SMB observations for the training. Please specify the climate variables used in the previous step in the list below. Consult the [documentation](https://confluence.ecmwf.int/display/CKB/ERA5-Land%3A+data+documentation) of all short names of the climate variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5c40243a95f88f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T15:45:17.373154Z",
     "start_time": "2024-07-12T15:45:17.220243Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (7,7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m voi_topographical \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maspect\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslope\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m voi_climate \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt2m\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslhf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msshf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mssrd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfal\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrt\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_monthly\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvoi_climate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoi_topographical\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/Jbies/OneDrive/AES/MSc Thesis/MassBalanceMachine/massbalancemachine/data_processing/Dataset.py:97\u001b[0m, in \u001b[0;36mDataset.convert_to_monthly\u001b[0;34m(self, vois_climate, vois_topographical)\u001b[0m\n\u001b[1;32m     94\u001b[0m output_fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregion_monthly.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m prepare_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, vois_climate)\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_monthly\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvois_climate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvois_topographical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_fname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/Jbies/OneDrive/AES/MSc Thesis/MassBalanceMachine/massbalancemachine/data_processing/transform_to_monthly.py:116\u001b[0m, in \u001b[0;36mconvert_to_monthly\u001b[0;34m(df, vois_climate, vois_topographical, output_fname)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m monthly_df\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Apply the helper function to each row and concatenate the results\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m monthly_dfs \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m concatenated_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(monthly_dfs\u001b[38;5;241m.\u001b[39mtolist())\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m    119\u001b[0m concatenated_df\u001b[38;5;241m.\u001b[39mto_csv(output_fname, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/mbm_env/lib/python3.12/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/mbm_env/lib/python3.12/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mbm_env/lib/python3.12/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/anaconda3/envs/mbm_env/lib/python3.12/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/mnt/c/Users/Jbies/OneDrive/AES/MSc Thesis/MassBalanceMachine/massbalancemachine/data_processing/transform_to_monthly.py:92\u001b[0m, in \u001b[0;36mconvert_to_monthly.<locals>.process_row\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     89\u001b[0m columns_to_keep \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(col\u001b[38;5;241m.\u001b[39mendswith(month) \u001b[38;5;28;01mfor\u001b[39;00m month \u001b[38;5;129;01min\u001b[39;00m months)]\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Reshape the data for the current row to a 2D array (months x climate variables)\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m reshaped_data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns_to_keep\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmonths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvois_climate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mF\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Create a MultiIndex for the new DataFrame, these are the columns to keep in the new dataframe\u001b[39;00m\n\u001b[1;32m     95\u001b[0m index_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMONTH\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYEAR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN_MONTHS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOINT_LON\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOINT_LAT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOINT_BALANCE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mALTITUDE_CLIMATE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mELEVATION_DIFFERENCE\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/mbm_env/lib/python3.12/site-packages/numpy/core/fromnumeric.py:285\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    202\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mbm_env/lib/python3.12/site-packages/numpy/core/fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (7,7)"
     ]
    }
   ],
   "source": [
    "voi_climate = ['t2m', 'tp', 'slhf', 'sshf', 'ssrd', 'fal', 'srt']\n",
    "\n",
    "dataset.convert_to_monthly(voi_climate, voi_topographical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c4f78689b849e4",
   "metadata": {},
   "source": [
    "Finally, we can take a look at the dataset which will be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6edf2f9025c61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
